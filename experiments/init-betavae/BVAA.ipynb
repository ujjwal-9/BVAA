{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch import nn\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "mnist_dataset = datasets.MNIST('../../data', \n",
    "                   train=True, \n",
    "                   download=True, \n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.Resize(32),\n",
    "                       transforms.ToTensor()\n",
    "                   ]))\n",
    "\n",
    "mnist_dataset_test = datasets.MNIST('../../data', train=False, download=True, transform=transforms.Compose([\n",
    "                       transforms.Resize(32),\n",
    "                       transforms.ToTensor()\n",
    "                   ]))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(mnist_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(mnist_dataset_test, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Encoder(nn.Module):\n",
    "#     def __init__(self, x_size, h_size, z_size):\n",
    "#         super(Encoder, self).__init__()\n",
    "#         self.fc1 = nn.Linear(x_size, h_size)\n",
    "#         self.mu_gen = nn.Linear(h_size, z_size)\n",
    "#         # make the output to be the logarithm \n",
    "#         # i.e will have to take the exponent\n",
    "#         # which forces variance to be positive\n",
    "#         # not that this is the diagonal of the covariance\n",
    "#         self.log_var_gen = nn.Linear(h_size, z_size)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = F.relu(self.fc1(x))\n",
    "#         mu = self.mu_gen(x)\n",
    "#         log_var = self.log_var_gen(x)\n",
    "#         return mu, log_var\n",
    "    \n",
    "class Encoder(nn.Module):\n",
    "    r\"\"\"\n",
    "    References:\n",
    "            [1] Burgess, Christopher P., et al. \"Understanding disentangling in\n",
    "            $\\beta$-VAE.\" arXiv preprint arXiv:1804.03599 (2018).\n",
    "    \"\"\"\n",
    "    def __init__(self, img_size, latent_dim=10):\n",
    "\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        hidden_channels = 32\n",
    "        kernel_size = 4\n",
    "        hidden_dim = 256\n",
    "\n",
    "        self.latent_dim = latent_dim\n",
    "        self.img_size = img_size\n",
    "\n",
    "        self.reshape = (hidden_channels, kernel_size, kernel_size)\n",
    "\n",
    "        n_channels = self.img_size[0]\n",
    "\n",
    "        cnn_kwargs = dict(stride=2, padding=1)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(n_channels, hidden_channels, kernel_size, **cnn_kwargs)\n",
    "        self.conv2 = nn.Conv2d(hidden_channels, hidden_channels, kernel_size, **cnn_kwargs)\n",
    "        self.conv3 = nn.Conv2d(hidden_channels, hidden_channels, kernel_size, **cnn_kwargs)\n",
    "\n",
    "        if self.img_size[1] == self.img_size[2] == 64:\n",
    "            self.conv_64 = nn.Conv2d(hidden_channels, hidden_channels, kernel_size, **cnn_kwargs)\n",
    "\n",
    "        self.lin1 = nn.Linear(np.product(self.reshape), hidden_dim)\n",
    "        self.lin2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "\n",
    "        self.mu_logvar_gen = nn.Linear(hidden_dim, self.latent_dim * 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = torch.relu(self.conv3(x))\n",
    "\n",
    "        if self.img_size[1] == self.img_size[2] == 64:\n",
    "            x = torch.relu(self.conv_64(x))\n",
    "\n",
    "        x = x.view((batch_size, -1))\n",
    "        x = torch.relu(self.lin1(x))\n",
    "        x = torch.relu(self.lin2(x))\n",
    "\n",
    "        mu_logvar = self.mu_logvar_gen(x)\n",
    "\n",
    "        mu, logvar = mu_logvar.view(-1, self.latent_dim, 2).unbind(-1)\n",
    "\n",
    "        return mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Decoder(nn.Module):\n",
    "#     def __init__(self, x_size, h_size, z_size):\n",
    "#         super(Decoder, self).__init__()\n",
    "#         self.fc1 = nn.Linear(z_size, h_size)\n",
    "#         self.fc3 = nn.Linear(h_size, x_size)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = F.relu(self.fc1(x))\n",
    "#         x = F.relu(self.fc3(x))\n",
    "#         # black and white MNIST => sigmoid for each pixel\n",
    "#         x = torch.sigmoid(x) \n",
    "#         return x\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    r\"\"\"\n",
    "    References:\n",
    "            [1] Burgess, Christopher P., et al. \"Understanding disentangling in\n",
    "            $\\beta$-VAE.\" arXiv preprint arXiv:1804.03599 (2018).\n",
    "    \"\"\"\n",
    "    def __init__(self, img_size, latent_dim):\n",
    "\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        hidden_channels = 32\n",
    "        kernel_size = 4\n",
    "        hidden_dim = 256\n",
    "\n",
    "        self.img_size = img_size\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "        self.reshape = (hidden_channels, kernel_size, kernel_size)\n",
    "\n",
    "        n_channels = self.img_size[0]\n",
    "\n",
    "        self.lin1 = nn.Linear(latent_dim, hidden_dim)\n",
    "        self.lin2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.lin3 = nn.Linear(hidden_dim, np.product(self.reshape))\n",
    "\n",
    "        cnn_kwargs = dict(stride=2, padding=1)\n",
    "\n",
    "        if self.img_size[1] == self.img_size[2] == 64:\n",
    "            self.convT_64 = nn.ConvTranspose2d(hidden_channels, hidden_channels, kernel_size, **cnn_kwargs)\n",
    "\n",
    "        self.convT1 = nn.ConvTranspose2d(hidden_channels, hidden_channels, kernel_size, **cnn_kwargs)\n",
    "        self.convT2 = nn.ConvTranspose2d(hidden_channels, hidden_channels, kernel_size, **cnn_kwargs)\n",
    "        self.convT3 = nn.ConvTranspose2d(hidden_channels, n_channels, kernel_size, **cnn_kwargs)\n",
    "\n",
    "    def forward(self, z):\n",
    "        batch_size = z.size(0)\n",
    "\n",
    "        x = torch.relu(self.lin1(z))\n",
    "        x = torch.relu(self.lin2(x))\n",
    "        x = torch.relu(self.lin3(x))\n",
    "\n",
    "        x = x.view(batch_size, *self.reshape)\n",
    "\n",
    "        if self.img_size[1] == self.img_size[2] == 64:\n",
    "            x = torch.relu(self.convT_64(x))\n",
    "\n",
    "        x = torch.relu(self.convT1(x))\n",
    "        x = torch.relu(self.convT2(x))\n",
    "\n",
    "        x = torch.sigmoid(self.convT3(x))\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class VAE(nn.Module):\n",
    "#     def __init__(self, x_size, h_size, z_size):\n",
    "#         super(VAE, self).__init__()\n",
    "#         self.x_size = x_size\n",
    "#         self.z_size = z_size\n",
    "#         self.encoder = Encoder(x_size, h_size, z_size)\n",
    "#         self.decoder = Decoder(x_size, h_size, z_size)\n",
    "\n",
    "#     def reparameterize(self, mu, log_var):\n",
    "#         std = torch.exp(0.5 * log_var) # square root in exponent => std\n",
    "#         eps = torch.randn_like(std)\n",
    "#         z = std * eps + mu\n",
    "#         return z\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         # make image linear (i.e vector form)\n",
    "#         x = x.view(-1, self.x_size)\n",
    "#         mu, log_var = self.encoder(x)\n",
    "#         z = self.reparameterize(mu, log_var)\n",
    "#         x_hat = self.decoder(z)\n",
    "#         return x_hat, mu, log_var\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, img_size, latent_dim):\n",
    "        super(VAE, self).__init__()\n",
    "        if list(img_size[1:]) not in [[32,32], [64,64]]:\n",
    "            raise RuntimeError(\"{} sized images not supported. Only (None, 32, 32) and (None, 64, 64) supported. Build your own architecture or reshape images!\".format(img_size))\n",
    "\n",
    "        self.latent_dim = latent_dim\n",
    "        self.img_size = img_size\n",
    "        self.num_pixels = self.img_size[1] * self.img_size[2]\n",
    "        self.encoder = Encoder(img_size, self.latent_dim)\n",
    "        self.decoder = Decoder(img_size, self.latent_dim)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reparameterize(self, mean, logvar):\n",
    "        if self.training:\n",
    "            std = torch.exp(0.5 * logvar)\n",
    "            eps = torch.randn_like(std)\n",
    "            return mean + std * eps\n",
    "\n",
    "        else:\n",
    "            return mean\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        latent_distribution = self.encoder(x)\n",
    "        latent_sample = self.reparameterize(*latent_distribution)\n",
    "        reconstruct = self.decoder(latent_sample)\n",
    "        return reconstruct, latent_distribution, latent_sample\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.apply(weights_init)\n",
    "\n",
    "    def sample_latent(self, x):\n",
    "        latent_distribution = self.encoder(x)\n",
    "        latent_sample = self.reparameterize(*latent_distribution)\n",
    "        return latent_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_activation_name(activation):\n",
    "    \"\"\"Given a string or a `torch.nn.modules.activation` return the name of the activation.\"\"\"\n",
    "    if isinstance(activation, str):\n",
    "        return activation\n",
    "\n",
    "    mapper = {nn.LeakyReLU: \"leaky_relu\", nn.ReLU: \"relu\", nn.Tanh: \"tanh\",\n",
    "              nn.Sigmoid: \"sigmoid\", nn.Softmax: \"sigmoid\"}\n",
    "    for k, v in mapper.items():\n",
    "        if isinstance(activation, k):\n",
    "            return k\n",
    "\n",
    "    raise ValueError(\"Unkown given activation type : {}\".format(activation))\n",
    "\n",
    "\n",
    "def get_gain(activation):\n",
    "    \"\"\"Given an object of `torch.nn.modules.activation` or an activation name\n",
    "    return the correct gain.\"\"\"\n",
    "    if activation is None:\n",
    "        return 1\n",
    "\n",
    "    activation_name = get_activation_name(activation)\n",
    "\n",
    "    param = None if activation_name != \"leaky_relu\" else activation.negative_slope\n",
    "    gain = nn.init.calculate_gain(activation_name, param)\n",
    "\n",
    "    return gain\n",
    "def linear_init(layer, activation=\"relu\"):\n",
    "    \"\"\"Initialize a linear layer.\n",
    "    Args:\n",
    "        layer (nn.Linear): parameters to initialize.\n",
    "        activation (`torch.nn.modules.activation` or str, optional) activation that\n",
    "            will be used on the `layer`.\n",
    "    \"\"\"\n",
    "    x = layer.weight\n",
    "\n",
    "    if activation is None:\n",
    "        return nn.init.xavier_uniform_(x)\n",
    "\n",
    "    activation_name = get_activation_name(activation)\n",
    "\n",
    "    if activation_name == \"leaky_relu\":\n",
    "        a = 0 if isinstance(activation, str) else activation.negative_slope\n",
    "        return nn.init.kaiming_uniform_(x, a=a, nonlinearity='leaky_relu')\n",
    "    elif activation_name == \"relu\":\n",
    "        return nn.init.kaiming_uniform_(x, nonlinearity='relu')\n",
    "    elif activation_name in [\"sigmoid\", \"tanh\"]:\n",
    "        return nn.init.xavier_uniform_(x, gain=get_gain(activation))\n",
    "def weights_init(module):\n",
    "    if isinstance(module, nn.modules.conv._ConvNd):\n",
    "        # TO-DO: check litterature\n",
    "        linear_init(module)\n",
    "    elif isinstance(module, nn.Linear):\n",
    "        linear_init(module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_annealing(init, fin, step, annealing_steps):\n",
    "    \"\"\"Linear annealing of a parameter.\"\"\"\n",
    "    if annealing_steps == 0:\n",
    "        return fin\n",
    "    assert fin > init\n",
    "    delta = fin - init\n",
    "    annealed = min(init + delta * step / annealing_steps, fin)\n",
    "    return annealed\n",
    "\n",
    "def _kl_normal_loss(mean, logvar):\n",
    "    latent_dim = mean.size(1)\n",
    "    latent_kl = 0.5 * (-1 - logvar + mean.pow(2) + logvar.exp()).mean(dim=0)\n",
    "    total_kl = latent_kl.sum()\n",
    "\n",
    "    return total_kl\n",
    "\n",
    "def _reconstruction_loss(data, recon_data, distribution=\"bernoulli\"):\n",
    "    batch_size, n_channels, height, width = recon_data.size()\n",
    "    is_colored = n_channels == 3\n",
    "\n",
    "    if distribution == \"bernoulli\":\n",
    "        loss = F.binary_cross_entropy(recon_data, data, reduction=\"sum\")\n",
    "\n",
    "    elif distribution == \"gaussian\":\n",
    "        loss = F.mse_loss(recon_data * 255, data * 255, reduction=\"sum\") / 255\n",
    "\n",
    "    elif distribution == \"laplace\":\n",
    "        loss = F.l1_loss(recon_data, data, reduction=\"sum\")\n",
    "        loss = loss * 3\n",
    "        loss = loss * (loss != 0)\n",
    "\n",
    "    loss = loss / batch_size\n",
    "\n",
    "    return loss\n",
    "\n",
    "def loss_function(x_hat, x, mu, log_var, is_train, n_train_steps, steps_anneal=0, beta=1, C_init=0., C_fin=20., gamma=100.):\n",
    "    \"\"\"Compute the ELBO loss\"\"\"\n",
    "    x_size = x_hat.size(-1)\n",
    "    # black or white image => use sigmoid for each pixel\n",
    "#     rec_loss = F.binary_cross_entropy(x_hat, x.view(-1, x_size), reduction='sum')\n",
    "    rec_loss = _reconstruction_loss(x, x_hat, distribution=\"bernoulli\")\n",
    "    # closed form solution for gaussian prior and posterior\n",
    "#     kl_div = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "    kl_div = _kl_normal_loss(mu, log_var)\n",
    "    \n",
    "    C = (linear_annealing(C_init, C_fin, n_train_steps, steps_anneal) if is_train else C_fin)\n",
    "    vae_loss = rec_loss + gamma * (kl_div - C).abs()\n",
    "#     vae_loss = rec_loss + beta * kl_div\n",
    "    return vae_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, model, optimizer=optim.Adam, loss_function=loss_function):\n",
    "        self.model = model \n",
    "        self.optimizer = optimizer(self.model.parameters())\n",
    "        self.loss_function = loss_function\n",
    "        self.epoch = 0\n",
    "        \n",
    "    def __call__(self, train, test, n_epochs=100):\n",
    "        self.epoch = 0\n",
    "        for _ in range(n_epochs):\n",
    "            self._train_epoch(train)\n",
    "            self._test_epoch(test)\n",
    "            with torch.no_grad():\n",
    "                sample = torch.randn(64, self.model.latent_dim).to(device)\n",
    "                sample = model.decoder(sample).cpu()  # make sure on cpu\n",
    "                save_image(sample.view(64, 1, 32, 32),\n",
    "                           '../results/sample_' + str(self.epoch) + '.png')\n",
    "        \n",
    "    def _train_epoch(self, train):\n",
    "        self.epoch += 1\n",
    "        model.train() # make sure train mode (e.g. dropout)\n",
    "        train_loss = 0\n",
    "        for i, (x, _) in enumerate(train):\n",
    "            x = x.to(device) # data on GPU \n",
    "            self.optimizer.zero_grad() # reset all previous gradients\n",
    "            x_hat, latent_distribution, latent_sample = model(x)\n",
    "            loss = self.loss_function(x_hat, x, *latent_distribution, True, i)\n",
    "            loss.backward() # backpropagate (i.e store gradients)\n",
    "            train_loss += loss.item() # compute loss (.item because only the value)\n",
    "            self.optimizer.step() # take optimizing step (~gradient descent)\n",
    "\n",
    "        print('Epoch: {} Train loss: {:.4f}'.format(\n",
    "              self.epoch, train_loss / len(train.dataset)))\n",
    "        \n",
    "    def _test_epoch(self, test):\n",
    "        model.eval() # make sure evaluate mode (e.g. dropout)\n",
    "        test_loss = 0\n",
    "        with torch.no_grad():  # stop gradients computation\n",
    "            for i, (x, _) in enumerate(test):\n",
    "                x = x.to(device)\n",
    "                x_hat, latent_distribution, latent_sample = model(x)\n",
    "                test_loss += loss_function(x_hat, x, *latent_distribution, False, i).item()\n",
    "\n",
    "        print('Test loss: {:.4f}'.format(test_loss/len(test.dataset)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = enumerate(test_loader)\n",
    "batch_idx, (example_data, example_targets) = next(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZQAAAELCAYAAAD+9XA2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO3deZRU1Z0H8O9laRCaRRZZZHVDBRGjKIsBjWBiMCEqakRiguOZeDRmzMwcPTpjZCYTT+LEM85xXIZ43ACXQSBuaFwCKiCorIJhURbZlxZklWa588crfn7fS1d3dfWtrurq7+cczvk2/V7Va+pSt9+v7uK89xAREampBvm+ABERKQ7qUEREJAh1KCIiEoQ6FBERCUIdioiIBKEORUREgijqDsU5t9Y5NyyPz7/BOXdRvp5fsqe2I9mqz22nRh2Kc+7Hzrl5zrl9zrltqXyLc86FusBccM697pzbm/pzyDlXTl8/luVjTnTOjQt4jSc6515xzm12znnnXJdQj10I1HZij6m2Uw1qO7HHDNp2Uo85xjm3LnVdU51zrTM9N+sOxTn3TwD+G8B/AugIoAOAmwEMBlCS5pyG2T5fSN77y7z3pd77UgCTANx/7Gvv/c3J451zjWr/KnEUwHQAo/Lw3DmltpNzajvxc9R2MuSc6wvgEQDXI/r3PQTgfzJ+AO99tf8AaAVgH4CrqjjuKQCPImrc+wAMS537DIDtANYB+FcADVLHjwMwkc7vAcADaJT6eiaA3wCYDWAPgDcBtKPjf5J6zDIA/wJgLYBhGVzjfyT+bljq3LsBbAHwJICbAMykYxqlrq0HgFtS//DlAPYCmJY6ZgOAfwTwCYCvADwHoEk1/62bpp6nSzavVaH9UdtR21HbKdy2A+B+AM/Q170AHATQLJPzs71DGQigCYCXMjh2NIDfAmgBYBaAhxC9uCcBGArgBgBjq/Hco1PHn4DoN5J/BgDn3JmIGtFPAHQG0BZATW71uwAoBdAN0QuXlvf+EQAvALjPR79tXEHfvgbAcEQ/77mp64NzrqFzbpdzbkANrrEuUtshajvVorZDctR2egNYTM+xAtEd76mZXHy2HUo7ADu894eP/YVzbk7qQg8454bQsS9572d7748i6k1/DOAu7/0e7/1aAA8g9cNm6Env/Urv/QEA/wegX+rvRwF41Xv/nvf+IIB7EP1DZOswgHHe+/LUc2XrQe/9Fu99GYBXj12v9/6I9761935uDR67LlLbyZzaTpzaTuaybTuliO5q2G5EHXOVsu1QygC04xqf936Q97516nv8uOsptwPQGNHt4THrAJxYjefeQnk/on8AIPrtwJ7Le78vdS3Z2uq9L6/B+ceku976Sm0nc2o7cWo7mcu27ewF0DLxdy0RlfqqlG2H8gGiutrIDI7l5Yx3IPptoTv9XTcAG1N5H4Bm9L2O1bimzQC6HvvCOdcM0e1ntpLLMFd1bVq2OTNqO2o72VLbyX3bWQbg7GNfOOdOQ9RPrMrk5Kw6FO/9LgD/BuAR59wo51wL51wD51w/AM0rOe8IotvF36bO6Y7ow6OJqUMWARjinOvmnGsF4K5qXNaLAC53zl3onCsB8O8IO89mMYC+zrmznHPHAbg38f2tiOqVwTjnmiKqGQNAE+dck8qOrwvUdtR2sqW2UyttZyKAHznnBjnnmiP6eSZ77/dncnLWP7j3/n5EL8odiH6orQD+F8CdAOZUcuptiHrd1Yg+LHsWwBOpx3wL0YdMSwDMR1T7y/R6lgG4NfV4mwHsRDTaIQjv/acA7kM04mMFgPcShzwO4Gzn3E7n3ItVPV7qw7G9zrmBab7fCMABALtSf/UZon+3Ok9tR20nW2o7uW073vslAH4B4HkA2xD9UnJbptfrUkPDREREaqSol14REZHaow5FRESCUIciIiJBqEMREZEg1KGIiEgQ1VrN0jmnIWEFyHtf6Mt2q90Uph3e+/b5vojKqO0UrArbju5QROqvdVUfIlKhCtuOOhQREQlCHYqIiAShDkVERIJQhyIiIkGoQxERkSDUoYiISBDqUEREJAh1KCIiEoQ6FBERCUIdioiIBFGttbzqusaNG1seNmyY5RYtWlj+8MMPY+ds2PDNbp6HDx/O4dVJIXHum+XRuH1cf/31lleuXGl54cKFsfO//PLLHF6dFJKGDRvGvj7uuOMst2nTxvLgwYMtt2vXLu35bPHixZZnzZpl+dChQ9ldbI7pDkVERIJQhyIiIkHUq5JXSUmJ5RtuuMFynz59LN9///2xc1555RXLu3btyuHVSSFp0OCb37W4bPG73/3O8rx58yw/+uijsfPfffddyyp/FZ+WLVta7ty5c+x7PXv2tNy/f3/LY8aMsdyjRw/LXIoHAO+/WbF/0qRJltesWWN57dq11b/oWqA7FBERCUIdioiIBFGvSl7s6NGjlrt27Wr5jDPOiB03e/Zsyyp5CZcjhg8fbvnIkSOx4/bu3Wt5xowZljVSsPA1avTN2yKPxmratKllfp/gdgAA55xzjuUhQ4ZU+BxcUuU2lfy6V69eli+55BLLU6dOtbxz584KnyMfdIciIiJBqEMREZEg6lXJiyertW3b1nJlE4tEMjF06NDY13PmzLHMkx537NhRa9ck2Wnfvr3l2267zXK/fv0s88iu0047LXZ+kyZNgl1L3759Ld98882WuWQ/ceJEy/me8Kg7FBERCUIdioiIBFFvS17Nmze3rJKX1FRypM369estl5WV1fblSA1069bN8qBBgywPGDDAMo/SyuX7B096POussyzffvvtlrl9vfHGG7Hzy8vLc3ZtFdEdioiIBKEORUREglCHIiIiQdSrz1B4qN22bdss53uondR98+fPj3392WefWU7OhJb84OG8vIDjqaeeGjsu3VDh5CKOtY2fnxen5M+D8013KCIiEoQ6FBERCaJelbx4eB8PweMtO0WysWfPntjXtT1cU6rGpSFetHHs2LGx484888wKzykkvC31xRdfbHnmzJmx47i0n1zANBd0hyIiIkGoQxERkSCKvuTFIyN4QbcOHTpY5v0PeGtOIL4fwurVq3NwhVKIuN107NjRMs+QlsLHq2PwKC/eA4kXYATi+56kw/vaJFdJ2Lhxo+X9+/db7t27t2VuX59//nns/AULFljm9x9egLS0tNQy75OydevW2GP98Y9/tLxhwwbLPOI1JP3vEBGRINShiIhIEEVR8iopKbGcXKiNy1mnn3665XSli+TtLj+21B/cjlq1amWZSyhS+Pj/c/fu3S0PHDjQMr9HVIa3dV68eLFl3uIZiJew9u3bZ5lHlnL7SpbSueTVqVOnCp//0ksvtcyLWf7sZz+LPRbvvzN58mTLmzZtQi7oDkVERIJQhyIiIkEURcmrWbNmlpMlq4MHD1rOZLQOj9AA/nYEh9QPXJI4/vjj83glUhM8aZlL3jwZsDJcsuL12p5++mnLU6ZMiZ3DpSmWPC4TK1asqPBxeZQYj/LiEhkAjBw50vIHH3xgWSUvEREpaOpQREQkCHUoIiISRFF8hsKSwzp5Lwquh6abKZpc5O/AgQMBr07qCq6980zqTIeYSt3F+yMtWrTI8lNPPWV5+vTpltN9ZhLC119/bXnhwoWWH3nkEcv82fD5558fO5/bMQ9/51UD+HPmmtIdioiIBKEORUREgiiK+/ddu3ZVmIH4Vpna6lcyxaVTLQhZv2zfvt3y+PHjLb/88suWd+/eXavXBMRL9rzF9Jo1ayyfd955sXN4qPTw4cMtr1+/3vLy5cuDXaP+p4iISBDqUEREJIiiKHlVhmeU8t4CPBNaC/5JEo+C6dmzp2WVv4pDZa8j73XC+4skR4AWisrKszyyq3379pZ5dZGQ9L9DRESCUIciIiJBFH3Jiyc2pvt7nuTIt7vJ70n90bx5c8sXXHCB5XQTG7/44ovY12VlZbm5MKmW8vJyyzyyifcc4X1KgPTvB+neS/It3XtZ8nu1QXcoIiIShDoUEREJouhLXryWTZ8+fSzzKC9eyya5H0o+JjBJ/vFomdLSUsvpRgSuXbs29jVPjpP84bX4eALgnDlzLJ9xxhmxc3hk1ODBgys8P/l6S0R3KCIiEoQ6FBERCUIdioiIBFH0n6HwjOdTTjnFMtfI+TOUHTt2xM7nBdmkePHnJABw0kknWebP4dJ9hpLcEyPkHhOSvSNHjljm14g/40oOrW3RooXlK6+80jK/ptOmTbO8evXq2Pkhpxpw2+P94gcNGmS5X79+lvmz4XzQHYqIiAShDkVERIIo+pJXJsM/+RaVt9wEtIdKfVFZyatp06YVnsPlFK2oUPj49eKVDJJTA9q2bWuZpxqMHj3acklJieXXXnstdv6WLVsqzIzbFG/hC8RXaeAy/dChQy1zmatXr16WVfISEZGioA5FRESCKPqSVyYqW1xNpYz6gUsYQHzr6HR7Z2zevNlysmzC5RUpDDxrfv78+ZZnzJgRO463yj3++OMt9+3b1zKPHk2WrJYtW2Z57ty5FV4L7800YMCA2Pc6dOhguXfv3pZ5ZBfv81QZHtnGI1j379+f0fnVpTsUEREJQh2KiIgEUa9KXjyyizPfFmpUV/2U3BK1S5cuVZ6zaNEiy1z+Av52Xx3JPy7zfPTRR5YfeOCB2HHpFofkCY88sqpHjx6x83mB2aVLl1Z4LVxK47IWALRp06bCc7LBi1h+/PHHlpPtNRTdoYiISBDqUEREJIiiK3kl11riiT78PR7ZxSMxtI9F/cSjbgCgf//+VZ7DIwA1GrBu4VF4POILAO69917Lf/jDHyzzKCse+ccjvoD4pFjOjM9PriUWctvebdu2Wf78888tf/XVV8Geg+kORUREglCHIiIiQRRdySt5+9m5c2fLPXv2tMylMF6iXqO86qfkqCyeBJcOT2DbtWtX8GuS/NiwYYPl999/3zKP8uKRXa1bt66V68pEeXl57Ovly5db3rNnT86fX3coIiIShDoUEREJQh2KiIgEUXSfoTRqFP+RuO7JtU4eQjxr1izLW7duzeHVSaFK7lvBCwYOHDiwwnN4GGZyC2Cpu3gRxYcfftgyv09cd911lnmbYCC+n0mu8Ochs2fPtvzJJ5/EjpswYYJlnjWfK7pDERGRINShiIhIEEVX8krOWOYF4fg2kUte69evt5zJcFEpPsnh4ry/Cc+q/vTTTy1zu0luHS11Fw8h51IoTy/gEueqVati519wwQWWR4wYUaNr4fevJUuWWH7++ect8wKUX3zxRex8bqPJIcW5oDsUEREJQh2KiIgEUXQlr8pmit55550VnsNljNq4LZTCk1ws75133rHMZVAuIXCpQSWv4scl8wULFljmmfVAfHY9tyOWbqHaJH4/4lFavKAlX1e+S/a6QxERkSDUoYiISBCuOmvvO+fCLdQvwXjvXdVH5Y/aTcGa770/L98XURm1nYJVYdvRHYqIiAShDkVERIJQhyIiIkGoQxERkSDUoYiISBDqUEREJAh1KCIiEoQ6FBERCUIdioiIBKEORUREglCHIiIiQahDERGRIKq7H8oOAOtycSGSte75voAMqN0UJrUdyVaFbadaqw2LiIiko5KXiIgEoQ5FRESCUIciIiJBqEMREZEg1KGIiEgQ6lBERCQIdSgiIhKEOhQREQlCHYqIiAShDkVERIJQhyIiIkGoQxERkSDUoYiISBBF3aE459Y654bl8fk3OOcuytfzS/bUdiRb9bnt1KhDcc792Dk3zzm3zzm3LZVvcc65UBeYC865151ze1N/Djnnyunrx7J8zInOuXEBr3GYc26pc26Xc26Hc26Kc65TqMfPN7Wd2GMGbTupx7w99ca22zn3oXNuUMjHzye1ndhjFlTbybpDcc79E4D/BvCfADoC6ADgZgCDAZSkOadhts8Xkvf+Mu99qfe+FMAkAPcf+9p7f3PyeOdcdTciC2EpgOHe+9YATgSwFsDDebiO4NR2css5NxjAbwBcAaA1gAkAphb6G24m1HZyq8Ztx3tf7T8AWgHYB+CqKo57CsCjAKanjh+WOvcZANsR7cT2rwAapI4fB2Aind8DgAfQKPX1zNQPOxvAHgBvAmhHx/8k9ZhlAP4F0ZvwsAyu8T8Sfzcsde7dALYAeBLATQBm0jGNUtfWA8AtAA4BKAewF8C01DEbAPwjgE8AfAXgOQBNsvj3boroP9CSbF6vQvqjtpP7tgPgegBzEv/mHkD7fL/+ajvF3XayvUMZCKAJgJcyOHY0gN8CaAFgFoCHUhd5EoChAG4AMLYazz06dfwJiH4j+WcAcM6diagR/QRAZwBtAXSpxuMmdQFQCqAbohcuLe/9IwBeAHCfj37buIK+fQ2A4Yh+3nNT1wfnXMNUOWtAusd1zvV0zu0CsB/APwC4vwY/T6FQ2yE5ajuvAWjqnOuf+u38RgDzvffba/AzFQK1HVKIbSfbDqUdgB3e+8PH/sI5Nyd1oQecc0Po2Je897O990cR9aY/BnCX936P934tgAeQ+mEz9KT3fqX3/gCA/wPQL/X3owC86r1/z3t/EMA9AI5m+fMBwGEA47z35annytaD3vst3vsyAK8eu17v/RHvfWvv/dx0J3rv1/io5NUewK8BrKjBdRQKtZ3MZdt2dgOYBmAOgIMA7gLw9zW4jkKhtpO5vLSdbDuUMgDtuMbnvR+UevMrSzzuesrtADRGdHt4zDpEnxFkagvl/Yh6cyD67cCey3u/L3Ut2drqvS+vwfnHpLvejKUaxUQALzvn6vrIPLWdzGXbdv4ewBgAZyL6jX4sgOnOuQ4Brimf1HYyl5e2k+2b0weIeq+RGRzrKe9A9NtCd/q7bgA2pvI+AM3oex2rcU2bAXQ99oVzrhmi289s+cTXVV1b8vjQGqWes9odUoFR28l92+kH4GXv/arUb6SvIfr3Gxj4eWqb2k6Bt52sOhTv/S4A/wbgEefcKOdcC+dcA+dcPwDNKznvCKLbxd+mzumO6MOjialDFgEY4pzr5pxrheh2K1MvArjcOXehc64EwL8j7DybxQD6OufOcs4dB+DexPe3IqpXBuGcu8o5d6qLnIDoFv0j7/3uUM+RD2o7uW87AD5C9PP0SLWf7wI4GcCygM9R69R2Cr/tZP2De+/vR/Si3IHoh9oK4H8B3Imo/pbObYh63dWIPix7FsATqcd8C9GHTEsAzEdU+8v0epYBuDX1eJsB7EQ02iEI7/2nAO5DNOJjBYD3Eoc8DuBs59xO59yLVT1e6sOxvc65dD1/V0SjSfYialTliOq1dZ7aTs7bzpMApqae5ysA/wXg77z3q7L8EQqG2k5htx2XGhomIiJSI3X9A14RESkQ6lBERCQIdSgiIhKEOhQREQlCHYqIiARRrdUsnXMaElaAvPcFvYqs2k3B2uG9b5/vi6iM2k7BqrDt6A5FpP5aV/UhIhWqsO2oQxERkSDUoYiISBDqUEREJAh1KCIiEoQ6FBERCUIdioiIBKEORUREglCHIiIiQahDERGRINShiIhIENVay0tEKta6devY1926dbPco0cPyx07drTcsGFDy2vXrrX89ttvxx7r0KFDga5SJLd0hyIiIkGoQxERkSCKruTFZQQAaNy4cdrvZeLIkSOWufTAfy/1R4MG3/wOxuWr888/P3bcd77zHct9+/a13LZtW8vcnt58803LM2fOjD2WSl6FrVGj+Ntoq1atLHfp0qXCczp37my5pKQko+cpLy+3XFZWZnn58uWW9+zZEzvH+9pd/V93KCIiEoQ6FBERCaLOlryc+2aTwmbNmlnu1KlT7LiuXbtaLi0trfbzfPXVV5Y3bdpkeevWrZb37dtn+ejRo9V+Dils3NZatmxp+aqrrrJ85ZVXxs7hUgeP4HrllVcsr1692vLHH39smUsbUji4fH788cdbTpa1zj77bMuXXXZZhY81fPhwy8kRgulwOWvevHmW77vvPsvvv/9+7JzDhw9n9Nih6A5FRESCUIciIiJB1NmSV5MmTSwPGDDA8k033RQ7jm8t27RpU+3n2bJli+V33nnH8pQpUyzPnj3b8pdffmlZI8GKA4/iGThwoOXbb7/dcvv27WPnTJo0yfJjjz1mefHixbm4RAmIR/LxCCyeoDpq1CjLY8aMiZ3fvXv3Cs/nEVc8cm///v2x87nEym2PS/bf+ta3LI8ePdoyl8IAlbxERKSOUociIiJB1KmSF98KDhs2zPIvfvELyxdddFHsHB6ZkY0TTjjB8tVXX22ZSx+vvvqq5fHjx1tesWJF7LFUAqubjjvuOMu///3vLTdv3tzyHXfcETtn2rRplnfs2JHDq5PQuHz505/+1DL//z/99NMtN23aNHY+l7a2b99umUeDvvzyy5Z5kiIQL+cPGjTI8sUXX2yZS2E8WZbLdfmgOxQREQlCHYqIiAShDkVERIKoU5+hcH2Qa4ucM11oLZvn5Mfm/S6uu+46y+eee67lX//617HH+vDDDy1zPVUKD6++wK8pr8TAM905A/EVFkJ+dtanTx/LXOvn9rRhw4bYObzCg0T4/zV/BgEA9957r+VLL73U8oknnmiZPyfhxRmB+Geqb7zxhmX+LK2y6QU8c54/v+PPUBh/tpxvukMREZEg1KGIiEgQdarkxbd2PGs0m0UfM8UzWrmswLe87dq1s9yiRQvL48aNiz3Wrbfeavmvf/2rZQ0nrju4Da5fv95ycuhnJgs88v48vNggl3AB4IILLrDM5Tc+h1d04AUoAeDxxx+v8lrqA/735jLXPffcEzvu8ssvt8xlRf43fu+99yxPnz49dj7PVudzDh48aJnfP3hqAhDfW4dnxDN+LC635vu9RHcoIiIShDoUEREJok6VvHivER4xxXtJcEkgiW8zOS9YsMDyypUrY+fw7SSXvM455xzL1157rWWeNcuz6YH4QpVcItm8eXPaa5b84NIWv6YHDhywzIsA8qg/AFi1apVlLn/x3hlcyho6dKhlnoUNAD179rTMs/O55MbtNNmGJcIlLy5T/+AHP4gdxyP5li5dannq1KmWX3/9dcv8WgPxEX6ZSG4fzfvs9OvXzzK3o40bN1qeO3euZZW8RESkKKhDERGRIOpUyYvLVO+++65lHuXFW/MC8cmIa9assczlKy6ZJW9ft23bZvnUU0+1zCWvdHgBNwC45pprLPNIEJW8Cg/vI8FtYNeuXZa5PYwYMSJ2Pk9O41JL7969LXOp4+STT7bMW70C8fbBJRgudcyZM8eySl4V4zImTxjk0XJA/PVi6bYa37t3b+w4LjtxiZT/nktZI0eOjJ3PpdBWrVpZ/uyzzyw/99xzlrn8X9v7nyTpDkVERIJQhyIiIkHU2ZIXj3B56aWXLPNtIRAfFbNw4ULLPBKDR4/xLSYAnHXWWZa5ZMUjtjLFk5SS6wdJYeGJY7xW06JFiyx37drV8ne/+93Y+Vy24DbImUf6ccmKSxhAfG2ujz76yPK6dessf/311+l+FEnh/+dc8k7uW8RlSc48qo/X1eLSIxB/n+HXjt9zbrzxRsu8XhgQnxz9+eefW+Y9VJ544gnLhbTfju5QREQkCHUoIiIShDoUEREJok59hsLS7QGQHDbH+x5UNov+GB4KCgCjRo2yfN5551XnEv8Gf+6THGoo+ZVsTzzkm2van3zyieVLLrnEMs+AB4A2bdpY5lnNs2bNsvzBBx9Y5lr5a6+9FnusTBaalKrxsF1etPGhhx6KHTd27FjLvEoBv6b8XpCc6c6fZ/E0BH5O/oyNhzADwLJlyyy/8MILlidPnmy5kD43YbpDERGRINShiIhIEHW25MWzWb/97W9bvvvuu2PH9e3bt9auKYmHngLApEmTLPOsfcm/xo0bx77mxR55f4y77rrLcnKIOeP9bh588EHLEydOrNF1SvZ42DCveDBhwoTYcTNnzrTMpSne6nvw4MGWeVUEAGjSpIllnnbAmXFJFIgPCX7mmWcs7969u8LzC4nuUEREJAh1KCIiEkSdLXnxyAheWI9ntuYDl7mS5Q2+teYRX5IfPAIwWRrlbWF5VQTeGyXdSMOkTI+TwsAlKJ6d/tZbb1nmUtiYMWNi5/PM9+T2vhVJLiLL5dd0C1UWKt2hiIhIEOpQREQkiDpb8uJ9Bnj7Ux5dAwB9+vTJyfPzZLMvvvjCMt8ijx8/PnYOH5fvrTrrK9769YorrrD885//PHYcT3Dl1+rJJ5+0zIv9JbeR5UUgeR8NKXw8Goz/nx86dMjy7NmzLSf/L/PCr5dddlmVz5dcKPb666+3/OWXX1p++umnq3ysfNMdioiIBKEORUREgshJyevaa6+1zHtGvPnmm5aXLFlSo+fg20xeB4nXRwLiW3WG3IOEb395XR3eG4FLXIDWZKpNvK0rj7o5++yzLQ8aNMgyr9MEAFOmTLHM63f95S9/sfy9730v7fPzvjzJPXqkbuL9mFhyYiOXS/kcfp/g9pkc5XXKKadY5vbK5Vqt5SUiIkVNHYqIiAShDkVERILIyWcovHf6j370I8u8h8C8efMsv//++5Y//fTT2GNlMryWP6tILvS2YMECy6WlpZZ5aCDPRuWZ0AAwYsQIyzw7tqSkxDJ/TsMLVc6YMSP2WPwZCj+/hMef411zzTWWTzrpJMs8JPPFF1+Mnf/8889b3rRpk2VeVPCWW26xnFwocvPmzRVmKQ78eUZydQ7eG2fnzp2Wed8V3kunX79+sfP5fYofm/dz+vOf/5zNZeec7lBERCQIdSgiIhJETkpevB/AaaedZrlHjx6WBwwYYJlLZLz9JZBZyYv3CUgOp+NtN9m+ffss83BiHuZcGV7A7cQTT7T8/e9/3/LDDz+c9jpV8qo5LjtyGwLis425VMDt4e2337bM+04AwNKlSy3za80zn/v37285OaSUy7CFOsRTqofbwemnn2554MCBseP4PYtL7tzGeAvwDh06xM7v1auXZR6CzFsN8/B1nsKQb7pDERGRINShiIhIEDkpefHoGR7lwDNKeYtVLk9kg0sKyX1GktvwHsML+/EoLR4FBMRHXKTDo8R4Bizv2QJoX4wQuMzFr9Uvf/nL2HG83SovJPrGG29Y5pFcydGF/Nrx8/zqV7+yzOXR5Gx4Lt2WlZVV9GYdfj4AAASISURBVKNIHcPvE7wFMI9eBeLveTx6cOvWrZZ5m+GLL744dj63q/bt21vmjw+4farkJSIiRUcdioiIBJGTkhdPWuSRNBdeeKFlLn8lJxNWF08y4pxLPKpn//79llesWGF5z549sXM0sqvmWrZsaZn3IOEJtEC8vDh9+nTLf/rTnyxzmSq5OCSP4hk5cqRlLm+sWbPGMm8PCwArV660rL1vigOXnM455xzLybbDi4lOmzbNMpemeN8m3s8JiE+g5vdJ3lenULcG1h2KiIgEoQ5FRESCyEnJi8tcXBb44Q9/aPnqq6+2fMYZZ1jmyUNAvLTUoEGDCnNlt39cbki3nwE/VhKfw4/FI4d4RM8999xjOTni7PDhw2mfRzLDW+vyhLJkG+ByFq+hNGfOHMudO3e2PGzYsNj5N954o2UuQXB5k7eBffbZZ2PnL1++vJKfQopJ8n2F3yd4AiO3UZ6w2Ldv39j5PNGaJ8guXLjQMo9SLSS6QxERkSDUoYiISBA5KXml25730UcftTx58mTLPKImOVqHJy3yhB8uk/HEs2T5iiespZtgxstN80gKANi+fbvlRYsWWeathnlUB4/yUokrPC6J8qSv5OvO7Y7XluNl7XlCLU9UA+Lbsq5bt84ylzTfeecdy1qvq/5Ktj1e22/cuHGWeSQgjxzk8hcQL41x2Zzffwp1xKjuUEREJAh1KCIiEoQ6FBERCSInn6Ew/jyFh1xu3LjRMtefeR8KIP45BC8MyIsw8jC7ZD2T97/gPVAYz0bl2jkQH/bH+5nw33/99dcVXq+Ex68P16qTr/uQIUMs8zaq/BkMt6Hkqgavv/665fHjx1tOtxKCZsMXv23btlnmz1aTeOb82LFjLV911VWWectoXv0BiG8z/fHHH1ueO3duNa+49ukORUREglCHIiIiQeS85MV4RimXhjinK0slbdq0yTKXMZJ7jpSXl1tOV5bgMkryfD6nUIfq1SdcduSFHk855ZTYcbzF9AknnGCZh15OmDDBMg/9BoAlS5ZYXrVqleVC2ntCahcPH+cFcJNDznkYcCYL13L5HwAmTZpkmbcN5n1WCpXuUEREJAh1KCIiEkStlrxC4lJUTUfYaGRW3cHbSz/xxBOWk3tSnHzyyZZ5vx1erJT3LOHtWYHMS69Sf3C5dcaMGZaT24TzwrfnnnuuZd4DhUe2zpo1K3b+lClTKjwn3eK2hUR3KCIiEoQ6FBERCcJV5zbKOVf491z1kPfeVX1U/qjdFKz53vvzqj4sfwq17fACjp06dYp9j7c679+/v2WetM0L1fJ+SgCwYcMGywcPHqz5xeZGhW1HdygiIhKEOhQREQlCJa8ioJKXZEklL8mWSl4iIpI76lBERCQIdSgiIhKEOhQREQlCHYqIiAShDkVERIJQhyIiIkGoQxERkSDUoYiISBDV3Q9lB4B1VR4ltal7vi8gA2o3hUltR7JVYdup1tIrIiIi6ajkJSIiQahDERGRINShiIhIEOpQREQkCHUoIiIShDoUEREJQh2KiIgEoQ5FRESCUIciIiJB/D+UDxlCvVsekQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "for i in range(6):\n",
    "    plt.subplot(2,3,i+1)\n",
    "    plt.tight_layout()\n",
    "    plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n",
    "    plt.title(\"Ground Truth: {}\".format(example_targets[i]))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 32, 32]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(example_data[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = list(example_data[0].shape) # mnist image\n",
    "# h_size = 256\n",
    "z_size = 12\n",
    "model = VAE(img_size, z_size).to(device) # migrates to CUDA if you can\n",
    "model_old = VAE(img_size, z_size).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VAE(\n",
       "  (encoder): Encoder(\n",
       "    (conv1): Conv2d(1, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (conv2): Conv2d(32, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (conv3): Conv2d(32, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (lin1): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (lin2): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (mu_logvar_gen): Linear(in_features=256, out_features=24, bias=True)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (lin1): Linear(in_features=12, out_features=256, bias=True)\n",
       "    (lin2): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (lin3): Linear(in_features=256, out_features=512, bias=True)\n",
       "    (convT1): ConvTranspose2d(32, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (convT2): ConvTranspose2d(32, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (convT3): ConvTranspose2d(32, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer = Trainer(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# trainer(train_loader, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), './model/betaVAE.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# older model\n",
    "# model.load_state_dict(torch.load('./model/betaVAE.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# siamese tweeked model\n",
    "model.load_state_dict(torch.load('./model/Siamese/G/G-200.pt'))\n",
    "# old model\n",
    "model_old.load_state_dict(torch.load('./model/betaVAE.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import StepLR\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout2d(0.25)\n",
    "        self.dropout2 = nn.Dropout2d(0.5)\n",
    "        self.fc1 = nn.Linear(12544, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "#         data_hat,_,_ = vae_model(data)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, vae_model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            data_hat,_,_ = vae_model(data)\n",
    "            output = model(data_hat)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch_size = 1000\n",
    "batch_size = 64\n",
    "epochs = 2\n",
    "lr = 0.1\n",
    "gamma = 0.7\n",
    "seed = 1\n",
    "no_cuda = False\n",
    "log_interval = 1000\n",
    "save_model = True\n",
    "use_cuda = True\n",
    "torch.manual_seed(seed)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_classification = Net().to(device)\n",
    "optimizer = optim.Adadelta(model_classification.parameters(), lr=lr)\n",
    "\n",
    "scheduler = StepLR(optimizer, step_size=1, gamma=gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.084794\n",
      "\n",
      "Test set: Average loss: 1.9122, Accuracy: 7560/10000 (76%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.1544, Accuracy: 9589/10000 (96%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.095666\n",
      "\n",
      "Test set: Average loss: 1.9334, Accuracy: 7530/10000 (75%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.1548, Accuracy: 9591/10000 (96%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, epochs + 1):\n",
    "    train(model_classification, device, train_loader, optimizer, epoch)\n",
    "    test(model_classification, model, device, test_loader)\n",
    "    test(model_classification, model_old, device, test_loader)\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([], <a list of 0 Text yticklabel objects>)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(example_data[10][0], cmap='gray', interpolation='none')\n",
    "plt.title(\"Ground Truth: {}\".format(example_targets[0]))\n",
    "plt.xticks([])\n",
    "plt.yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[15],\n",
       "        [25],\n",
       "        [34],\n",
       "        [38],\n",
       "        [39],\n",
       "        [42],\n",
       "        [44],\n",
       "        [53]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(example_targets == 6).nonzero().data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 31.5, 31.5, -0.5)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAAC2CAYAAAB6fF5CAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAASTUlEQVR4nO3de4zWVX7H8c9hgEEc7veLiAasIgXUegNjvbAxi1YjEl1Xt5s2TTTrNjWy2cZ229puXZOtNW2q2zbpynaDrlZI1WpNx2hgdd0VpV5RRlRYbgUBZ1Cug3j6x+9hM7/z/Q7zzDBz5vZ+JZNwvpzneX4zc+Y7vznf55wTYowCAOQxoLsvAAD6E5IuAGRE0gWAjEi6AJARSRcAMiLpAkBG/TbphhA2hRAWduPrbw0hXNZdr4++i7Hds3VZ0g0hfC2E8GoIYX8I4ZPKv78VQghd9ZqdIYTwXAhhX+XjSAihuUX7Xzr4nMtDCPd08nWODyH8LISwN4TQGEL4aWc+/3Fe93dCCC9Vvh47QgjfzvG6PQlju/ScjO12GtgVTxpCWCrpu5LukPQ/kvZJmifpO5J+LOmw85iaGOPRrrie9ogxfvXYv0MIP5G0Ncb4vdb6hxAGxhi/yHFtiackvSTpFEkHJc2u9oEhhDGS9rb3ukMI4yX9t6Q/kbRS0hBJk9vzHL0dYzuLvj22Y4yd+iFphKT9km5oo99PJP1z5RPdL2lh5bE/lbRL0q8lfU/SgEr/eyQtb/H46ZKipIGV9ipJ35f0C0mfS6qXNLZF/29UnnOPpD+XtEnSwiqu8W+T2MLKY/9M0g5JyyT9kaRVLfoMrFzbdEnfknREUrOKH9D/rPTZKukuSe9I2ivpZ5Jqq/waL5L00bGvTQe+R7dUrv3vJJ3djsf9UNKyzh4zveWDsc3Y7oyPrpheuFhSrYrfVm35uqR7JQ2T9LKkf1IxOE+X9LuSfl/SH7Tjtb9e6T9e0mAVdx8KIcxS8UPwDRW/vcZImtqO501NlVQnaZqKgdeqGOOPJD0u6QcxxroY4/Ut/vtGSV9R8fmeV7k+hRBqQghNIYSLWnnaiyQ1SFoeQtgTQlgTQrik2ouPMT5Sed0Bkl6o/Hl8ewhhZBsPvUhSUwjhV5U/q58KIZzI17G3YWy3wNjumK5IumMl7Y4tbu9DCK9UvtAHQwiXtuj7VIzxFzHGL1X8xvyapLtjjJ/HGDdJ+ntVvllVWhZj/CDGeFDSf6j4s0+Slkh6Jsb48xjjYUl/IenLDn+G0heS7okxNldeq6P+Ica4I8a4R9Izx643xng0xjgyxvirVh43VdJXVfx5O1HSP0p6OoQwutoXjjG+E2NcWnmu76tylxNCeDSEUHec1/2mih/GaZK2SXqk2tfsAxjb1WNst6Irku4eSWNDCL+ZL44xzo8xjqz8X8vX3NLi32MlDVLxZ9Ixv5Y0pR2vvaPFvw+o+I0tFXcAv3mtGOP+yrV01M4YY/MJPP6Y1q63LQclfRhj/PcY45HKb/edKu7ESkII32xRLPmv9P8rCeQdSW9KalIxfzboOK+7Msb4vzHGQ5L+WtKlxxnIfQ1ju3qM7VZ0RdL9pYpiwnVV9G25xdluFXcEp7aIHfuNIxVzY0Nb/N/EdlzT/6mYlJckhRCGqvgzrKPSrdnaurbO3srtbec53deoDN66ysfvHYuHEIaFEP4whLBK0loV17wkxjgnxthY5evG1l63j2JsM7ZPWKcn3Rhjk4rfEj8KISypfAEGhBDmSTr5OI87quLPpnsrjzlVxWT88kqXN1X85pkWQhgh6e52XNYKSdeEEC4JIQyW9Dfq3M/9LUlzQgi/HUI4SdJfJf+/U8XcVmdZKWlCCOGWyhzZTSrm+n5ZzYNDCFer+IFfIukhSVNijN+OMb7exkOXSVoSQpgTQhikohi0Osa4r8OfSS/C2GZsd4YueZ9ujPGHKgbVd1V8U3ZK+ldJfyrpleM89I9V/Gb9WEXx4VFJD1ee83kVk/Zvq/jt9Uw7rmedirf4PKrizqBRRYW1U8QY35P0AxVV5gZJP0+6/JukuZX3HK5o6/kqg21fCMH8SVV5vd0q7rbuVlEd/o6ka2OMn1Z5ye9L+q0Y46IY4xOVucA2xRjrJf2lpOckfaLizu3WKl+zT2BsM7ZPVIixP/11CADdq98uAwaA7kDSBYCMSLoAkBFJFwAyIukCQEbH3WUshMBbG9ClYozdsh1ifxjbwdlpkncr5dPa2OZOFwAyIukCQEYkXQDIqEtOjujtvLkwLzZgQPl31sCB9st5+LBdhci8GrpCOh5ra2tNn5qaGhNrbrabih05cqTUZsx2Hu50ASAjki4AZETSBYCMSLoAkFG/L6R5BbJBg+yJHiNH2nPtrr/++lL7jDPOMH3uvfdeE2tstJvXU6hAe3jjdsKECaX2/PnzTZ+5c+ea2P79+01sxYry1ribN282fdJiG6rDnS4AZETSBYCMSLoAkBFzus7cmPem8iuuuMLEli5dWmp7817jxo0zsX377Fl33hvUgdZ4ixxGjx5das+cOdP0WbBggYnt3bvXxFavXl1qb9++3fRhTrdjuNMFgIxIugCQEUkXADIi6QJARv2ukJYWzrydwbzi1+LFi9vs19TUZPoMGzasvZcItMkrAI8dO7bUnjVrlukzceJEE9u1a5eJpUVhimadhztdAMiIpAsAGZF0ASAjki4AZNTvCmmDBw8utU877TTT54477jCxhQsXmtiBAwdK7fvvv9/0Wbt2rYmxoxhOlDeG0li665jk76C3bds2E0vH9tGjR9t7iWgFd7oAkBFJFwAyIukCQEYkXQDIqE8X0rxVO+n2dzfddJPps2jRIhPzVpZ9+OGHpfYTTzxh+lA0Q1eoZlx5Y9b7mdi0aZOJHTp0qN2vh+pwpwsAGZF0ASAjki4AZNSn53Tr6upM7Oyzzy61vd3DhgwZYmL19fUmlj6WeS/k4h3XM2nSpFJ7zJgxpo+3q543p8uuYl2HO10AyIikCwAZkXQBICOSLgBk1KcLaV5h66qrriq10+KDJJ100kkmtmXLFhM7fPjwCVwd0HEDBtj7peHDh5fa3kKId99918TefPNNE2NXsa7DnS4AZETSBYCMSLoAkBFJFwAy6jOFNK+wMG3aNBNLj+f54osvTB/v+BLvKB6gu3gry9Lxnh5NJUlNTU0mRtEsL+50ASAjki4AZETSBYCMSLoAkFGfKaR5q29mzJhhYul2d+mxJJL07LPPmtjGjRtP4OqAzlVbW2ti6Xj3fiY+/fRTE+vqlZXedaS8Qni1W6V++eWX7b6m7sSdLgBkRNIFgIxIugCQEUkXADLqM4U071yzCy+80MQmTJhQau/bt8/02bBhg4lx/hl6kmHDhpnYlClT2nyct0XpwYMHO3QNXvFr6NChJuZtlTpq1KhSe/To0abP7t27TWzPnj0m9vnnn5tYusquJ/38cqcLABmRdAEgI5IuAGTUZ+Z0x40bZ2LeLmPpXE9DQ4Pp8+KLL5pYT3gDtvcmc2++7MiRIybm7STVEz4ntM37vo8dO7bNmDeP6S3y8cZLypu/raurM7F0Fz9JmjVrlonNnTu31B4/frzp09jYaGKrVq0ysddff93E0vlgbzfB7prn5U4XADIi6QJARiRdAMiIpAsAGfWZQpq3OGL48OEmlh5zsmbNGtPHO66nM3mFEe/4lbS44BUpJk+ebGLeG8i9z+mDDz4otSms9R7eeE+Lpd6iB2/BgSctnJ188smmj7f46JprrjGxc88918TS6/cKXV7MK7h5X4v6+vpS+7PPPjN9ugt3ugCQEUkXADIi6QJARiRdAMiozxTSvKLB4MGDTSyddPd2GfNWt3lFpmp2Z/IKZLNnzzaxG2+80cQuu+yyUtsrIhw4cMDEvJ2kvGNa7rvvvlJ7/fr1pg/Fte7nFV69XcZqampKbW9seOPR+zlJX/Piiy82fe666y4T81afea/Z1NRUan/yySemj1e8u+SSS0zMO7po7dq1pbb3c+6t0syBO10AyIikCwAZkXQBICOSLgBk1GcKaVOnTjWxiRMnmlg6Oe8dL+JN/J966qkmlk7gX3vttVU9buHChVX1S1V7VMmcOXNMzFvdc8stt5TaDzzwgOnjFeB60tEn/YG3raI33tNtPr0tG73tGL2CVfr8d955p+lzwQUXmJhXnHr//fdNbPXq1aX2Rx99ZPrMmzfPxK6++moTO/30001s5MiRpbZXXKaQBgD9AEkXADIi6QJARr1yTteb4/Lmb705rfQN496bpr05Xe94lHTe64YbbjB9vKOlvef35rTSnZGefPJJ08d7U/mSJUvavFZJOvPMM0vt9Hh6Sdq7d6+JefPD6H7puPK+T4MGDTIxb2ynY/n88883fbw50ZdeesnEHn74YRN74403Sm1vAYi3MOfyyy83MW9xRPp86cIRqbpjiroCd7oAkBFJFwAyIukCQEYkXQDIqFcW0jyHDh0ysfTN4pItwnlH4HiFhcWLF5tYWrxL35At+W/Kfvrpp00sfbO4JL399tultlcYSXcia41XfEx5xxt5O1BRSOt+XmEo/RnwvnfeQgKvIJYeseMtiHnllVdMzFtgk45jSWpubi61R40aZfqMGTPGxLzFTOmxU5LU2NhYavek3fK40wWAjEi6AJARSRcAMiLpAkBGvbKQ5k3qr1u3zsS2bt1qYukxJ3PnzjV9vBVj3lE56eoebxewlStXmtiDDz5oYt7Kr3TFjFdE8AqIaRFBkqZNm2Zihw8fLrV3795t+qBn8o6KSlcwesVTr9g7ffp0E0sLdQ0NDaaPt0Jy48aNJuYVsdIin7fL3nXXXWdiI0aMMLHNmzebWPr1oZAGAP0USRcAMiLpAkBGJF0AyKjPFNK8LQ7r6+tNLF115RXI0u0fJWnbtm0mlha6vKNtNmzYYGLe8SjVrPy69NJLTZ+lS5dW9VzVHKOyf//+Nq8B+XlFIG+8DxkypNT2VhjOnj3bxLZv325iaZHVK5Bt2rTJxLztEr2VoZMmTSq1b775ZtPnrLPOMrFdu3aZmLfCs6mpqdTurqN5PNzpAkBGJF0AyIikCwAZkXQBIKNeWUjzeCuzXnjhBRNLt230zjUbN26ciXmrvHbs2FFqe9sz7ty508S8VXBe0SP9nG699VbTx9uqzzv37eOPPzax9957r83HUUjrmbzxnhaAvTHlrfzyzidLC2Leqi+voH3KKaeYmFesXrRoUal95ZVXmj5eQXv58uUm9uqrr5pYWgj0rrW7cKcLABmRdAEgI5IuAGTUZ+Z0vTeQe2/6TufC0iN3JLt7mOTPe6W8XZ1mzJhhYt6OX97uT3V1daW2d63egobnnnvOxB577DETe+2110ptbw6tJ+3O1F953wPviJp0IY43XqZMmWJi3txvNYsLvEU+3hE73oKMdO7X29nv5ZdfNrHHH3/cxLwd+nryuOVOFwAyIukCQEYkXQDIiKQLABn1mUKaJy0GSLZ4lB5xIvm7IqVFLcke/eMtVPCKa95OTOmbuSX7hm5vocWKFStMbNmyZSbm7UqVXkdPegM5js8bt6tWrSq1vaLZOeecY2KTJ082sXQXMK/PvHnzTMwrpHk/T+lCnDVr1pg+Dz30kIl5izR60g5i1eBOFwAyIukCQEYkXQDIiKQLABmF4xVPQgi9urLirSJLC2K33Xab6TN//nwT83ZnSndP8opt3kqb5uZmE/OKfm+99Vap/cgjj5g+3pFE3m5hPbVIFmNse6lfF+jtY9sbV+kKNG/nrttvv93EvGNxRowYUWp748cbx54tW7aY2MqVK0ttb/ewhoYGE/OK0D1Va2ObO10AyIikCwAZkXQBICOSLgBk1KcLaZ60uOZtqTh69GgTmz59uomdd955pXZtbW1V1+AdgZOulJPs9n3eVpW9/TgdCmkd4xWJ0+Kad0yOt83iggULTGzmzJml9tChQ00fr6i1bt06E3v++edNbP369aW2dxxWb1tplqKQBgA9AEkXADIi6QJARiRdAMio3xXSquGt9vFWpKWrdrzzyryVZgcPHjSx9Ow2yRbJevK5Tx1FIa3r1NTUmJg3tr0CcLolqbc9o/e4asd7WoTrT2ObO10AyIikCwAZkXQBICPmdDuRdzSP9/XtqTt+dQfmdPPyFlVUwxvbHm9utr+Od+Z0AaAHIOkCQEYkXQDIiKQLABnZd0qjw/riG7zRt3S0qNXbd/zqSbjTBYCMSLoAkBFJFwAyIukCQEYkXQDIiKQLABmRdAEgI5IuAGRE0gWAjEi6AJARSRcAMiLpAkBGJF0AyIikCwAZkXQBICOSLgBkRNIFgIxIugCQEUkXADIi6QJARiRdAMiIpAsAGZF0ASCjEGPs7msAgH6DO10AyIikCwAZkXQBICOSLgBkRNIFgIxIugCQ0f8DGUy/b2SjYeoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 34\n",
    "recon_img,_,_ = model(torch.FloatTensor(example_data[i]).unsqueeze(0).to(device))\n",
    "recon_img_old,_,_ = model_old(torch.FloatTensor(example_data[i]).unsqueeze(0).to(device))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(recon_img[0][0].detach().cpu().numpy(), cmap='gray', interpolation='none')\n",
    "plt.title(\"Ground Truth: {} -> {}\".format(example_targets[i], torch.argmax(model_classification(recon_img)).item()))\n",
    "plt.axis('off')\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(recon_img_old[0][0].detach().cpu().numpy(), cmap='gray', interpolation='none')\n",
    "plt.title(\"Ground Truth: {} -> {}\".format(example_targets[i], torch.argmax(model_classification(recon_img_old)).item()))\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseDiscriminator(nn.Module):\n",
    "    def __init__(self, image_size):\n",
    "        super(SiameseDiscriminator, self).__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(1, 4, kernel_size=3),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.BatchNorm2d(4),\n",
    "            nn.Dropout2d(p=.2),\n",
    "\n",
    "            nn.Conv2d(4, 8, kernel_size=3),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.Dropout2d(p=.2),\n",
    "\n",
    "            nn.Conv2d(8, 8, kernel_size=3),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.Dropout2d(p=.2)\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(8 * 26 * 26, 500),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "\n",
    "            nn.Linear(500, 500),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "\n",
    "            nn.Linear(500, 15)\n",
    "        )\n",
    "    \n",
    "    def forward_once(self, x):\n",
    "        \"\"\"Define the computation performed at every call by one side of siamese network.\"\"\"\n",
    "#         x = x_.unsqueeze(0)\n",
    "#         print(x.shape)\n",
    "        output = self.cnn(x)\n",
    "        output = output.view(output.size()[0], -1)\n",
    "        output = self.fc(output)\n",
    "        return output\n",
    "    \n",
    "    def forward(self, input1, input2):\n",
    "        \"\"\"Define the computation performed at every call.\"\"\"\n",
    "        output1 = self.forward_once(input1)\n",
    "        output2 = self.forward_once(input2)\n",
    "        return output1, output2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseLoss(nn.Module):\n",
    "    def __init__(self, margin):\n",
    "        super(Loss, self).__init__()\n",
    "        self.margin = margin\n",
    "    \n",
    "    def forward(self, output1, output2, label):\n",
    "        \"\"\"Define the computation performed at every call.\"\"\"\n",
    "        euclidean_distance = F.pairwise_distance(output1, output2)\n",
    "        distance_from_margin = torch.clamp(torch.pow(euclidean_distance, 2) - self.margin, max=50.0)\n",
    "        exp_distance_from_margin = torch.exp(distance_from_margin)\n",
    "        distance_based_loss = (1.0 + math.exp(-self.margin)) / (1.0 + exp_distance_from_margin)\n",
    "        similar_loss = -0.5 * (1 - label) * torch.log(distance_based_loss)\n",
    "        dissimilar_loss = -0.5 * label * torch.log(1.0 - distance_based_loss)\n",
    "        return torch.mean(similar_loss + dissimilar_loss)\n",
    "    \n",
    "    def predict(self, output1, output2, threshold_factor=0.5):\n",
    "        \"\"\"Predict a dissimilarity label given two embeddings.\n",
    "        Return `1` if dissimilar.\n",
    "        \"\"\"\n",
    "        return F.pairwise_distance(output1, output2) > self.margin * threshold_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistanceBasedLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Distance based loss function.\n",
    "    For reference see:\n",
    "    Hadsell et al., CVPR'06\n",
    "    Chopra et al., CVPR'05\n",
    "    Vo and Hays, ECCV'16\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, margin):\n",
    "        \"\"\"Set parameters of distance-based loss function.\"\"\"\n",
    "        super(DistanceBasedLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, output1, output2, label):\n",
    "        \"\"\"Define the computation performed at every call.\"\"\"\n",
    "        euclidean_distance = F.pairwise_distance(output1, output2)\n",
    "        distance_from_margin = torch.clamp(torch.pow(euclidean_distance, 2) - self.margin, max=50.0)\n",
    "        exp_distance_from_margin = torch.exp(distance_from_margin)\n",
    "        distance_based_loss = (1.0 + math.exp(-self.margin)) / (1.0 + exp_distance_from_margin)\n",
    "        similar_loss = -0.5 * (1 - label) * torch.log(distance_based_loss)\n",
    "        dissimilar_loss = -0.5 * label * torch.log(1.0 - distance_based_loss)\n",
    "        return torch.mean(similar_loss + dissimilar_loss)\n",
    "\n",
    "    def predict(self, output1, output2, threshold_factor=0.5):\n",
    "        \"\"\"Predict a dissimilarity label given two embeddings.\n",
    "        Return `1` if dissimilar.\n",
    "        \"\"\"\n",
    "        return F.pairwise_distance(output1, output2) > self.margin * threshold_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastiveLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Contrastive loss function.\n",
    "    Based on: http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, margin):\n",
    "        \"\"\"Set parameters of contrastive loss function.\"\"\"\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, output1, output2, label):\n",
    "        \"\"\"Define the computation performed at every call.\"\"\"\n",
    "        euclidean_distance = F.pairwise_distance(output1, output2)\n",
    "        clamped = torch.clamp(self.margin - euclidean_distance, min=0.0)\n",
    "        similar_loss = (1 - label) * 0.5 * torch.pow(euclidean_distance, 2)\n",
    "        dissimilar_loss = label * 0.5 * torch.pow(clamped, 2)\n",
    "        contrastive_loss = similar_loss + dissimilar_loss\n",
    "\n",
    "        return torch.mean(contrastive_loss)\n",
    "\n",
    "    def predict(self, output1, output2, threshold_factor=0.5):\n",
    "        \"\"\"Predict a dissimilarity label given two embeddings.\n",
    "        Return `1` if dissimilar.\n",
    "        \"\"\"\n",
    "        return F.pairwise_distance(output1, output2) > self.margin * threshold_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import exp\n",
    "\n",
    "\n",
    "def gaussian(window_size, sigma):\n",
    "    \"\"\"Compute gaussian window, that is a tensor with values of the bell curve.\"\"\"\n",
    "    gauss = torch.Tensor(\n",
    "        [exp(-(x - window_size//2)**2/float(2*sigma**2)) for x in range(window_size)])\n",
    "    return gauss/gauss.sum()\n",
    "\n",
    "\n",
    "def create_window(window_size, channel):\n",
    "    \"\"\"Generate a two dimensional window with desired number of channels.\"\"\"\n",
    "    _1D_window = gaussian(window_size, 1.5).unsqueeze(1)\n",
    "    _2D_window = _1D_window.mm(_1D_window.t()).float().unsqueeze(0).unsqueeze(0)\n",
    "    window = torch.Tensor(_2D_window.expand(channel, 1, window_size, window_size).contiguous())\n",
    "    return window\n",
    "\n",
    "\n",
    "def _ssim(img1, img2, window, window_size, channel, size_average=True):\n",
    "    \"\"\"Compute the structural similarity index between two images.\"\"\"\n",
    "    mu1 = F.conv2d(img1, window, padding=window_size//2, groups=channel)\n",
    "    mu2 = F.conv2d(img2, window, padding=window_size//2, groups=channel)\n",
    "\n",
    "    mu1_sq = mu1.pow(2)\n",
    "    mu2_sq = mu2.pow(2)\n",
    "    mu1_mu2 = mu1*mu2\n",
    "\n",
    "    sigma1_sq = F.conv2d(img1*img1, window, padding=window_size//2, groups=channel) - mu1_sq\n",
    "    sigma2_sq = F.conv2d(img2*img2, window, padding=window_size//2, groups=channel) - mu2_sq\n",
    "    sigma12 = F.conv2d(img1*img2, window, padding=window_size//2, groups=channel) - mu1_mu2\n",
    "\n",
    "    C1 = 0.01**2\n",
    "    C2 = 0.03**2\n",
    "\n",
    "    ssim_map = ((2*mu1_mu2 + C1)*(2*sigma12 + C2))/((mu1_sq + mu2_sq + C1) *\n",
    "                                                    (sigma1_sq + sigma2_sq + C2))\n",
    "\n",
    "    if size_average:\n",
    "        return ssim_map.mean()\n",
    "    else:\n",
    "        return ssim_map.mean(1).mean(1).mean(1)\n",
    "\n",
    "\n",
    "class SSIM(nn.Module):\n",
    "    \"\"\"Wrapper class used to compute the structural similarity index.\"\"\"\n",
    "\n",
    "    def __init__(self, window_size=11, size_average=True):\n",
    "        super(SSIM, self).__init__()\n",
    "        self.window_size = window_size\n",
    "        self.size_average = size_average\n",
    "        self.channel = 1\n",
    "        self.window = create_window(window_size, self.channel)\n",
    "\n",
    "    def forward(self, img1, img2):\n",
    "        \"\"\"Execute the computation of the structural similarity index.\"\"\"\n",
    "        (_, channel, _, _) = img1.size()\n",
    "\n",
    "        if channel == self.channel and self.window.data.type() == img1.data.type():\n",
    "            window = self.window\n",
    "        else:\n",
    "            window = create_window(self.window_size, channel)\n",
    "\n",
    "            if img1.is_cuda:\n",
    "                window = window.cuda(img1.get_device())\n",
    "            window = window.type_as(img1)\n",
    "\n",
    "            self.window = window\n",
    "            self.channel = channel\n",
    "\n",
    "        return _ssim(img1, img2, window, self.window_size, channel, self.size_average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data.sampler import BatchSampler\n",
    "\n",
    "\n",
    "class SiameseMNIST(Dataset):\n",
    "    \"\"\"\n",
    "    Train: For each sample creates randomly a positive or a negative pair\n",
    "    Test: Creates fixed pairs for testing\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, mnist_dataset):\n",
    "        self.mnist_dataset = mnist_dataset\n",
    "\n",
    "        self.train = self.mnist_dataset.train\n",
    "        self.transform = self.mnist_dataset.transform\n",
    "\n",
    "        if self.train:\n",
    "            self.train_labels = self.mnist_dataset.targets\n",
    "            self.train_data = self.mnist_dataset.data\n",
    "            self.labels_set = set(self.train_labels.numpy())\n",
    "            self.label_to_indices = {label: np.where(self.train_labels.numpy() == label)[0]\n",
    "                                     for label in self.labels_set}\n",
    "        else:\n",
    "            # generate fixed pairs for testing\n",
    "            self.test_labels = self.mnist_dataset.targets\n",
    "            self.test_data = self.mnist_dataset.data\n",
    "            self.labels_set = set(self.test_labels.numpy())\n",
    "            self.label_to_indices = {label: np.where(self.test_labels.numpy() == label)[0]\n",
    "                                     for label in self.labels_set}\n",
    "\n",
    "            random_state = np.random.RandomState(29)\n",
    "\n",
    "            positive_pairs = [[i,\n",
    "                               random_state.choice(self.label_to_indices[self.test_labels[i].item()]),\n",
    "                               1]\n",
    "                              for i in range(0, len(self.test_data), 2)]\n",
    "\n",
    "            negative_pairs = [[i,\n",
    "                               random_state.choice(self.label_to_indices[\n",
    "                                                       np.random.choice(\n",
    "                                                           list(self.labels_set - set([self.test_labels[i].item()]))\n",
    "                                                       )\n",
    "                                                   ]),\n",
    "                               0]\n",
    "                              for i in range(1, len(self.test_data), 2)]\n",
    "            self.test_pairs = positive_pairs + negative_pairs\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.train:\n",
    "            target = np.random.randint(0, 2)\n",
    "            img1, label1 = self.train_data[index], self.train_labels[index].item()\n",
    "            if target == 1:\n",
    "                siamese_index = index\n",
    "                while siamese_index == index:\n",
    "                    siamese_index = np.random.choice(self.label_to_indices[label1])\n",
    "            else:\n",
    "                siamese_label = np.random.choice(list(self.labels_set - set([label1])))\n",
    "                siamese_index = np.random.choice(self.label_to_indices[siamese_label])\n",
    "            img2 = self.train_data[siamese_index]\n",
    "        else:\n",
    "            img1 = self.test_data[self.test_pairs[index][0]]\n",
    "            img2 = self.test_data[self.test_pairs[index][1]]\n",
    "            target = self.test_pairs[index][2]\n",
    "\n",
    "        img1 = Image.fromarray(img1.numpy(), mode='L')\n",
    "        img2 = Image.fromarray(img2.numpy(), mode='L')\n",
    "        if self.transform is not None:\n",
    "            img1 = self.transform(img1)\n",
    "            img2 = self.transform(img2)\n",
    "        return torch.FloatTensor([target]), img1, img2\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.mnist_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_siamese_dataset = SiameseMNIST(mnist_dataset)\n",
    "mnist_siamese_dataset_test = SiameseMNIST(mnist_dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    def __init__(self, image_size=32, mode='train', model_path='./model/Siamese', \n",
    "                 generate_path='./Generated', num_epochs=100, distance_weight=1.0, \n",
    "                 dataset='MNIST', tensorboard=True, generator=model, batch_size=64, batch_size_test=1000):\n",
    "        self.mode = mode\n",
    "        self.image_size = image_size\n",
    "        self.model_path = model_path\n",
    "        self.generate_path = generate_path\n",
    "        self.dataset = dataset\n",
    "        self.num_epochs = num_epochs\n",
    "        self.distance_weight = distance_weight\n",
    "        self.tensorboard = tensorboard\n",
    "        self.generator = generator\n",
    "        self.batch_size = batch_size\n",
    "        self.batch_size_test = batch_size_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "class SiameseGanSolver(object):\n",
    "    \"\"\"Solving GAN-like neural network with siamese discriminator.\"\"\"\n",
    "\n",
    "    def __init__(self, config, data_loader):\n",
    "        \"\"\"Set parameters of neural network and its training.\"\"\"\n",
    "        self.ssim_loss = SSIM()\n",
    "        self.generator = config.generator\n",
    "        self.discriminator = None\n",
    "        self.distance_based_loss = None\n",
    "\n",
    "        self.g_optimizer = None\n",
    "        self.d_optimizer = None\n",
    "\n",
    "        self.g_conv_dim = 128\n",
    "\n",
    "        self.beta1 = 0.9\n",
    "        self.beta2 = 0.999\n",
    "        self.learning_rate = 0.0001\n",
    "        self.image_size = config.image_size\n",
    "        self.num_epochs = config.num_epochs\n",
    "        self.distance_weight = config.distance_weight\n",
    "\n",
    "        self.data_loader = data_loader\n",
    "#         print(self.data_loader.dataset)\n",
    "        self.generate_path = config.generate_path\n",
    "        self.model_path = config.model_path\n",
    "        self.tensorboard = config.tensorboard\n",
    "\n",
    "        if self.tensorboard:\n",
    "            self.tb_writer = tensorboardX.SummaryWriter(\n",
    "                filename_suffix='_%s_%s' % (config.distance_weight, config.dataset))\n",
    "            self.tb_graph_added = False\n",
    "\n",
    "        self.build_model()\n",
    "\n",
    "    def build_model(self):\n",
    "        \"\"\"Build generator and discriminator.\"\"\"\n",
    "#         self.generator = Generator(self.g_conv_dim, noise=self.noise, residual=self.residual)\n",
    "        self.discriminator = SiameseDiscriminator(self.image_size)\n",
    "        self.distance_based_loss = DistanceBasedLoss(2.0)\n",
    "\n",
    "        self.g_optimizer = torch.optim.Adam(\n",
    "            self.generator.parameters(), self.learning_rate, [self.beta1, self.beta2])\n",
    "        self.d_optimizer = torch.optim.Adam(\n",
    "            self.discriminator.parameters(), self.learning_rate, [self.beta1, self.beta2])\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            self.generator.cuda()\n",
    "            self.discriminator.cuda()\n",
    "            self.distance_based_loss.cuda()\n",
    "\n",
    "    def train(self):\n",
    "        \"\"\"Train generator and discriminator in minimax game.\"\"\"\n",
    "        # Prepare tensorboard writer\n",
    "        if self.tensorboard:\n",
    "            step = 0\n",
    "        \n",
    "        print(\"We are training\\n\")\n",
    "\n",
    "        for epoch in tqdm(range(self.num_epochs)):\n",
    "            print(str(epoch) + \" \" + str(datetime.now()))\n",
    "#             i = 0\n",
    "            for label, images0, images1 in self.data_loader:\n",
    "#                 i += 1\n",
    "#                 print(i)\n",
    "                images0 = to_variable(images0)\n",
    "                images1 = to_variable(images1)\n",
    "#                 print(\"label:\", label)\n",
    "                label = to_variable(label)\n",
    "#                 print(\"We extracted samples\")\n",
    "                # Train discriminator to recognize identity of real images\n",
    "                output0, output1 = self.discriminator(images0, images1)\n",
    "                d_real_loss = self.distance_based_loss(output0, output1, label)\n",
    "#                 print(\"We calculated loss\")\n",
    "                # Backpropagation\n",
    "                self.distance_based_loss.zero_grad()\n",
    "                self.discriminator.zero_grad()\n",
    "                d_real_loss.backward()\n",
    "                self.d_optimizer.step()\n",
    "#                 print(\"We did backprop\")\n",
    "                # Train discriminator to recognize identity of fake(privatized) images\n",
    "                \n",
    "                privatized_imgs, _, _ = self.generator(images0)\n",
    "#                 print(privatized_imgs)\n",
    "                output0, output1 = self.discriminator(images0, privatized_imgs)\n",
    "\n",
    "                # Discriminator wants to minimize Euclidean distance between\n",
    "                # original & privatized versions, hence label = 0\n",
    "                d_fake_loss = self.distance_based_loss(output0, output1, 0)\n",
    "                distance = 1.0 - self.ssim_loss(privatized_imgs, images0)\n",
    "                d_fake_loss += self.distance_weight * distance\n",
    "#                 print(\"We calculated loss\")\n",
    "                # Backpropagation\n",
    "                self.distance_based_loss.zero_grad()\n",
    "                self.discriminator.zero_grad()\n",
    "                self.generator.zero_grad()\n",
    "                d_fake_loss.backward()\n",
    "                self.d_optimizer.step()\n",
    "\n",
    "                # Train generator to fool discriminator\n",
    "                # Generator wants to push the distance between original & privatized\n",
    "                # right to the margin, hence label = 1\n",
    "                privatized_imgs, _, _ = self.generator(images0)\n",
    "                output0, output1 = self.discriminator(images0, privatized_imgs)\n",
    "                g_loss = self.distance_based_loss(output0, output1, 1)\n",
    "                distance = 1.0 - self.ssim_loss(privatized_imgs, images0)\n",
    "                g_loss += self.distance_weight * distance\n",
    "#                 print(\"We calculated loss\")\n",
    "                # Backpropagation\n",
    "                self.distance_based_loss.zero_grad()\n",
    "                self.discriminator.zero_grad()\n",
    "                self.generator.zero_grad()\n",
    "                g_loss.backward()\n",
    "                self.g_optimizer.step()\n",
    "\n",
    "                # Write losses to tensorboard\n",
    "                if self.tensorboard:\n",
    "                    self.tb_writer.add_scalar('phase0/discriminator_real_loss',\n",
    "                                              d_real_loss.item(), step)\n",
    "                    self.tb_writer.add_scalar('phase0/discriminator_fake_loss',\n",
    "                                              d_fake_loss.item(), step)\n",
    "                    self.tb_writer.add_scalar('phase0/generator_loss',\n",
    "                                              g_loss.item(), step)\n",
    "                    self.tb_writer.add_scalar('phase0/distance_loss',\n",
    "                                              distance.item(), step)\n",
    "\n",
    "                    step += 1\n",
    "\n",
    "            # Monitor training after each epoch\n",
    "            if self.tensorboard:\n",
    "                self._monitor_phase_0(self.tb_writer, step)\n",
    "\n",
    "            # At the end save generator and discriminator to files\n",
    "            if (epoch + 1) % 10 == 0:\n",
    "                g_path = os.path.join(self.model_path, 'G', 'G-%d.pt' % (epoch+1))\n",
    "                torch.save(self.generator.state_dict(), g_path)\n",
    "                d_path = os.path.join(self.model_path, 'D', 'D-%d.pt' % (epoch+1))\n",
    "                torch.save(self.discriminator.state_dict(), d_path)\n",
    "\n",
    "        if self.tensorboard:\n",
    "            self.tb_writer.close()\n",
    "\n",
    "    def _monitor_phase_0(self, writer, step, n_images=10):\n",
    "        # Measure accuracy of identity verification by discriminator\n",
    "        correct_pairs = 0\n",
    "        total_pairs = 0\n",
    "\n",
    "        for label, images0, images1 in self.data_loader:\n",
    "            images0 = to_variable(images0)\n",
    "            images1 = to_variable(images1)\n",
    "            label = to_variable(label)\n",
    "\n",
    "            # Predict label = 1 if outputs are dissimilar (distance > margin)\n",
    "            privatized_images0, _, _ = self.generator(images0)\n",
    "            output0, output1 = self.discriminator(privatized_images0, images1)\n",
    "            predictions = self.distance_based_loss.predict(output0, output1)\n",
    "            predictions = predictions.type(label.data.type())\n",
    "\n",
    "            correct_pairs += (predictions == label).sum().item()\n",
    "            total_pairs += len(predictions == label)\n",
    "\n",
    "            if total_pairs > 1000:\n",
    "                break\n",
    "\n",
    "        # Write accuracy to tensorboard\n",
    "        accuracy = correct_pairs / total_pairs\n",
    "        writer.add_scalar('phase0/discriminator_accuracy', accuracy, step)\n",
    "\n",
    "        # Generate previews of privatized images\n",
    "        reals, fakes = [], []\n",
    "        for _, image, _ in self.data_loader.dataset:\n",
    "#             print(\"i: \", image.shape)\n",
    "            g_image, _, _ = self.generator(to_variable(image).unsqueeze(0))\n",
    "            g_image = g_image.squeeze(0)\n",
    "#             print(\"g: \", g_image.shape)\n",
    "            reals.append(denorm(to_variable(image).data[0]))\n",
    "            fakes.append(denorm(to_variable(g_image).data[0]))\n",
    "            if len(reals) == n_images:\n",
    "                break\n",
    "\n",
    "        # Write images to tensorboard\n",
    "        real_previews = torchvision.utils.make_grid(reals, nrow=n_images)\n",
    "        fake_previews = torchvision.utils.make_grid(fakes, nrow=n_images)\n",
    "#         print(real_previews.shape)\n",
    "#         print(fake_previews.shape)\n",
    "#         img = torchvision.utils.make_grid([real_previews, fake_previews], nrow=1)\n",
    "        img = torchvision.utils.make_grid(torch.stack(\n",
    "            [*real_previews.unsqueeze_(1).unbind(0), *fake_previews.unsqueeze_(1).unbind(0)]), nrow=1)\n",
    "        writer.add_image('Previews', img, step)\n",
    "\n",
    "    def generate(self):\n",
    "        \"\"\"Generate privatized images.\"\"\"\n",
    "        # Load trained parameters (generator)\n",
    "        g_path = os.path.join(self.model_path, 'G', 'G-%d.pkl' % self.num_epochs)\n",
    "        self.generator.load_state_dict(torch.load(g_path))\n",
    "        self.generator.eval()\n",
    "\n",
    "        # Generate the images\n",
    "        for relative_path, image in self.data_loader:\n",
    "            fake_image, _, _ = self.generator(to_variable(image))\n",
    "            fake_path = os.path.join(self.generate_path, relative_path[0])\n",
    "            if not os.path.exists(os.path.dirname(fake_path)):\n",
    "                os.makedirs(os.path.dirname(fake_path))\n",
    "            torchvision.utils.save_image(fake_image.data, fake_path, nrow=1)\n",
    "\n",
    "    def check_discriminator_accuracy(self):\n",
    "        \"\"\"Measure discriminator's accuracy.\"\"\"\n",
    "        # Measure accuracy of identity verification by discriminator\n",
    "        correct_pairs = 0\n",
    "        total_pairs = 0\n",
    "\n",
    "        g_path = os.path.join(self.model_path, 'G', 'G-%d.pkl' % self.num_epochs)\n",
    "        self.generator.load_state_dict(torch.load(g_path))\n",
    "        self.generator.eval()\n",
    "\n",
    "        d_path = os.path.join(self.model_path, 'D', 'D-%d.pkl' % self.num_epochs)\n",
    "        self.discriminator.load_state_dict(torch.load(d_path))\n",
    "        self.discriminator.eval()\n",
    "\n",
    "        for label, images0, images1 in self.data_loader:\n",
    "            images0 = to_variable(images0)\n",
    "            images1 = to_variable(images1)\n",
    "            label = to_variable(label)\n",
    "\n",
    "            # Predict label = 1 if outputs are dissimilar (distance > margin)\n",
    "            privatized_images0, _, _ = self.generator(images0)\n",
    "            output0, output1 = self.discriminator(privatized_images0, images1)\n",
    "            predictions = self.distance_based_loss.predict(output0, output1)\n",
    "            predictions = predictions.type(label.data.type())\n",
    "\n",
    "            correct_pairs += (predictions == label).sum().item()\n",
    "            total_pairs += len(predictions)\n",
    "\n",
    "        accuracy = correct_pairs / total_pairs\n",
    "        print('distance weight = %f' % self.distance_weight)\n",
    "        print('accuracy = %f' % accuracy)\n",
    "        \n",
    "def to_variable(tensor):\n",
    "    \"\"\"Convert tensor to variable.\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        tensor = tensor.cuda()\n",
    "    return tensor\n",
    "\n",
    "def denorm(image):\n",
    "    \"\"\"Convert image range (-1, 1) to (0, 1).\"\"\"\n",
    "    out = (image + 1) / 2\n",
    "    return out.clamp(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, time\n",
    "import tensorboardX, math, os\n",
    "from torch.utils.data import DataLoader\n",
    "config = Config(num_epochs=200, tensorboard=True)\n",
    "siamese_data_loader = DataLoader(dataset=mnist_siamese_dataset, batch_size=config.batch_size, shuffle=True)\n",
    "siamese_data_loader_test = DataLoader(dataset=mnist_siamese_dataset_test, batch_size=config.batch_size_test, shuffle=True)\n",
    "solver = SiameseGanSolver(config, siamese_data_loader)\n",
    "date1 = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are training\n",
      "\n",
      "0 2020-01-08 01:44:04.899575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 1/200 [00:33<1:51:38, 33.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2020-01-08 01:44:38.560524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 2/200 [01:06<1:50:05, 33.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 2020-01-08 01:45:11.221317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|         | 3/200 [01:39<1:49:04, 33.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 2020-01-08 01:45:44.111432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|         | 4/200 [02:12<1:48:07, 33.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 2020-01-08 01:46:16.936330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|         | 5/200 [02:45<1:47:35, 33.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 2020-01-08 01:46:50.042478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|         | 6/200 [03:18<1:46:47, 33.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 2020-01-08 01:47:22.901138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|         | 7/200 [03:51<1:46:14, 33.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 2020-01-08 01:47:55.935386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|         | 8/200 [04:24<1:45:47, 33.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 2020-01-08 01:48:29.066377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|         | 9/200 [04:57<1:45:04, 33.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 2020-01-08 01:49:01.956709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|         | 10/200 [05:30<1:44:32, 33.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 2020-01-08 01:49:34.971979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|         | 11/200 [06:02<1:43:43, 32.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 2020-01-08 01:50:07.711168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|         | 12/200 [06:35<1:43:07, 32.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 2020-01-08 01:50:40.579261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|         | 13/200 [07:08<1:42:38, 32.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 2020-01-08 01:51:13.569443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|         | 14/200 [07:41<1:42:12, 32.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 2020-01-08 01:51:46.626990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|         | 15/200 [08:14<1:41:48, 33.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 2020-01-08 01:52:19.747666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|         | 16/200 [08:47<1:41:10, 32.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 2020-01-08 01:52:52.688507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|         | 17/200 [09:20<1:40:31, 32.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 2020-01-08 01:53:25.571720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|         | 18/200 [09:53<1:40:04, 32.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 2020-01-08 01:53:58.643569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|         | 19/200 [10:26<1:39:40, 33.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 2020-01-08 01:54:31.786962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|         | 20/200 [10:59<1:39:00, 33.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 2020-01-08 01:55:04.705307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|         | 21/200 [11:32<1:38:24, 32.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 2020-01-08 01:55:37.660721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|         | 22/200 [12:05<1:37:40, 32.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22 2020-01-08 01:56:10.438154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|        | 23/200 [12:38<1:37:13, 32.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23 2020-01-08 01:56:43.479663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|        | 24/200 [13:11<1:36:42, 32.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 2020-01-08 01:57:16.471608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|        | 25/200 [13:44<1:36:07, 32.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 2020-01-08 01:57:49.394318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|        | 26/200 [14:17<1:35:32, 32.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 2020-01-08 01:58:22.317230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|        | 27/200 [14:50<1:35:12, 33.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27 2020-01-08 01:58:55.511346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|        | 28/200 [15:23<1:34:29, 32.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28 2020-01-08 01:59:28.340799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|        | 29/200 [15:56<1:33:52, 32.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 2020-01-08 02:00:01.229470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|        | 30/200 [16:29<1:33:16, 32.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 2020-01-08 02:00:34.110291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|        | 31/200 [17:02<1:32:44, 32.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31 2020-01-08 02:01:07.038482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|        | 32/200 [17:35<1:32:14, 32.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 2020-01-08 02:01:40.025042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|        | 33/200 [18:08<1:31:44, 32.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 2020-01-08 02:02:13.025186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|        | 34/200 [18:41<1:31:12, 32.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34 2020-01-08 02:02:46.006875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|        | 35/200 [19:14<1:30:37, 32.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35 2020-01-08 02:03:18.942217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|        | 36/200 [19:47<1:30:07, 32.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36 2020-01-08 02:03:51.941646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|        | 37/200 [20:20<1:30:14, 33.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37 2020-01-08 02:04:25.742217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|        | 38/200 [20:54<1:29:46, 33.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38 2020-01-08 02:04:59.071379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|        | 39/200 [21:27<1:28:55, 33.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39 2020-01-08 02:05:31.951310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|        | 40/200 [21:59<1:28:08, 33.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 2020-01-08 02:06:04.808875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|        | 41/200 [22:32<1:27:31, 33.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41 2020-01-08 02:06:37.771456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|        | 42/200 [23:05<1:26:49, 32.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42 2020-01-08 02:07:10.605725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|       | 43/200 [23:38<1:26:14, 32.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43 2020-01-08 02:07:43.541911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|       | 44/200 [24:11<1:25:38, 32.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44 2020-01-08 02:08:16.440746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|       | 45/200 [24:44<1:25:08, 32.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45 2020-01-08 02:08:49.445433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|       | 46/200 [25:17<1:24:41, 33.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46 2020-01-08 02:09:22.536467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|       | 47/200 [25:50<1:24:11, 33.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47 2020-01-08 02:09:55.597640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|       | 48/200 [26:23<1:23:44, 33.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48 2020-01-08 02:10:28.730750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|       | 49/200 [26:56<1:23:07, 33.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49 2020-01-08 02:11:01.700073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|       | 50/200 [27:29<1:22:41, 33.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 2020-01-08 02:11:34.885616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|       | 51/200 [28:02<1:21:57, 33.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51 2020-01-08 02:12:07.722990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|       | 52/200 [28:35<1:21:19, 32.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52 2020-01-08 02:12:40.616298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|       | 53/200 [29:08<1:20:50, 33.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53 2020-01-08 02:13:13.680602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|       | 54/200 [29:41<1:20:19, 33.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54 2020-01-08 02:13:46.729399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|       | 55/200 [30:14<1:19:37, 32.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55 2020-01-08 02:14:19.521385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|       | 56/200 [30:47<1:19:15, 33.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56 2020-01-08 02:14:52.729519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|       | 57/200 [31:20<1:18:37, 32.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57 2020-01-08 02:15:25.636449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|       | 58/200 [31:53<1:18:14, 33.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58 2020-01-08 02:15:58.854019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|       | 59/200 [32:26<1:17:39, 33.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59 2020-01-08 02:16:31.878979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|       | 60/200 [32:59<1:17:03, 33.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60 2020-01-08 02:17:04.839160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|       | 61/200 [33:33<1:16:37, 33.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61 2020-01-08 02:17:38.033546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|       | 62/200 [34:06<1:15:55, 33.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62 2020-01-08 02:18:10.906724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|      | 63/200 [34:38<1:15:20, 32.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63 2020-01-08 02:18:43.853739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|      | 64/200 [35:11<1:14:45, 32.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64 2020-01-08 02:19:16.797828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|      | 65/200 [35:44<1:14:13, 32.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65 2020-01-08 02:19:49.798867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|      | 66/200 [36:18<1:13:45, 33.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66 2020-01-08 02:20:22.911608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|      | 67/200 [36:50<1:13:10, 33.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67 2020-01-08 02:20:55.890708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|      | 68/200 [37:24<1:12:39, 33.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68 2020-01-08 02:21:28.961909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|      | 69/200 [37:57<1:12:05, 33.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69 2020-01-08 02:22:01.965210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|      | 70/200 [38:29<1:11:27, 32.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70 2020-01-08 02:22:34.859040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|      | 71/200 [39:02<1:10:48, 32.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71 2020-01-08 02:23:07.667341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|      | 72/200 [39:35<1:10:07, 32.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72 2020-01-08 02:23:40.400964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|      | 73/200 [40:08<1:09:30, 32.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73 2020-01-08 02:24:13.166686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|      | 74/200 [40:41<1:09:07, 32.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74 2020-01-08 02:24:46.272445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|      | 75/200 [41:14<1:08:29, 32.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75 2020-01-08 02:25:19.039867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|      | 76/200 [41:47<1:08:02, 32.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76 2020-01-08 02:25:52.086580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|      | 77/200 [42:19<1:07:23, 32.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77 2020-01-08 02:26:24.845551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 39%|      | 78/200 [42:52<1:06:49, 32.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78 2020-01-08 02:26:57.685959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|      | 79/200 [43:25<1:06:21, 32.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79 2020-01-08 02:27:30.697898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|      | 80/200 [43:58<1:05:50, 32.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80 2020-01-08 02:28:03.634666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|      | 81/200 [44:31<1:05:24, 32.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81 2020-01-08 02:28:36.756096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|      | 82/200 [45:04<1:04:55, 33.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82 2020-01-08 02:29:09.843776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|     | 83/200 [45:38<1:04:24, 33.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83 2020-01-08 02:29:42.903604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|     | 84/200 [46:11<1:03:52, 33.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84 2020-01-08 02:30:15.976379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|     | 85/200 [46:43<1:03:15, 33.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85 2020-01-08 02:30:48.887460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|     | 86/200 [47:17<1:02:45, 33.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86 2020-01-08 02:31:21.972244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|     | 87/200 [47:49<1:02:04, 32.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87 2020-01-08 02:31:54.786710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|     | 88/200 [48:23<1:01:44, 33.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88 2020-01-08 02:32:28.134304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|     | 89/200 [48:56<1:01:11, 33.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89 2020-01-08 02:33:01.198906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|     | 90/200 [49:29<1:00:35, 33.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90 2020-01-08 02:33:34.183401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|     | 91/200 [50:02<59:57, 33.00s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91 2020-01-08 02:34:07.087283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|     | 92/200 [50:35<59:21, 32.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92 2020-01-08 02:34:39.985643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|     | 93/200 [51:07<58:39, 32.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93 2020-01-08 02:35:12.696877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|     | 94/200 [51:40<58:04, 32.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94 2020-01-08 02:35:45.525819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|     | 95/200 [52:13<57:39, 32.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95 2020-01-08 02:36:18.655764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|     | 96/200 [52:46<57:13, 33.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96 2020-01-08 02:36:51.833094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|     | 97/200 [53:20<56:43, 33.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97 2020-01-08 02:37:24.927463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 49%|     | 98/200 [53:53<56:13, 33.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98 2020-01-08 02:37:58.065073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|     | 99/200 [54:26<55:34, 33.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 2020-01-08 02:38:30.959219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|     | 100/200 [54:58<54:57, 32.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 2020-01-08 02:39:03.825927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|     | 101/200 [55:31<54:22, 32.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101 2020-01-08 02:39:36.740851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 51%|     | 102/200 [56:04<53:47, 32.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102 2020-01-08 02:40:09.639718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|    | 103/200 [56:37<53:12, 32.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103 2020-01-08 02:40:42.503158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|    | 104/200 [57:10<52:41, 32.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104 2020-01-08 02:41:15.484275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|    | 105/200 [57:43<52:13, 32.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105 2020-01-08 02:41:48.584191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|    | 106/200 [58:16<51:42, 33.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106 2020-01-08 02:42:21.629806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|    | 107/200 [58:49<51:04, 32.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107 2020-01-08 02:42:54.451663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|    | 108/200 [59:22<50:27, 32.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108 2020-01-08 02:43:27.275413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|    | 109/200 [59:55<49:54, 32.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109 2020-01-08 02:44:00.178297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|    | 110/200 [1:00:28<49:26, 32.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110 2020-01-08 02:44:33.253960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|    | 111/200 [1:01:01<48:48, 32.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111 2020-01-08 02:45:06.046824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|    | 112/200 [1:01:34<48:19, 32.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112 2020-01-08 02:45:39.077641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|    | 113/200 [1:02:07<47:46, 32.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113 2020-01-08 02:46:12.046001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|    | 114/200 [1:02:40<47:15, 32.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114 2020-01-08 02:46:45.051098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|    | 115/200 [1:03:13<46:39, 32.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115 2020-01-08 02:47:17.921720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|    | 116/200 [1:03:46<46:11, 33.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116 2020-01-08 02:47:51.058226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|    | 117/200 [1:04:18<45:33, 32.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117 2020-01-08 02:48:23.836901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|    | 118/200 [1:04:51<45:02, 32.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118 2020-01-08 02:48:56.850938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|    | 119/200 [1:05:25<44:33, 33.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119 2020-01-08 02:49:29.970278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|    | 120/200 [1:05:57<43:57, 32.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 2020-01-08 02:50:02.857625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|    | 121/200 [1:06:31<43:28, 33.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121 2020-01-08 02:50:36.008361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 61%|    | 122/200 [1:07:04<42:56, 33.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122 2020-01-08 02:51:09.041908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|   | 123/200 [1:07:37<42:22, 33.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123 2020-01-08 02:51:42.025319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|   | 124/200 [1:08:10<41:46, 32.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124 2020-01-08 02:52:14.943538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|   | 125/200 [1:08:43<41:16, 33.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125 2020-01-08 02:52:48.036175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|   | 126/200 [1:09:15<40:39, 32.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126 2020-01-08 02:53:20.869772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|   | 127/200 [1:09:48<40:02, 32.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127 2020-01-08 02:53:53.653790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|   | 128/200 [1:10:21<39:30, 32.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128 2020-01-08 02:54:26.588988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|   | 129/200 [1:10:54<38:58, 32.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129 2020-01-08 02:54:59.593461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|   | 130/200 [1:11:27<38:24, 32.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130 2020-01-08 02:55:32.444685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|   | 131/200 [1:12:00<37:53, 32.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131 2020-01-08 02:56:05.458295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|   | 132/200 [1:12:33<37:20, 32.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132 2020-01-08 02:56:38.393528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|   | 133/200 [1:13:06<36:47, 32.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133 2020-01-08 02:57:11.348483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|   | 134/200 [1:13:39<36:15, 32.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134 2020-01-08 02:57:44.368676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|   | 135/200 [1:14:12<35:42, 32.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135 2020-01-08 02:58:17.327096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|   | 136/200 [1:14:45<35:10, 32.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136 2020-01-08 02:58:50.353192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|   | 137/200 [1:15:18<34:39, 33.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137 2020-01-08 02:59:23.435848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|   | 138/200 [1:15:51<34:11, 33.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138 2020-01-08 02:59:56.706643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|   | 139/200 [1:16:24<33:34, 33.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139 2020-01-08 03:00:29.582830\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|   | 140/200 [1:16:57<33:01, 33.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140 2020-01-08 03:01:02.614676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|   | 141/200 [1:17:30<32:29, 33.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141 2020-01-08 03:01:35.684263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|   | 142/200 [1:18:03<31:53, 33.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142 2020-01-08 03:02:08.576745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|  | 143/200 [1:18:36<31:21, 33.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143 2020-01-08 03:02:41.635631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|  | 144/200 [1:19:09<30:45, 32.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144 2020-01-08 03:03:14.473282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|  | 145/200 [1:19:42<30:14, 32.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145 2020-01-08 03:03:47.528872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|  | 146/200 [1:20:15<29:39, 32.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146 2020-01-08 03:04:20.407484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|  | 147/200 [1:20:48<29:07, 32.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147 2020-01-08 03:04:53.401991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|  | 148/200 [1:21:21<28:35, 32.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148 2020-01-08 03:05:26.454577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|  | 149/200 [1:21:54<28:04, 33.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149 2020-01-08 03:05:59.583645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|  | 150/200 [1:22:27<27:33, 33.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150 2020-01-08 03:06:32.750563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|  | 151/200 [1:23:00<26:59, 33.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151 2020-01-08 03:07:05.731338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|  | 152/200 [1:23:33<26:23, 32.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152 2020-01-08 03:07:38.592296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|  | 153/200 [1:24:06<25:48, 32.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153 2020-01-08 03:08:11.450399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|  | 154/200 [1:24:39<25:17, 32.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "154 2020-01-08 03:08:44.545019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|  | 155/200 [1:25:12<24:44, 32.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155 2020-01-08 03:09:17.490521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|  | 156/200 [1:25:45<24:12, 33.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156 2020-01-08 03:09:50.549283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|  | 157/200 [1:26:18<23:40, 33.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157 2020-01-08 03:10:23.662962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 79%|  | 158/200 [1:26:51<23:04, 32.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158 2020-01-08 03:10:56.495261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|  | 159/200 [1:27:24<22:34, 33.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159 2020-01-08 03:11:29.648953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|  | 160/200 [1:27:57<21:58, 32.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160 2020-01-08 03:12:02.464786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|  | 161/200 [1:28:30<21:26, 32.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161 2020-01-08 03:12:35.463064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 81%|  | 162/200 [1:29:03<20:53, 32.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162 2020-01-08 03:13:08.502575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%| | 163/200 [1:29:36<20:19, 32.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163 2020-01-08 03:13:41.350913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%| | 164/200 [1:30:09<19:44, 32.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164 2020-01-08 03:14:14.177903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%| | 165/200 [1:30:42<19:12, 32.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165 2020-01-08 03:14:47.184337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%| | 166/200 [1:31:15<18:39, 32.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166 2020-01-08 03:15:20.070448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%| | 167/200 [1:31:48<18:09, 33.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167 2020-01-08 03:15:53.309940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%| | 168/200 [1:32:21<17:37, 33.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168 2020-01-08 03:16:26.416096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%| | 169/200 [1:32:54<17:04, 33.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169 2020-01-08 03:16:59.501225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%| | 170/200 [1:33:27<16:32, 33.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170 2020-01-08 03:17:32.596001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%| | 171/200 [1:34:00<15:58, 33.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171 2020-01-08 03:18:05.603810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%| | 172/200 [1:34:33<15:25, 33.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172 2020-01-08 03:18:38.613430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%| | 173/200 [1:35:06<14:50, 32.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "173 2020-01-08 03:19:11.485561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%| | 174/200 [1:35:39<14:15, 32.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174 2020-01-08 03:19:44.241583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%| | 175/200 [1:36:12<13:43, 32.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175 2020-01-08 03:20:17.165760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%| | 176/200 [1:36:45<13:10, 32.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176 2020-01-08 03:20:50.211083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%| | 177/200 [1:37:18<12:38, 32.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177 2020-01-08 03:21:23.228233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 89%| | 178/200 [1:37:51<12:04, 32.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178 2020-01-08 03:21:56.116291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%| | 179/200 [1:38:24<11:32, 32.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179 2020-01-08 03:22:29.133712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%| | 180/200 [1:38:57<10:59, 32.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180 2020-01-08 03:23:02.142103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%| | 181/200 [1:39:30<10:26, 32.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "181 2020-01-08 03:23:35.055152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%| | 182/200 [1:40:03<09:54, 33.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182 2020-01-08 03:24:08.219678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|| 183/200 [1:40:36<09:20, 32.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183 2020-01-08 03:24:41.075341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|| 184/200 [1:41:09<08:47, 32.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184 2020-01-08 03:25:13.965233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|| 185/200 [1:41:42<08:14, 32.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185 2020-01-08 03:25:46.964998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|| 186/200 [1:42:14<07:40, 32.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186 2020-01-08 03:26:19.740111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|| 187/200 [1:42:48<07:08, 32.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187 2020-01-08 03:26:52.903909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|| 188/200 [1:43:21<06:36, 33.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188 2020-01-08 03:27:25.992882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|| 189/200 [1:43:54<06:03, 33.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189 2020-01-08 03:27:59.128834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|| 190/200 [1:44:27<05:30, 33.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190 2020-01-08 03:28:32.114168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|| 191/200 [1:45:00<04:57, 33.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191 2020-01-08 03:29:05.191473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|| 192/200 [1:45:33<04:24, 33.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192 2020-01-08 03:29:38.252497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|| 193/200 [1:46:06<03:51, 33.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193 2020-01-08 03:30:11.355976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|| 194/200 [1:46:39<03:18, 33.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "194 2020-01-08 03:30:44.553778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|| 195/200 [1:47:12<02:45, 33.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195 2020-01-08 03:31:17.447486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|| 196/200 [1:47:45<02:12, 33.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196 2020-01-08 03:31:50.500911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|| 197/200 [1:48:18<01:39, 33.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "197 2020-01-08 03:32:23.589050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 99%|| 198/200 [1:48:51<01:06, 33.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198 2020-01-08 03:32:56.684654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|| 199/200 [1:49:24<00:33, 33.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199 2020-01-08 03:33:29.762776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 200/200 [1:49:57<00:00, 32.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 54min 55s, sys: 1min 40s, total: 1h 56min 36s\n",
      "Wall time: 1h 49min 57s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "solver.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi, Ujjwal. The training has been completed. It took approx 0 days, 1 hours, 49 minutes, 57 seconds\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
