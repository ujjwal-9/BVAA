{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch import nn\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "mnist_dataset = datasets.MNIST('../../data', \n",
    "                   train=True, \n",
    "                   download=True, \n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.Resize(32),\n",
    "                       transforms.ToTensor()\n",
    "                   ]))\n",
    "\n",
    "mnist_dataset_test = datasets.MNIST('../../data', train=False, download=True, transform=transforms.Compose([\n",
    "                       transforms.Resize(32),\n",
    "                       transforms.ToTensor()\n",
    "                   ]))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(mnist_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(mnist_dataset_test, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Encoder(nn.Module):\n",
    "#     def __init__(self, x_size, h_size, z_size):\n",
    "#         super(Encoder, self).__init__()\n",
    "#         self.fc1 = nn.Linear(x_size, h_size)\n",
    "#         self.mu_gen = nn.Linear(h_size, z_size)\n",
    "#         # make the output to be the logarithm \n",
    "#         # i.e will have to take the exponent\n",
    "#         # which forces variance to be positive\n",
    "#         # not that this is the diagonal of the covariance\n",
    "#         self.log_var_gen = nn.Linear(h_size, z_size)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = F.relu(self.fc1(x))\n",
    "#         mu = self.mu_gen(x)\n",
    "#         log_var = self.log_var_gen(x)\n",
    "#         return mu, log_var\n",
    "    \n",
    "class Encoder(nn.Module):\n",
    "    r\"\"\"\n",
    "    References:\n",
    "            [1] Burgess, Christopher P., et al. \"Understanding disentangling in\n",
    "            $\\beta$-VAE.\" arXiv preprint arXiv:1804.03599 (2018).\n",
    "    \"\"\"\n",
    "    def __init__(self, img_size, latent_dim=10):\n",
    "\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        hidden_channels = 32\n",
    "        kernel_size = 4\n",
    "        hidden_dim = 256\n",
    "\n",
    "        self.latent_dim = latent_dim\n",
    "        self.img_size = img_size\n",
    "\n",
    "        self.reshape = (hidden_channels, kernel_size, kernel_size)\n",
    "\n",
    "        n_channels = self.img_size[0]\n",
    "\n",
    "        cnn_kwargs = dict(stride=2, padding=1)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(n_channels, hidden_channels, kernel_size, **cnn_kwargs)\n",
    "        self.conv2 = nn.Conv2d(hidden_channels, hidden_channels, kernel_size, **cnn_kwargs)\n",
    "        self.conv3 = nn.Conv2d(hidden_channels, hidden_channels, kernel_size, **cnn_kwargs)\n",
    "\n",
    "        if self.img_size[1] == self.img_size[2] == 64:\n",
    "            self.conv_64 = nn.Conv2d(hidden_channels, hidden_channels, kernel_size, **cnn_kwargs)\n",
    "\n",
    "        self.lin1 = nn.Linear(np.product(self.reshape), hidden_dim)\n",
    "        self.lin2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "\n",
    "        self.mu_logvar_gen = nn.Linear(hidden_dim, self.latent_dim * 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = torch.relu(self.conv3(x))\n",
    "\n",
    "        if self.img_size[1] == self.img_size[2] == 64:\n",
    "            x = torch.relu(self.conv_64(x))\n",
    "\n",
    "        x = x.view((batch_size, -1))\n",
    "        x = torch.relu(self.lin1(x))\n",
    "        x = torch.relu(self.lin2(x))\n",
    "\n",
    "        mu_logvar = self.mu_logvar_gen(x)\n",
    "\n",
    "        mu, logvar = mu_logvar.view(-1, self.latent_dim, 2).unbind(-1)\n",
    "\n",
    "        return mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Decoder(nn.Module):\n",
    "#     def __init__(self, x_size, h_size, z_size):\n",
    "#         super(Decoder, self).__init__()\n",
    "#         self.fc1 = nn.Linear(z_size, h_size)\n",
    "#         self.fc3 = nn.Linear(h_size, x_size)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = F.relu(self.fc1(x))\n",
    "#         x = F.relu(self.fc3(x))\n",
    "#         # black and white MNIST => sigmoid for each pixel\n",
    "#         x = torch.sigmoid(x) \n",
    "#         return x\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    r\"\"\"\n",
    "    References:\n",
    "            [1] Burgess, Christopher P., et al. \"Understanding disentangling in\n",
    "            $\\beta$-VAE.\" arXiv preprint arXiv:1804.03599 (2018).\n",
    "    \"\"\"\n",
    "    def __init__(self, img_size, latent_dim):\n",
    "\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        hidden_channels = 32\n",
    "        kernel_size = 4\n",
    "        hidden_dim = 256\n",
    "\n",
    "        self.img_size = img_size\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "        self.reshape = (hidden_channels, kernel_size, kernel_size)\n",
    "\n",
    "        n_channels = self.img_size[0]\n",
    "\n",
    "        self.lin1 = nn.Linear(latent_dim, hidden_dim)\n",
    "        self.lin2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.lin3 = nn.Linear(hidden_dim, np.product(self.reshape))\n",
    "\n",
    "        cnn_kwargs = dict(stride=2, padding=1)\n",
    "\n",
    "        if self.img_size[1] == self.img_size[2] == 64:\n",
    "            self.convT_64 = nn.ConvTranspose2d(hidden_channels, hidden_channels, kernel_size, **cnn_kwargs)\n",
    "\n",
    "        self.convT1 = nn.ConvTranspose2d(hidden_channels, hidden_channels, kernel_size, **cnn_kwargs)\n",
    "        self.convT2 = nn.ConvTranspose2d(hidden_channels, hidden_channels, kernel_size, **cnn_kwargs)\n",
    "        self.convT3 = nn.ConvTranspose2d(hidden_channels, n_channels, kernel_size, **cnn_kwargs)\n",
    "\n",
    "    def forward(self, z):\n",
    "        batch_size = z.size(0)\n",
    "\n",
    "        x = torch.relu(self.lin1(z))\n",
    "        x = torch.relu(self.lin2(x))\n",
    "        x = torch.relu(self.lin3(x))\n",
    "\n",
    "        x = x.view(batch_size, *self.reshape)\n",
    "\n",
    "        if self.img_size[1] == self.img_size[2] == 64:\n",
    "            x = torch.relu(self.convT_64(x))\n",
    "\n",
    "        x = torch.relu(self.convT1(x))\n",
    "        x = torch.relu(self.convT2(x))\n",
    "\n",
    "        x = torch.sigmoid(self.convT3(x))\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class VAE(nn.Module):\n",
    "#     def __init__(self, x_size, h_size, z_size):\n",
    "#         super(VAE, self).__init__()\n",
    "#         self.x_size = x_size\n",
    "#         self.z_size = z_size\n",
    "#         self.encoder = Encoder(x_size, h_size, z_size)\n",
    "#         self.decoder = Decoder(x_size, h_size, z_size)\n",
    "\n",
    "#     def reparameterize(self, mu, log_var):\n",
    "#         std = torch.exp(0.5 * log_var) # square root in exponent => std\n",
    "#         eps = torch.randn_like(std)\n",
    "#         z = std * eps + mu\n",
    "#         return z\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         # make image linear (i.e vector form)\n",
    "#         x = x.view(-1, self.x_size)\n",
    "#         mu, log_var = self.encoder(x)\n",
    "#         z = self.reparameterize(mu, log_var)\n",
    "#         x_hat = self.decoder(z)\n",
    "#         return x_hat, mu, log_var\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, img_size, latent_dim):\n",
    "        super(VAE, self).__init__()\n",
    "        if list(img_size[1:]) not in [[32,32], [64,64]]:\n",
    "            raise RuntimeError(\"{} sized images not supported. Only (None, 32, 32) and (None, 64, 64) supported. Build your own architecture or reshape images!\".format(img_size))\n",
    "\n",
    "        self.latent_dim = latent_dim\n",
    "        self.img_size = img_size\n",
    "        self.num_pixels = self.img_size[1] * self.img_size[2]\n",
    "        self.encoder = Encoder(img_size, self.latent_dim)\n",
    "        self.decoder = Decoder(img_size, self.latent_dim)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reparameterize(self, mean, logvar):\n",
    "        if self.training:\n",
    "            std = torch.exp(0.5 * logvar)\n",
    "            eps = torch.randn_like(std)\n",
    "            return mean + std * eps\n",
    "\n",
    "        else:\n",
    "            return mean\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        latent_distribution = self.encoder(x)\n",
    "        latent_sample = self.reparameterize(*latent_distribution)\n",
    "        reconstruct = self.decoder(latent_sample)\n",
    "        return reconstruct, latent_distribution, latent_sample\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.apply(weights_init)\n",
    "\n",
    "    def sample_latent(self, x):\n",
    "        latent_distribution = self.encoder(x)\n",
    "        latent_sample = self.reparameterize(*latent_distribution)\n",
    "        return latent_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = enumerate(test_loader)\n",
    "batch_idx, (example_data, example_targets) = next(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "for i in range(6):\n",
    "    plt.subplot(2,3,i+1)\n",
    "    plt.tight_layout()\n",
    "    plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n",
    "    plt.title(\"Ground Truth: {}\".format(example_targets[i]))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(example_data[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_activation_name(activation):\n",
    "    \"\"\"Given a string or a `torch.nn.modules.activation` return the name of the activation.\"\"\"\n",
    "    if isinstance(activation, str):\n",
    "        return activation\n",
    "\n",
    "    mapper = {nn.LeakyReLU: \"leaky_relu\", nn.ReLU: \"relu\", nn.Tanh: \"tanh\",\n",
    "              nn.Sigmoid: \"sigmoid\", nn.Softmax: \"sigmoid\"}\n",
    "    for k, v in mapper.items():\n",
    "        if isinstance(activation, k):\n",
    "            return k\n",
    "\n",
    "    raise ValueError(\"Unkown given activation type : {}\".format(activation))\n",
    "\n",
    "\n",
    "def get_gain(activation):\n",
    "    \"\"\"Given an object of `torch.nn.modules.activation` or an activation name\n",
    "    return the correct gain.\"\"\"\n",
    "    if activation is None:\n",
    "        return 1\n",
    "\n",
    "    activation_name = get_activation_name(activation)\n",
    "\n",
    "    param = None if activation_name != \"leaky_relu\" else activation.negative_slope\n",
    "    gain = nn.init.calculate_gain(activation_name, param)\n",
    "\n",
    "    return gain\n",
    "def linear_init(layer, activation=\"relu\"):\n",
    "    \"\"\"Initialize a linear layer.\n",
    "    Args:\n",
    "        layer (nn.Linear): parameters to initialize.\n",
    "        activation (`torch.nn.modules.activation` or str, optional) activation that\n",
    "            will be used on the `layer`.\n",
    "    \"\"\"\n",
    "    x = layer.weight\n",
    "\n",
    "    if activation is None:\n",
    "        return nn.init.xavier_uniform_(x)\n",
    "\n",
    "    activation_name = get_activation_name(activation)\n",
    "\n",
    "    if activation_name == \"leaky_relu\":\n",
    "        a = 0 if isinstance(activation, str) else activation.negative_slope\n",
    "        return nn.init.kaiming_uniform_(x, a=a, nonlinearity='leaky_relu')\n",
    "    elif activation_name == \"relu\":\n",
    "        return nn.init.kaiming_uniform_(x, nonlinearity='relu')\n",
    "    elif activation_name in [\"sigmoid\", \"tanh\"]:\n",
    "        return nn.init.xavier_uniform_(x, gain=get_gain(activation))\n",
    "def weights_init(module):\n",
    "    if isinstance(module, nn.modules.conv._ConvNd):\n",
    "        # TO-DO: check litterature\n",
    "        linear_init(module)\n",
    "    elif isinstance(module, nn.Linear):\n",
    "        linear_init(module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = list(example_data[0].shape) # mnist image\n",
    "# h_size = 256\n",
    "z_size = 12\n",
    "model = VAE(img_size, z_size).to(device) # migrates to CUDA if you can"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_annealing(init, fin, step, annealing_steps):\n",
    "    \"\"\"Linear annealing of a parameter.\"\"\"\n",
    "    if annealing_steps == 0:\n",
    "        return fin\n",
    "    assert fin > init\n",
    "    delta = fin - init\n",
    "    annealed = min(init + delta * step / annealing_steps, fin)\n",
    "    return annealed\n",
    "\n",
    "def _kl_normal_loss(mean, logvar):\n",
    "    latent_dim = mean.size(1)\n",
    "    latent_kl = 0.5 * (-1 - logvar + mean.pow(2) + logvar.exp()).mean(dim=0)\n",
    "    total_kl = latent_kl.sum()\n",
    "\n",
    "    return total_kl\n",
    "\n",
    "def _reconstruction_loss(data, recon_data, distribution=\"bernoulli\"):\n",
    "    batch_size, n_channels, height, width = recon_data.size()\n",
    "    is_colored = n_channels == 3\n",
    "\n",
    "    if distribution == \"bernoulli\":\n",
    "        loss = F.binary_cross_entropy(recon_data, data, reduction=\"sum\")\n",
    "\n",
    "    elif distribution == \"gaussian\":\n",
    "        loss = F.mse_loss(recon_data * 255, data * 255, reduction=\"sum\") / 255\n",
    "\n",
    "    elif distribution == \"laplace\":\n",
    "        loss = F.l1_loss(recon_data, data, reduction=\"sum\")\n",
    "        loss = loss * 3\n",
    "        loss = loss * (loss != 0)\n",
    "\n",
    "    loss = loss / batch_size\n",
    "\n",
    "    return loss\n",
    "\n",
    "def loss_function(x_hat, x, mu, log_var, is_train, n_train_steps, steps_anneal=0, beta=1, C_init=0., C_fin=20., gamma=100.):\n",
    "    \"\"\"Compute the ELBO loss\"\"\"\n",
    "    x_size = x_hat.size(-1)\n",
    "    # black or white image => use sigmoid for each pixel\n",
    "#     rec_loss = F.binary_cross_entropy(x_hat, x.view(-1, x_size), reduction='sum')\n",
    "    rec_loss = _reconstruction_loss(x, x_hat, distribution=\"bernoulli\")\n",
    "    # closed form solution for gaussian prior and posterior\n",
    "#     kl_div = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "    kl_div = _kl_normal_loss(mu, log_var)\n",
    "    \n",
    "    C = (linear_annealing(C_init, C_fin, n_train_steps, steps_anneal) if is_train else C_fin)\n",
    "    vae_loss = rec_loss + gamma * (kl_div - C).abs()\n",
    "#     vae_loss = rec_loss + beta * kl_div\n",
    "    return vae_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, model, optimizer=optim.Adam, loss_function=loss_function):\n",
    "        self.model = model \n",
    "        self.optimizer = optimizer(self.model.parameters())\n",
    "        self.loss_function = loss_function\n",
    "        self.epoch = 0\n",
    "        \n",
    "    def __call__(self, train, test, n_epochs=100):\n",
    "        self.epoch = 0\n",
    "        for _ in range(n_epochs):\n",
    "            self._train_epoch(train)\n",
    "            self._test_epoch(test)\n",
    "            with torch.no_grad():\n",
    "                sample = torch.randn(64, self.model.latent_dim).to(device)\n",
    "                sample = model.decoder(sample).cpu()  # make sure on cpu\n",
    "                save_image(sample.view(64, 1, 32, 32),\n",
    "                           '../results/sample_' + str(self.epoch) + '.png')\n",
    "        \n",
    "    def _train_epoch(self, train):\n",
    "        self.epoch += 1\n",
    "        model.train() # make sure train mode (e.g. dropout)\n",
    "        train_loss = 0\n",
    "        for i, (x, _) in enumerate(train):\n",
    "            x = x.to(device) # data on GPU \n",
    "            self.optimizer.zero_grad() # reset all previous gradients\n",
    "            x_hat, latent_distribution, latent_sample = model(x)\n",
    "            loss = self.loss_function(x_hat, x, *latent_distribution, True, i)\n",
    "            loss.backward() # backpropagate (i.e store gradients)\n",
    "            train_loss += loss.item() # compute loss (.item because only the value)\n",
    "            self.optimizer.step() # take optimizing step (~gradient descent)\n",
    "\n",
    "        print('Epoch: {} Train loss: {:.4f}'.format(\n",
    "              self.epoch, train_loss / len(train.dataset)))\n",
    "        \n",
    "    def _test_epoch(self, test):\n",
    "        model.eval() # make sure evaluate mode (e.g. dropout)\n",
    "        test_loss = 0\n",
    "        with torch.no_grad():  # stop gradients computation\n",
    "            for i, (x, _) in enumerate(test):\n",
    "                x = x.to(device)\n",
    "                x_hat, latent_distribution, latent_sample = model(x)\n",
    "                test_loss += loss_function(x_hat, x, *latent_distribution, False, i).item()\n",
    "\n",
    "        print('Test loss: {:.4f}'.format(test_loss/len(test.dataset)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer = Trainer(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# trainer(train_loader, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), './model/betaVAE.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('./model/betaVAE.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import StepLR\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout2d(0.25)\n",
    "        self.dropout2 = nn.Dropout2d(0.5)\n",
    "        self.fc1 = nn.Linear(12544, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "#         data_hat,_,_ = vae_model(data)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, vae_model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            data_hat,_,_ = vae_model(data)\n",
    "            output = model(data_hat)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch_size = 1000\n",
    "batch_size = 64\n",
    "epochs = 2\n",
    "lr = 0.1\n",
    "gamma = 0.7\n",
    "seed = 1\n",
    "no_cuda = False\n",
    "log_interval = 1000\n",
    "save_model = True\n",
    "use_cuda = True\n",
    "torch.manual_seed(seed)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_classification = Net().to(device)\n",
    "optimizer = optim.Adadelta(model_classification.parameters(), lr=lr)\n",
    "\n",
    "scheduler = StepLR(optimizer, step_size=1, gamma=gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for epoch in range(1, epochs + 1):\n",
    "#     train(model_classification, device, train_loader, optimizer, epoch)\n",
    "#     test(model_classification, model, device, test_loader)\n",
    "#     scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseDiscriminator(nn.Module):\n",
    "    def __init__(self, image_size):\n",
    "        super(SiameseDiscriminator, self).__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(1, 4, kernel_size=3),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.BatchNorm2d(4),\n",
    "            nn.Dropout2d(p=.2),\n",
    "\n",
    "            nn.Conv2d(4, 8, kernel_size=3),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.Dropout2d(p=.2),\n",
    "\n",
    "            nn.Conv2d(8, 8, kernel_size=3),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.Dropout2d(p=.2)\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(8 * 26 * 26, 500),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "\n",
    "            nn.Linear(500, 500),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "\n",
    "            nn.Linear(500, 15)\n",
    "        )\n",
    "    \n",
    "    def forward_once(self, x):\n",
    "        \"\"\"Define the computation performed at every call by one side of siamese network.\"\"\"\n",
    "#         x = x_.unsqueeze(0)\n",
    "#         print(x.shape)\n",
    "        output = self.cnn(x)\n",
    "        output = output.view(output.size()[0], -1)\n",
    "        output = self.fc(output)\n",
    "        return output\n",
    "    \n",
    "    def forward(self, input1, input2):\n",
    "        \"\"\"Define the computation performed at every call.\"\"\"\n",
    "        output1 = self.forward_once(input1)\n",
    "        output2 = self.forward_once(input2)\n",
    "        return output1, output2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseLoss(nn.Module):\n",
    "    def __init__(self, margin):\n",
    "        super(Loss, self).__init__()\n",
    "        self.margin = margin\n",
    "    \n",
    "    def forward(self, output1, output2, label):\n",
    "        \"\"\"Define the computation performed at every call.\"\"\"\n",
    "        euclidean_distance = F.pairwise_distance(output1, output2)\n",
    "        distance_from_margin = torch.clamp(torch.pow(euclidean_distance, 2) - self.margin, max=50.0)\n",
    "        exp_distance_from_margin = torch.exp(distance_from_margin)\n",
    "        distance_based_loss = (1.0 + math.exp(-self.margin)) / (1.0 + exp_distance_from_margin)\n",
    "        similar_loss = -0.5 * (1 - label) * torch.log(distance_based_loss)\n",
    "        dissimilar_loss = -0.5 * label * torch.log(1.0 - distance_based_loss)\n",
    "        return torch.mean(similar_loss + dissimilar_loss)\n",
    "    \n",
    "    def predict(self, output1, output2, threshold_factor=0.5):\n",
    "        \"\"\"Predict a dissimilarity label given two embeddings.\n",
    "        Return `1` if dissimilar.\n",
    "        \"\"\"\n",
    "        return F.pairwise_distance(output1, output2) > self.margin * threshold_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistanceBasedLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Distance based loss function.\n",
    "    For reference see:\n",
    "    Hadsell et al., CVPR'06\n",
    "    Chopra et al., CVPR'05\n",
    "    Vo and Hays, ECCV'16\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, margin):\n",
    "        \"\"\"Set parameters of distance-based loss function.\"\"\"\n",
    "        super(DistanceBasedLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, output1, output2, label):\n",
    "        \"\"\"Define the computation performed at every call.\"\"\"\n",
    "        euclidean_distance = F.pairwise_distance(output1, output2)\n",
    "        distance_from_margin = torch.clamp(torch.pow(euclidean_distance, 2) - self.margin, max=50.0)\n",
    "        exp_distance_from_margin = torch.exp(distance_from_margin)\n",
    "        distance_based_loss = (1.0 + math.exp(-self.margin)) / (1.0 + exp_distance_from_margin)\n",
    "        similar_loss = -0.5 * (1 - label) * torch.log(distance_based_loss)\n",
    "        dissimilar_loss = -0.5 * label * torch.log(1.0 - distance_based_loss)\n",
    "        return torch.mean(similar_loss + dissimilar_loss)\n",
    "\n",
    "    def predict(self, output1, output2, threshold_factor=0.5):\n",
    "        \"\"\"Predict a dissimilarity label given two embeddings.\n",
    "        Return `1` if dissimilar.\n",
    "        \"\"\"\n",
    "        return F.pairwise_distance(output1, output2) > self.margin * threshold_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastiveLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Contrastive loss function.\n",
    "    Based on: http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, margin):\n",
    "        \"\"\"Set parameters of contrastive loss function.\"\"\"\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, output1, output2, label):\n",
    "        \"\"\"Define the computation performed at every call.\"\"\"\n",
    "        euclidean_distance = F.pairwise_distance(output1, output2)\n",
    "        clamped = torch.clamp(self.margin - euclidean_distance, min=0.0)\n",
    "        similar_loss = (1 - label) * 0.5 * torch.pow(euclidean_distance, 2)\n",
    "        dissimilar_loss = label * 0.5 * torch.pow(clamped, 2)\n",
    "        contrastive_loss = similar_loss + dissimilar_loss\n",
    "\n",
    "        return torch.mean(contrastive_loss)\n",
    "\n",
    "    def predict(self, output1, output2, threshold_factor=0.5):\n",
    "        \"\"\"Predict a dissimilarity label given two embeddings.\n",
    "        Return `1` if dissimilar.\n",
    "        \"\"\"\n",
    "        return F.pairwise_distance(output1, output2) > self.margin * threshold_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import exp\n",
    "\n",
    "\n",
    "def gaussian(window_size, sigma):\n",
    "    \"\"\"Compute gaussian window, that is a tensor with values of the bell curve.\"\"\"\n",
    "    gauss = torch.Tensor(\n",
    "        [exp(-(x - window_size//2)**2/float(2*sigma**2)) for x in range(window_size)])\n",
    "    return gauss/gauss.sum()\n",
    "\n",
    "\n",
    "def create_window(window_size, channel):\n",
    "    \"\"\"Generate a two dimensional window with desired number of channels.\"\"\"\n",
    "    _1D_window = gaussian(window_size, 1.5).unsqueeze(1)\n",
    "    _2D_window = _1D_window.mm(_1D_window.t()).float().unsqueeze(0).unsqueeze(0)\n",
    "    window = torch.Tensor(_2D_window.expand(channel, 1, window_size, window_size).contiguous())\n",
    "    return window\n",
    "\n",
    "\n",
    "def _ssim(img1, img2, window, window_size, channel, size_average=True):\n",
    "    \"\"\"Compute the structural similarity index between two images.\"\"\"\n",
    "    mu1 = F.conv2d(img1, window, padding=window_size//2, groups=channel)\n",
    "    mu2 = F.conv2d(img2, window, padding=window_size//2, groups=channel)\n",
    "\n",
    "    mu1_sq = mu1.pow(2)\n",
    "    mu2_sq = mu2.pow(2)\n",
    "    mu1_mu2 = mu1*mu2\n",
    "\n",
    "    sigma1_sq = F.conv2d(img1*img1, window, padding=window_size//2, groups=channel) - mu1_sq\n",
    "    sigma2_sq = F.conv2d(img2*img2, window, padding=window_size//2, groups=channel) - mu2_sq\n",
    "    sigma12 = F.conv2d(img1*img2, window, padding=window_size//2, groups=channel) - mu1_mu2\n",
    "\n",
    "    C1 = 0.01**2\n",
    "    C2 = 0.03**2\n",
    "\n",
    "    ssim_map = ((2*mu1_mu2 + C1)*(2*sigma12 + C2))/((mu1_sq + mu2_sq + C1) *\n",
    "                                                    (sigma1_sq + sigma2_sq + C2))\n",
    "\n",
    "    if size_average:\n",
    "        return ssim_map.mean()\n",
    "    else:\n",
    "        return ssim_map.mean(1).mean(1).mean(1)\n",
    "\n",
    "\n",
    "class SSIM(nn.Module):\n",
    "    \"\"\"Wrapper class used to compute the structural similarity index.\"\"\"\n",
    "\n",
    "    def __init__(self, window_size=11, size_average=True):\n",
    "        super(SSIM, self).__init__()\n",
    "        self.window_size = window_size\n",
    "        self.size_average = size_average\n",
    "        self.channel = 1\n",
    "        self.window = create_window(window_size, self.channel)\n",
    "\n",
    "    def forward(self, img1, img2):\n",
    "        \"\"\"Execute the computation of the structural similarity index.\"\"\"\n",
    "        (_, channel, _, _) = img1.size()\n",
    "\n",
    "        if channel == self.channel and self.window.data.type() == img1.data.type():\n",
    "            window = self.window\n",
    "        else:\n",
    "            window = create_window(self.window_size, channel)\n",
    "\n",
    "            if img1.is_cuda:\n",
    "                window = window.cuda(img1.get_device())\n",
    "            window = window.type_as(img1)\n",
    "\n",
    "            self.window = window\n",
    "            self.channel = channel\n",
    "\n",
    "        return _ssim(img1, img2, window, self.window_size, channel, self.size_average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_dataset_test.transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data.sampler import BatchSampler\n",
    "\n",
    "\n",
    "class SiameseMNIST(Dataset):\n",
    "    \"\"\"\n",
    "    Train: For each sample creates randomly a positive or a negative pair\n",
    "    Test: Creates fixed pairs for testing\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, mnist_dataset):\n",
    "        self.mnist_dataset = mnist_dataset\n",
    "\n",
    "        self.train = self.mnist_dataset.train\n",
    "        self.transform = self.mnist_dataset.transform\n",
    "\n",
    "        if self.train:\n",
    "            self.train_labels = self.mnist_dataset.targets\n",
    "            self.train_data = self.mnist_dataset.data\n",
    "            self.labels_set = set(self.train_labels.numpy())\n",
    "            self.label_to_indices = {label: np.where(self.train_labels.numpy() == label)[0]\n",
    "                                     for label in self.labels_set}\n",
    "        else:\n",
    "            # generate fixed pairs for testing\n",
    "            self.test_labels = self.mnist_dataset.targets\n",
    "            self.test_data = self.mnist_dataset.data\n",
    "            self.labels_set = set(self.test_labels.numpy())\n",
    "            self.label_to_indices = {label: np.where(self.test_labels.numpy() == label)[0]\n",
    "                                     for label in self.labels_set}\n",
    "\n",
    "            random_state = np.random.RandomState(29)\n",
    "\n",
    "            positive_pairs = [[i,\n",
    "                               random_state.choice(self.label_to_indices[self.test_labels[i].item()]),\n",
    "                               1]\n",
    "                              for i in range(0, len(self.test_data), 2)]\n",
    "\n",
    "            negative_pairs = [[i,\n",
    "                               random_state.choice(self.label_to_indices[\n",
    "                                                       np.random.choice(\n",
    "                                                           list(self.labels_set - set([self.test_labels[i].item()]))\n",
    "                                                       )\n",
    "                                                   ]),\n",
    "                               0]\n",
    "                              for i in range(1, len(self.test_data), 2)]\n",
    "            self.test_pairs = positive_pairs + negative_pairs\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.train:\n",
    "            target = np.random.randint(0, 2)\n",
    "            img1, label1 = self.train_data[index], self.train_labels[index].item()\n",
    "            if target == 1:\n",
    "                siamese_index = index\n",
    "                while siamese_index == index:\n",
    "                    siamese_index = np.random.choice(self.label_to_indices[label1])\n",
    "            else:\n",
    "                siamese_label = np.random.choice(list(self.labels_set - set([label1])))\n",
    "                siamese_index = np.random.choice(self.label_to_indices[siamese_label])\n",
    "            img2 = self.train_data[siamese_index]\n",
    "        else:\n",
    "            img1 = self.test_data[self.test_pairs[index][0]]\n",
    "            img2 = self.test_data[self.test_pairs[index][1]]\n",
    "            target = self.test_pairs[index][2]\n",
    "\n",
    "        img1 = Image.fromarray(img1.numpy(), mode='L')\n",
    "        img2 = Image.fromarray(img2.numpy(), mode='L')\n",
    "        if self.transform is not None:\n",
    "            img1 = self.transform(img1)\n",
    "            img2 = self.transform(img2)\n",
    "        return torch.FloatTensor([target]), img1.unsqueeze_(0), img2.unsqueeze_(0)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.mnist_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_siamese_dataloader = SiameseMNIST(mnist_dataset)\n",
    "mnist_siamese_dataloader_test = SiameseMNIST(mnist_dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    def __init__(self, image_size=32, mode='train', model_path='./model/', \n",
    "                 generate_path='./model/', num_epochs=100, distance_weight=1.0, dataset='MNIST', \n",
    "                 data_loader=mnist_siamese_dataloader, tensorboard=True, generator=model):\n",
    "        self.mode = mode\n",
    "        self.image_size = image_size\n",
    "        self.model_path = model_path\n",
    "        self.generate_path = generate_path\n",
    "        self.dataset = dataset\n",
    "        self.num_epochs = num_epochs\n",
    "        self.distance_weight = distance_weight\n",
    "        self.tensorboard = tensorboard\n",
    "        self.generator = generator\n",
    "        self.data_loader = data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "class SiameseGanSolver(object):\n",
    "    \"\"\"Solving GAN-like neural network with siamese discriminator.\"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        \"\"\"Set parameters of neural network and its training.\"\"\"\n",
    "        self.ssim_loss = SSIM()\n",
    "        self.generator = config.generator\n",
    "        self.discriminator = None\n",
    "        self.distance_based_loss = None\n",
    "\n",
    "        self.g_optimizer = None\n",
    "        self.d_optimizer = None\n",
    "\n",
    "        self.g_conv_dim = 128\n",
    "\n",
    "        self.beta1 = 0.9\n",
    "        self.beta2 = 0.999\n",
    "        self.learning_rate = 0.0001\n",
    "        self.image_size = config.image_size\n",
    "        self.num_epochs = config.num_epochs\n",
    "        self.distance_weight = config.distance_weight\n",
    "\n",
    "        self.data_loader = config.data_loader\n",
    "        self.generate_path = config.generate_path\n",
    "        self.model_path = config.model_path\n",
    "        self.tensorboard = config.tensorboard\n",
    "\n",
    "        if self.tensorboard:\n",
    "            self.tb_writer = tensorboardX.SummaryWriter(\n",
    "                filename_suffix='_%s_%s' % (config.distance_weight, config.dataset))\n",
    "            self.tb_graph_added = False\n",
    "\n",
    "        self.build_model()\n",
    "\n",
    "    def build_model(self):\n",
    "        \"\"\"Build generator and discriminator.\"\"\"\n",
    "#         self.generator = Generator(self.g_conv_dim, noise=self.noise, residual=self.residual)\n",
    "        self.discriminator = SiameseDiscriminator(self.image_size)\n",
    "        self.distance_based_loss = DistanceBasedLoss(2.0)\n",
    "\n",
    "        self.g_optimizer = torch.optim.Adam(\n",
    "            self.generator.parameters(), self.learning_rate, [self.beta1, self.beta2])\n",
    "        self.d_optimizer = torch.optim.Adam(\n",
    "            self.discriminator.parameters(), self.learning_rate, [self.beta1, self.beta2])\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            self.generator.cuda()\n",
    "            self.discriminator.cuda()\n",
    "            self.distance_based_loss.cuda()\n",
    "\n",
    "    def train(self):\n",
    "        \"\"\"Train generator and discriminator in minimax game.\"\"\"\n",
    "        # Prepare tensorboard writer\n",
    "        if self.tensorboard:\n",
    "            step = 0\n",
    "        \n",
    "        print(\"We are training\\n\")\n",
    "\n",
    "        for epoch in tqdm(range(self.num_epochs)):\n",
    "            print(str(epoch) + \" \" + str(datetime.now()))\n",
    "\n",
    "            for label, images0, images1 in self.data_loader:\n",
    "                images0 = to_variable(images0)\n",
    "                images1 = to_variable(images1)\n",
    "#                 print(\"label:\", label)\n",
    "                label = to_variable(label)\n",
    "#                 print(\"We extracted samples\")\n",
    "                # Train discriminator to recognize identity of real images\n",
    "                output0, output1 = self.discriminator(images0, images1)\n",
    "                d_real_loss = self.distance_based_loss(output0, output1, label)\n",
    "#                 print(\"We calculated loss\")\n",
    "                # Backpropagation\n",
    "                self.distance_based_loss.zero_grad()\n",
    "                self.discriminator.zero_grad()\n",
    "                d_real_loss.backward()\n",
    "                self.d_optimizer.step()\n",
    "#                 print(\"We did backprop\")\n",
    "                # Train discriminator to recognize identity of fake(privatized) images\n",
    "                \n",
    "                privatized_imgs, _, _ = self.generator(images0)\n",
    "#                 print(privatized_imgs)\n",
    "                output0, output1 = self.discriminator(images0, privatized_imgs)\n",
    "\n",
    "                # Discriminator wants to minimize Euclidean distance between\n",
    "                # original & privatized versions, hence label = 0\n",
    "                d_fake_loss = self.distance_based_loss(output0, output1, 0)\n",
    "                distance = 1.0 - self.ssim_loss(privatized_imgs, images0)\n",
    "                d_fake_loss += self.distance_weight * distance\n",
    "#                 print(\"We calculated loss\")\n",
    "                # Backpropagation\n",
    "                self.distance_based_loss.zero_grad()\n",
    "                self.discriminator.zero_grad()\n",
    "                self.generator.zero_grad()\n",
    "                d_fake_loss.backward()\n",
    "                self.d_optimizer.step()\n",
    "\n",
    "                # Train generator to fool discriminator\n",
    "                # Generator wants to push the distance between original & privatized\n",
    "                # right to the margin, hence label = 1\n",
    "                privatized_imgs, _, _ = self.generator(images0)\n",
    "                output0, output1 = self.discriminator(images0, privatized_imgs)\n",
    "                g_loss = self.distance_based_loss(output0, output1, 1)\n",
    "                distance = 1.0 - self.ssim_loss(privatized_imgs, images0)\n",
    "                g_loss += self.distance_weight * distance\n",
    "#                 print(\"We calculated loss\")\n",
    "                # Backpropagation\n",
    "                self.distance_based_loss.zero_grad()\n",
    "                self.discriminator.zero_grad()\n",
    "                self.generator.zero_grad()\n",
    "                g_loss.backward()\n",
    "                self.g_optimizer.step()\n",
    "\n",
    "                # Write losses to tensorboard\n",
    "                if self.tensorboard:\n",
    "                    self.tb_writer.add_scalar('phase0/discriminator_real_loss',\n",
    "                                              d_real_loss.data[0], step)\n",
    "                    self.tb_writer.add_scalar('phase0/discriminator_fake_loss',\n",
    "                                              d_fake_loss.data[0], step)\n",
    "                    self.tb_writer.add_scalar('phase0/generator_loss',\n",
    "                                              g_loss.data[0], step)\n",
    "                    self.tb_writer.add_scalar('phase0/distance_loss',\n",
    "                                              distance.data[0], step)\n",
    "\n",
    "                    step += 1\n",
    "\n",
    "            # Monitor training after each epoch\n",
    "            if self.tensorboard:\n",
    "                self._monitor_phase_0(self.tb_writer, step)\n",
    "\n",
    "            # At the end save generator and discriminator to files\n",
    "            if (epoch + 1) % 10 == 0:\n",
    "                g_path = os.path.join(self.model_path, 'generator-%d.pt' % (epoch+1))\n",
    "                torch.save(self.generator.state_dict(), g_path)\n",
    "                d_path = os.path.join(self.model_path, 'discriminator-%d.pt' % (epoch+1))\n",
    "                torch.save(self.discriminator.state_dict(), d_path)\n",
    "\n",
    "        if self.tensorboard:\n",
    "            self.tb_writer.close()\n",
    "\n",
    "    def _monitor_phase_0(self, writer, step, n_images=10):\n",
    "        \"\"\"Monitor discriminator's accuracy, generate preview images of generator.\"\"\"\n",
    "        # Measure accuracy of identity verification by discriminator\n",
    "        correct_pairs = 0\n",
    "        total_pairs = 0\n",
    "\n",
    "        for label, images0, images1 in self.data_loader:\n",
    "            images0 = to_variable(images0)\n",
    "            images1 = to_variable(images1)\n",
    "            label = to_variable(label)\n",
    "\n",
    "            # Predict label = 1 if outputs are dissimilar (distance > margin)\n",
    "            privatized_images0, _, _ = self.generator(images0)\n",
    "            output0, output1 = self.discriminator(privatized_images0, images1)\n",
    "            predictions = self.distance_based_loss.predict(output0, output1)\n",
    "            predictions = predictions.type(label.data.type())\n",
    "\n",
    "            correct_pairs += (predictions == label).sum().data[0]\n",
    "            total_pairs += len(predictions == label)\n",
    "\n",
    "            if total_pairs > 1000:\n",
    "                break\n",
    "\n",
    "        # Write accuracy to tensorboard\n",
    "        accuracy = correct_pairs / total_pairs\n",
    "        writer.add_scalar('phase0/discriminator_accuracy', accuracy, step)\n",
    "\n",
    "        # Generate previews of privatized images\n",
    "        reals, fakes = [], []\n",
    "        for _, image, _ in self.data_loader.dataset:\n",
    "            image = image.unsqueeze(0)\n",
    "            reals.append(denorm(to_variable(image).data)[0])\n",
    "            fakes.append(denorm(self.generator(to_variable(image)).data)[0])\n",
    "            if len(reals) == n_images:\n",
    "                break\n",
    "\n",
    "        # Write images to tensorboard\n",
    "        real_previews = torchvision.utils.make_grid(reals, nrow=n_images)\n",
    "        fake_previews = torchvision.utils.make_grid(fakes, nrow=n_images)\n",
    "        img = torchvision.utils.make_grid([real_previews, fake_previews], nrow=1)\n",
    "        writer.add_image('Previews', img, step)\n",
    "\n",
    "    def generate(self):\n",
    "        \"\"\"Generate privatized images.\"\"\"\n",
    "        # Load trained parameters (generator)\n",
    "        g_path = os.path.join(self.model_path, 'generator-%d.pkl' % self.num_epochs)\n",
    "        self.generator.load_state_dict(torch.load(g_path))\n",
    "        self.generator.eval()\n",
    "\n",
    "        # Generate the images\n",
    "        for relative_path, image in self.data_loader:\n",
    "            fake_image = self.generator(to_variable(image))\n",
    "            fake_path = os.path.join(self.generate_path, relative_path[0])\n",
    "            if not os.path.exists(os.path.dirname(fake_path)):\n",
    "                os.makedirs(os.path.dirname(fake_path))\n",
    "            torchvision.utils.save_image(fake_image.data, fake_path, nrow=1)\n",
    "\n",
    "    def check_discriminator_accuracy(self):\n",
    "        \"\"\"Measure discriminator's accuracy.\"\"\"\n",
    "        # Measure accuracy of identity verification by discriminator\n",
    "        correct_pairs = 0\n",
    "        total_pairs = 0\n",
    "\n",
    "        g_path = os.path.join(self.model_path, 'generator-%d.pkl' % self.num_epochs)\n",
    "        self.generator.load_state_dict(torch.load(g_path))\n",
    "        self.generator.eval()\n",
    "\n",
    "        d_path = os.path.join(self.model_path, 'discriminator-%d.pkl' % self.num_epochs)\n",
    "        self.discriminator.load_state_dict(torch.load(d_path))\n",
    "        self.discriminator.eval()\n",
    "\n",
    "        for label, images0, images1 in self.data_loader:\n",
    "            images0 = to_variable(images0)\n",
    "            images1 = to_variable(images1)\n",
    "            label = to_variable(label)\n",
    "\n",
    "            # Predict label = 1 if outputs are dissimilar (distance > margin)\n",
    "            privatized_images0 = self.generator(images0)\n",
    "            output0, output1 = self.discriminator(privatized_images0, images1)\n",
    "            predictions = self.distance_based_loss.predict(output0, output1)\n",
    "            predictions = predictions.type(label.data.type())\n",
    "\n",
    "            correct_pairs += (predictions == label).sum().data[0]\n",
    "            total_pairs += len(predictions)\n",
    "\n",
    "        accuracy = correct_pairs / total_pairs\n",
    "        print('distance weight = %f' % self.distance_weight)\n",
    "        print('accuracy = %f' % accuracy)\n",
    "        \n",
    "def to_variable(tensor):\n",
    "    \"\"\"Convert tensor to variable.\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        tensor = tensor.cuda()\n",
    "    return tensor\n",
    "\n",
    "def denorm(image):\n",
    "    \"\"\"Convert image range (-1, 1) to (0, 1).\"\"\"\n",
    "    out = (image + 1) / 2\n",
    "    return out.clamp(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorboardX, math\n",
    "config = Config(tensorboard=False)\n",
    "solver = SiameseGanSolver(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(solver.state_dict(), './model/solver.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
