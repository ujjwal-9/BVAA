{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOU ARE USING CUDA ...\n"
     ]
    }
   ],
   "source": [
    "use_cuda = True if torch.cuda.is_available() else False\n",
    "print(\"YOU ARE USING CUDA ...\" if use_cuda else \"YOU ARE NOT USING CUDA ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.datasets as datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '/home/ujjwal/Desktop/BVAA/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1024\n",
    "train_batch_size = 64\n",
    "test_batch_size = 1000\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')\n",
    "torch.manual_seed(seed)\n",
    "epochs = 2\n",
    "lr = 0.1\n",
    "gamma = 0.7\n",
    "log_interval = 1000\n",
    "save_model = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(datasets.MNIST(DATA_PATH, train=True, download=True,\n",
    "                             transform=transforms.Compose([\n",
    "                                 transforms.ToTensor(),\n",
    "                                 transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])), batch_size=train_batch_size, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(datasets.MNIST(DATA_PATH, train=False, download=True,\n",
    "                                                        transform=transforms.Compose([\n",
    "                                                            transforms.ToTensor(),\n",
    "                                                            transforms.Normalize(\n",
    "                                                            (0.1307,), (0.3081,))\n",
    "                                                        ])), batch_size=test_batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = enumerate(test_loader)\n",
    "batch_idx, (example_data, example_targets) = next(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "for i in range(6):\n",
    "    plt.subplot(2,3,i+1)\n",
    "    plt.tight_layout()\n",
    "    plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n",
    "    plt.title(\"Ground Truth: {}\".format(example_targets[i]))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv(inch, ouch, ks, stride=2, pad=1, batchNorm=True):\n",
    "    layers = []\n",
    "    \n",
    "    layers.append(nn.Conv2d(inch, ouch, ks, pad))\n",
    "    \n",
    "    if batchNorm:\n",
    "        layers.append(nn.BatchNorm2d(ouch))\n",
    "    \n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, net_depth=4, conv_dim=64, img_dim=28, nc=1, z_dim=64):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.net_depth = net_depth\n",
    "        \n",
    "        kernel_size = 4\n",
    "        stride = 2\n",
    "        pad = 1\n",
    "        input_ch = nc\n",
    "        output_ch = conv_dim\n",
    "        \n",
    "        self.encoder = []\n",
    "        \n",
    "        self.encoder.extend([conv(input_ch, output_ch, kernel_size, stride, pad, batchNorm=False), nn.LeakyReLU(0.05)])\n",
    "        \n",
    "        map_dim = (img_dim - kernel_size + 2 * pad) / stride + 1\n",
    "        \n",
    "        for i in range(1,net_depth):\n",
    "            input_ch = output_ch\n",
    "            output_ch = conv_dim*(2**i)\n",
    "            self.encoder.extend([conv(input_ch, output_ch, kernel_size, stride, pad, batchNorm=False), nn.LeakyReLU(0.05)])\n",
    "            map_dim = (map_dim - kernel_size + 2 * pad) / stride + 1\n",
    "        \n",
    "        self.encoder = nn.Sequential(*self.encoder)\n",
    "#         print(output_ch*(map_dim**2))\n",
    "#         int(output_ch*(map_dim**2))\n",
    "        self.fc = nn.Linear(46208, 2048)\n",
    "        self.fc1 = nn.Linear(2048, 1024)\n",
    "        self.fc2 = nn.Linear(1024, z_dim)\n",
    "    \n",
    "    def num_features(self, x) :\n",
    "        size = x.size()[1:]\n",
    "        # all dim except the batch dim...\n",
    "        num_features = 1\n",
    "        for s in size :\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "    def encode(self, x):\n",
    "        out = self.encoder(x)\n",
    "        print(out.shape)\n",
    "        out = out.view((-1, self.num_features(out)))\n",
    "        print(out.shape)\n",
    "        out = self.fc(out)\n",
    "        out = F.leaky_relu(out, 0.05)\n",
    "        out = self.fc1(out)\n",
    "        out = F.leaky_relu(out, 0.05)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.encode(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deconv(inch, ouch, kernel_size, stride=2, pad=1, batchNorm=True):\n",
    "    layers = []\n",
    "    layers.append(nn.ConvTranspose2d(inch, ouch, kernel_size, stride, pad))\n",
    "    if batchNorm:\n",
    "        layers.append(nn.BatchNorm2d(ouch))\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, net_depth=4, conv_dim=64, img_dim=28, nc=1, z_dim=32):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.net_depth = net_depth\n",
    "        \n",
    "        kernel_size = 4\n",
    "        stride = 1\n",
    "        pad = 1\n",
    "        input_ch = z_dim\n",
    "        output_ch = conv_dim*(2**self.net_depth)\n",
    "        map_dim = kernel_size\n",
    "        \n",
    "        self.fc = deconv(input_ch, output_ch, kernel_size, stride=1, pad=0, batchNorm=False)\n",
    "        \n",
    "        self.decoder = []\n",
    "        \n",
    "        for i in reversed(range(self.net_depth)):\n",
    "            input_ch = output_ch\n",
    "            output_ch = output_ch*2\n",
    "#             output_ch = conv_dim*(2**i)\n",
    "            if i == 0:\n",
    "                kernel_size = img_dim - stride*(map_dim-1) + 2*pad\n",
    "                print(\"inside loop:\",kernel_size)\n",
    "            self.decoder.extend([deconv(input_ch, output_ch, kernel_size, stride, pad, batchNorm=False), nn.LeakyReLU(0.05)])\n",
    "            map_dim = stride * (map_dim - 1) - 2 * pad + kernel_size \n",
    "        \n",
    "        self.decoder = nn.Sequential(*self.decoder)\n",
    "        \n",
    "        input_ch = output_ch\n",
    "        output_ch = 1\n",
    "#         print(input_ch)\n",
    "        output_dim = img_dim\n",
    "        pad = 0\n",
    "        stride = 1\n",
    "#         kernel_size = output_dim + 2 * pad - stride * (map_dim - 1)\n",
    "#         kernel_size = 3\n",
    "        print(\"map:\", map_dim)\n",
    "        kernel_size = output_dim - (map_dim-1) * stride + 2*pad\n",
    "        print(\"kernel_size:\",kernel_size)\n",
    "        self.final = deconv(input_ch, output_ch, kernel_size, stride, pad, batchNorm=False)\n",
    "        \n",
    "    def decode(self, z):\n",
    "        z = z.view(z.size(0), z.size(1), 1, 1)\n",
    "        out = F.leaky_relu(self.fc(z), 0.05)\n",
    "        print(\"fc:\",out.shape)\n",
    "        out = F.leaky_relu(self.decoder(out), 0.05)\n",
    "        print(\"decoder: \",out.shape)\n",
    "        out = F.sigmoid(self.final(out))\n",
    "        return out\n",
    "    \n",
    "    def forward(self, z):\n",
    "        return self.decode(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class betaVAE(nn.Module):\n",
    "    def __init__(self, net_depth=4, conv_dim=64, img_dim=28, nc=1, z_dim=32, beta=1.0, use_cuda=True):\n",
    "        super(betaVAE, self).__init__()\n",
    "        self.encoder = Encoder(net_depth, conv_dim, img_dim, nc, z_dim=2*z_dim)\n",
    "        self.decoder = Decoder(net_depth, conv_dim, img_dim, nc, z_dim)\n",
    "        self.beta = beta\n",
    "        self.use_cuda = use_cuda\n",
    "        if self.use_cuda:\n",
    "            self.cuda()\n",
    "    \n",
    "    def reparameterize(self, mu, log_var):\n",
    "        eps = torch.randn(mu.size(), requires_grad=False).cuda()\n",
    "        return mu + eps * torch.exp(log_var/2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h = self.encoder(x)\n",
    "        mu, log_var = torch.chunk(h, 2, dim=1)\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "        out = self.decoder(z)\n",
    "        return out, mu, log_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class siamese(nn.Module):\n",
    "    def __init__(self, image_size):\n",
    "        super(siamse, self).__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(3, 4, kernel_size=3),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.BatchNorm2d(4),\n",
    "            nn.Dropout2d(p=.2),\n",
    "\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(4, 8, kernel_size=3),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.Dropout2d(p=.2),\n",
    "\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(8, 8, kernel_size=3),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.Dropout2d(p=.2)\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(8 * image_size * image_size, 500),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "\n",
    "            nn.Linear(500, 500),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "\n",
    "            nn.Linear(500, 15)\n",
    "        )\n",
    "    \n",
    "    def discriminator_embedding(self, x):\n",
    "        output = self.cnn(x)\n",
    "        output = output,view(output.size()[0], -1)\n",
    "        output = self.fc(output)\n",
    "        return output\n",
    "    \n",
    "    def forward(self, generator_model, original_input, phase='train'):\n",
    "        if phase is 'train':\n",
    "            generator_model.train()\n",
    "        else:\n",
    "            generator_model.eval()\n",
    "        intermediate_input = generator_model(original_input)\n",
    "        output_original = discriminator_embedding(original_input)\n",
    "        output_generator = discriminator_embedding(intermediate_input)\n",
    "        return output_original, output_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss(nn.Module):\n",
    "    def __init__(self, margin):\n",
    "        super(Loss, self).__init__()\n",
    "        self.margin = margin\n",
    "    \n",
    "    def forward(self, output1, output2, label):\n",
    "        \"\"\"Define the computation performed at every call.\"\"\"\n",
    "        euclidean_distance = F.pairwise_distance(output1, output2)\n",
    "        distance_from_margin = torch.clamp(torch.pow(euclidean_distance, 2) - self.margin, max=50.0)\n",
    "        exp_distance_from_margin = torch.exp(distance_from_margin)\n",
    "        distance_based_loss = (1.0 + math.exp(-self.margin)) / (1.0 + exp_distance_from_margin)\n",
    "        similar_loss = -0.5 * (1 - label) * torch.log(distance_based_loss)\n",
    "        dissimilar_loss = -0.5 * label * torch.log(1.0 - distance_based_loss)\n",
    "        return torch.mean(similar_loss + dissimilar_loss)\n",
    "    \n",
    "    def predict(self, output1, output2, threshold_factor=0.5):\n",
    "        \"\"\"Predict a dissimilarity label given two embeddings.\n",
    "        Return `1` if dissimilar.\n",
    "        \"\"\"\n",
    "        return F.pairwise_distance(output1, output2) > self.margin * threshold_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastiveLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Contrastive loss function.\n",
    "    Based on: http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, margin):\n",
    "        \"\"\"Set parameters of contrastive loss function.\"\"\"\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, output1, output2, label):\n",
    "        \"\"\"Define the computation performed at every call.\"\"\"\n",
    "        euclidean_distance = F.pairwise_distance(output1, output2)\n",
    "        clamped = torch.clamp(self.margin - euclidean_distance, min=0.0)\n",
    "        similar_loss = (1 - label) * 0.5 * torch.pow(euclidean_distance, 2)\n",
    "        dissimilar_loss = label * 0.5 * torch.pow(clamped, 2)\n",
    "        contrastive_loss = similar_loss + dissimilar_loss\n",
    "\n",
    "        return torch.mean(contrastive_loss)\n",
    "\n",
    "    def predict(self, output1, output2, threshold_factor=0.5):\n",
    "        \"\"\"Predict a dissimilarity label given two embeddings.\n",
    "        Return `1` if dissimilar.\n",
    "        \"\"\"\n",
    "        return F.pairwise_distance(output1, output2) > self.margin * threshold_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_dim = 12\n",
    "img_dim = example_data[0].shape[-1]\n",
    "color_channels=1\n",
    "conv_dim = 32\n",
    "net_depth = 3\n",
    "beta = 5e0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inside loop: 25\n",
      "map: 28\n",
      "kernel_size: 1\n"
     ]
    }
   ],
   "source": [
    "generator = betaVAE(beta=beta,\n",
    "                    net_depth=net_depth,\n",
    "                    z_dim=z_dim,\n",
    "                    img_dim=img_dim,\n",
    "                    nc=color_channels,\n",
    "                    conv_dim=conv_dim, \n",
    "                    use_cuda=use_cuda\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "betaVAE(\n",
       "  (encoder): Encoder(\n",
       "    (encoder): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): Conv2d(1, 32, kernel_size=(4, 4), stride=(1, 1))\n",
       "      )\n",
       "      (1): LeakyReLU(negative_slope=0.05)\n",
       "      (2): Sequential(\n",
       "        (0): Conv2d(32, 64, kernel_size=(4, 4), stride=(1, 1))\n",
       "      )\n",
       "      (3): LeakyReLU(negative_slope=0.05)\n",
       "      (4): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(1, 1))\n",
       "      )\n",
       "      (5): LeakyReLU(negative_slope=0.05)\n",
       "    )\n",
       "    (fc): Linear(in_features=1568, out_features=2048, bias=True)\n",
       "    (fc1): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "    (fc2): Linear(in_features=1024, out_features=24, bias=True)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (fc): Sequential(\n",
       "      (0): ConvTranspose2d(12, 256, kernel_size=(4, 4), stride=(1, 1))\n",
       "    )\n",
       "    (decoder): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      )\n",
       "      (1): LeakyReLU(negative_slope=0.05)\n",
       "      (2): Sequential(\n",
       "        (0): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      )\n",
       "      (3): LeakyReLU(negative_slope=0.05)\n",
       "      (4): Sequential(\n",
       "        (0): ConvTranspose2d(64, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      )\n",
       "      (5): LeakyReLU(negative_slope=0.05)\n",
       "    )\n",
       "    (final): Sequential(\n",
       "      (0): ConvTranspose2d(32, 1, kernel_size=(3, 3), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optim :\n",
    "lr = 1e-4\n",
    "optimizer = torch.optim.Adam(generator.parameters(), lr=lr)\n",
    "\n",
    "# Debug :\n",
    "# fixed inputs for debugging\n",
    "fixed_z = torch.Tensor(torch.randn(100, z_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_cuda:\n",
    "    fixed_z = fixed_z.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.exists('./beta-data'):\n",
    "    os.mkdir('./beta-data')\n",
    "\n",
    "path = 'test--mnist-beta{}-layers{}-z{}-conv{}-lr{}'.format(beta,net_depth,z_dim,conv_dim,lr)\n",
    "\n",
    "if not os.path.exists('./beta-data/{}/'.format(path)):\n",
    "    os.mkdir('./beta-data/{}/'.format(path))\n",
    "\n",
    "if not os.path.exists('./beta-data/{}/gen_images/'.format(path)):\n",
    "    os.mkdir('./beta-data/{}/gen_images/'.format(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta-data  model-latent-space.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iter = iter(train_loader)\n",
    "iter_per_epoch = len(train_loader)\n",
    "fixed_x, _ = next(data_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.utils import save_image\n",
    "fixed_x = fixed_x.view( (-1, img_depth, img_dim, img_dim) )\n",
    "save_image(fixed_x.cpu(), './beta-data/{}/real_images.png'.format(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_x = torch.Tensor(fixed_x.view(fixed_x.size(0), img_depth, img_dim, img_dim))\n",
    "if use_cuda:\n",
    "    fixed_x = fixed_x.cuda()\n",
    "out = torch.zeros((1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_mean = torch.ones((z_dim))\n",
    "mu_mean = torch.zeros((z_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 64\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 128, 19, 19])\n",
      "torch.Size([64, 46208])\n",
      "fc: torch.Size([64, 256, 4, 4])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 392.00 MiB (GPU 0; 10.91 GiB total capacity; 9.19 GiB already allocated; 312.06 MiB free; 46.08 MiB cached)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-130-f9c9e95a1731>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mreconsturcted_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfixed_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreconsturcted_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mreconsturcted_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreconsturcted_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/bvaa/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-74-e415e7ed9c47>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreparameterize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_var\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_var\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/bvaa/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-123-90e180c25d5f>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, z)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-123-90e180c25d5f>\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, z)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.05\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"fc:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.05\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"decoder: \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/bvaa/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/bvaa/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/bvaa/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/bvaa/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/bvaa/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/bvaa/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, output_size)\u001b[0m\n\u001b[1;32m    776\u001b[0m         return F.conv_transpose2d(\n\u001b[1;32m    777\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 778\u001b[0;31m             output_padding, self.groups, self.dilation)\n\u001b[0m\u001b[1;32m    779\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 392.00 MiB (GPU 0; 10.91 GiB total capacity; 9.19 GiB already allocated; 312.06 MiB free; 46.08 MiB cached)"
     ]
    }
   ],
   "source": [
    "for epoch in range(50):\n",
    "    reconsturcted_images, _, _ = generator(fixed_x)\n",
    "    print(reconsturcted_images.shape)\n",
    "    reconsturcted_images = reconsturcted_images.view(-1, color_channels, img_dim, img_dim)\n",
    "    \n",
    "    save_image(reconsturcted_images.data.cpu(),'./beta-data/{}/reconst_images_{}.png'.format(path,(epoch+1)))\n",
    "    \n",
    "    # Save generated variable images :\n",
    "    nbr_steps = 8\n",
    "    mu_mean /= batch_size\n",
    "    sigma_mean /= batch_size\n",
    "    gen_images = torch.ones((8, color_channels, img_dim, img_dim))\n",
    "    \n",
    "    for latent in range(z_dim):\n",
    "        var_z0 = torch.zeros(nbr_steps, z_dim)\n",
    "        val = mu_mean[latent] - sigma_mean[latent]\n",
    "        step = 2.0 * sigma_mean[latent] / nbr_steps\n",
    "        print(latent, mu_mean[latent], step)\n",
    "        for i in range(nbr_steps) :\n",
    "            var_z0[i] = mu_mean\n",
    "            var_z0[i][latent] = val\n",
    "            val += step\n",
    "\n",
    "        var_z0 = Variable(var_z0)\n",
    "        if use_cuda :\n",
    "            var_z0 = var_z0.cuda()\n",
    "        gen_images_latent = generator.decoder(var_z0)\n",
    "        gen_images_latent = gen_images_latent.view(-1, img_depth, img_dim, img_dim).cpu().data\n",
    "        gen_images = torch.cat([gen_images,gen_images_latent], dim=0)\n",
    "    save_image(gen_images,'./beta-data/{}/gen_images/{}.png'.format(path,(epoch+1)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.fc = nn.Linear(int(output_ch*(map_dim**2)), 2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Distribution(object) :\n",
    "    def sample(self) :\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def log_prob(self,values) :\n",
    "        raise NotImplementedError\n",
    "\n",
    "class Bernoulli(Distribution) :\n",
    "    def __init__(self, probs) :\n",
    "        self.probs = probs\n",
    "\n",
    "    def sample(self) :\n",
    "        return torch.bernoulli(self.probs)\n",
    "\n",
    "    def log_prob(self,values) :\n",
    "        log_pmf = ( torch.stack( [1-self.probs, self.probs] ) ).log()\n",
    "        dum = values.unsqueeze(0).long()\n",
    "        return log_pmf.gather( 0, dum ).squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (images, _) in enumerate(data_loader):\n",
    "    images = torch.Tensor((images.view(-1,1,img_dim, img_dim) ))\n",
    "    if use_cuda :\n",
    "        images = images.cuda() \n",
    "\n",
    "    out, mu, log_var = generator(images)\n",
    "\n",
    "    mu_mean += torch.mean(mu.data,dim=0)\n",
    "    sigma_mean += torch.mean(torch.sqrt(torch.exp(log_var.data)), dim=0 )\n",
    "\n",
    "    # Compute :\n",
    "    #reconstruction loss :\n",
    "    reconst_loss = F.binary_cross_entropy(out, images, size_average=False)\n",
    "    #reconst_loss = torch.mean( (out.view(-1) - images.view(-1))**2 )\n",
    "\n",
    "    # expected log likelyhood :\n",
    "    expected_log_lik = torch.mean(Bernoulli(out.view((-1))).log_prob(images.view((-1))))\n",
    "    #expected_log_lik = torch.mean( Bernoulli( out ).log_prob( images ) )\n",
    "\n",
    "    # kl divergence :\n",
    "    #kl_divergence = 0.5 * torch.mean( torch.sum( (mu**2 + torch.exp(log_var) - log_var -1), dim=1) )\n",
    "    kl_divergence = 0.5 * torch.sum( (mu**2 + torch.exp(log_var) - log_var -1) )\n",
    "\n",
    "    # ELBO :\n",
    "    elbo = expected_log_lik - generator.beta * kl_divergence\n",
    "\n",
    "    # TOTAL LOSS :\n",
    "    total_loss = reconst_loss + generator.beta*kl_divergence\n",
    "    #total_loss = reconst_loss\n",
    "    #total_loss = -elbo\n",
    "\n",
    "    # Backprop + Optimize :\n",
    "    optimizer.zero_grad()\n",
    "    total_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        print (\"Epoch[%d/%d], Step [%d/%d], Total Loss: %.4f, \"\n",
    "               \"Reconst Loss: %.4f, KL Div: %.7f, E[ |~| p(x|theta)]: %.7f \" \n",
    "               %(epoch+1, 50, i+1, iter_per_epoch, total_loss.data[0], \n",
    "                 reconst_loss.data[0], kl_divergence.data[0],expected_log_lik.exp().data[0]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'Module' has no attribute '_module'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-510a78182b82>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'Module' has no attribute '_module'"
     ]
    }
   ],
   "source": [
    "nn.Module._module"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
