{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.datasets as datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOU ARE USING CUDA ...\n"
     ]
    }
   ],
   "source": [
    "use_cuda = True if torch.cuda.is_available() else False\n",
    "print(\"YOU ARE USING CUDA ...\" if use_cuda else \"YOU ARE NOT USING CUDA ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '/home/ujjwal/Desktop/BVAA/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1024\n",
    "train_batch_size = 64\n",
    "test_batch_size = 1000\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')\n",
    "torch.manual_seed(seed)\n",
    "epochs = 2\n",
    "lr = 0.1\n",
    "gamma = 0.7\n",
    "log_interval = 1000\n",
    "save_model = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(datasets.MNIST(DATA_PATH, train=True, download=True,\n",
    "                             transform=transforms.Compose([\n",
    "                                 transforms.ToTensor(),\n",
    "                                 transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])), batch_size=train_batch_size, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(datasets.MNIST(DATA_PATH, train=False, download=True,\n",
    "                                                        transform=transforms.Compose([\n",
    "                                                            transforms.ToTensor(),\n",
    "                                                            transforms.Normalize(\n",
    "                                                            (0.1307,), (0.3081,))\n",
    "                                                        ])), batch_size=test_batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = enumerate(test_loader)\n",
    "batch_idx, (example_data, example_targets) = next(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "for i in range(6):\n",
    "    plt.subplot(2,3,i+1)\n",
    "    plt.tight_layout()\n",
    "    plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n",
    "    plt.title(\"Ground Truth: {}\".format(example_targets[i]))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv(inch, ouch, ks, stride=2, pad=1, batchNorm=True):\n",
    "    layers = []\n",
    "    \n",
    "    layers.append(nn.Conv2d(inch, ouch, ks, pad))\n",
    "    \n",
    "    if batchNorm:\n",
    "        layers.append(nn.BatchNorm2d(ouch))\n",
    "    \n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, net_depth=4, conv_dim=64, img_dim=28, nc=1, z_dim=64):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.net_depth = net_depth\n",
    "        \n",
    "        kernel_size = 4\n",
    "        stride = 2\n",
    "        pad = 1\n",
    "        input_ch = nc\n",
    "        output_ch = conv_dim\n",
    "        \n",
    "        self.encoder = []\n",
    "        \n",
    "        self.encoder.extend([conv(input_ch, output_ch, kernel_size, stride, pad, batchNorm=False), nn.LeakyReLU(0.05)])\n",
    "        \n",
    "        map_dim = (img_dim - kernel_size + 2 * pad) / stride + 1\n",
    "        \n",
    "        for i in range(1,net_depth):\n",
    "            input_ch = output_ch\n",
    "            output_ch = conv_dim*(2**i)\n",
    "            self.encoder.extend([conv(input_ch, output_ch, kernel_size, stride, pad, batchNorm=False), nn.LeakyReLU(0.05)])\n",
    "            map_dim = (map_dim - kernel_size + 2 * pad) / stride + 1\n",
    "        \n",
    "        self.encoder = nn.Sequential(*self.encoder)\n",
    "#         print(output_ch*(map_dim**2))\n",
    "#         int(output_ch*(map_dim**2))\n",
    "        self.fc = nn.Linear(46208, 2048)\n",
    "        self.fc1 = nn.Linear(2048, 1024)\n",
    "        self.fc2 = nn.Linear(1024, z_dim)\n",
    "    \n",
    "    def num_features(self, x) :\n",
    "        size = x.size()[1:]\n",
    "        # all dim except the batch dim...\n",
    "        num_features = 1\n",
    "        for s in size :\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "    def encode(self, x):\n",
    "        out = self.encoder(x)\n",
    "#         print(out.shape)\n",
    "        out = out.view((-1, self.num_features(out)))\n",
    "#         print(out.shape)\n",
    "        out = self.fc(out)\n",
    "        out = F.leaky_relu(out, 0.05)\n",
    "        out = self.fc1(out)\n",
    "        out = F.leaky_relu(out, 0.05)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.encode(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deconv(inch, ouch, kernel_size, stride=2, pad=1, batchNorm=True):\n",
    "    layers = []\n",
    "    layers.append(nn.ConvTranspose2d(inch, ouch, kernel_size, stride, pad))\n",
    "    if batchNorm:\n",
    "        layers.append(nn.BatchNorm2d(ouch))\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, net_depth=4, conv_dim=64, img_dim=28, nc=1, z_dim=32):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.net_depth = net_depth\n",
    "        print(self.net_depth)\n",
    "        kernel_size = 4\n",
    "        stride = 1\n",
    "        pad = 1\n",
    "        input_ch = z_dim\n",
    "        output_ch = conv_dim*(2**self.net_depth)\n",
    "        map_dim = kernel_size\n",
    "        \n",
    "        self.fc = deconv(input_ch, output_ch, kernel_size, stride=1, pad=0, batchNorm=False)\n",
    "        \n",
    "        self.decoder = []\n",
    "        \n",
    "        for i in reversed(range(self.net_depth)):\n",
    "            input_ch = output_ch\n",
    "            output_ch = output_ch*2\n",
    "#             output_ch = conv_dim*(2**i)\n",
    "            if i == 0:\n",
    "                kernel_size = img_dim - stride*(map_dim-1) + 2*pad\n",
    "#                 print(\"inside loop:\",kernel_size)\n",
    "            self.decoder.extend([deconv(input_ch, output_ch, kernel_size, stride, pad, batchNorm=False), nn.LeakyReLU(0.05)])\n",
    "            map_dim = stride * (map_dim - 1) - 2 * pad + kernel_size \n",
    "        \n",
    "        self.decoder = nn.Sequential(*self.decoder)\n",
    "        \n",
    "        input_ch = output_ch\n",
    "        output_ch = 1\n",
    "#         print(input_ch)\n",
    "        output_dim = img_dim\n",
    "        pad = 0\n",
    "        stride = 1\n",
    "#         kernel_size = output_dim + 2 * pad - stride * (map_dim - 1)\n",
    "#         kernel_size = 3\n",
    "#         print(\"map:\", map_dim)\n",
    "        kernel_size = output_dim - (map_dim-1) * stride + 2*pad\n",
    "#         print(\"kernel_size:\",kernel_size)\n",
    "        self.final = deconv(input_ch, output_ch, kernel_size, stride, pad, batchNorm=False)\n",
    "        \n",
    "    def decode(self, z):\n",
    "        z = z.view(z.size(0), z.size(1), 1, 1)\n",
    "        out = F.leaky_relu(self.fc(z), 0.05)\n",
    "#         print(\"fc:\",out.shape)\n",
    "        out = F.leaky_relu(self.decoder(out), 0.05)\n",
    "#         print(\"decoder: \",out.shape)\n",
    "        out = torch.sigmoid(self.final(out))\n",
    "        return out\n",
    "    \n",
    "    def forward(self, z):\n",
    "        return self.decode(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class betaVAE(nn.Module):\n",
    "    def __init__(self, net_depth=4, conv_dim=64, img_dim=28, nc=1, z_dim=32, beta=1.0, use_cuda=True):\n",
    "        super(betaVAE, self).__init__()\n",
    "        self.encoder = Encoder(net_depth, conv_dim, img_dim, nc, z_dim=2*z_dim)\n",
    "        self.decoder = Decoder(net_depth, conv_dim, img_dim, nc, z_dim)\n",
    "        self.beta = beta\n",
    "        self.use_cuda = use_cuda\n",
    "        if self.use_cuda:\n",
    "            self.cuda()\n",
    "    \n",
    "    def reparameterize(self, mu, log_var):\n",
    "        eps = torch.randn(mu.size(), requires_grad=False).cuda()\n",
    "        return mu + eps * torch.exp(log_var/2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h = self.encoder(x)\n",
    "        mu, log_var = torch.chunk(h, 2, dim=1)\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "        out = self.decoder(z)\n",
    "        return out, mu, log_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class siamese(nn.Module):\n",
    "    def __init__(self, image_size):\n",
    "        super(siamse, self).__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(3, 4, kernel_size=3),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.BatchNorm2d(4),\n",
    "            nn.Dropout2d(p=.2),\n",
    "\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(4, 8, kernel_size=3),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.Dropout2d(p=.2),\n",
    "\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(8, 8, kernel_size=3),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.Dropout2d(p=.2)\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(8 * image_size * image_size, 500),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "\n",
    "            nn.Linear(500, 500),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "\n",
    "            nn.Linear(500, 15)\n",
    "        )\n",
    "    \n",
    "    def discriminator_embedding(self, x):\n",
    "        output = self.cnn(x)\n",
    "        output = output,view(output.size()[0], -1)\n",
    "        output = self.fc(output)\n",
    "        return output\n",
    "    \n",
    "    def forward(self, generator_model, original_input, phase='train'):\n",
    "        if phase is 'train':\n",
    "            generator_model.train()\n",
    "        else:\n",
    "            generator_model.eval()\n",
    "        intermediate_input = generator_model(original_input)\n",
    "        output_original = discriminator_embedding(original_input)\n",
    "        output_generator = discriminator_embedding(intermediate_input)\n",
    "        return output_original, output_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss(nn.Module):\n",
    "    def __init__(self, margin):\n",
    "        super(Loss, self).__init__()\n",
    "        self.margin = margin\n",
    "    \n",
    "    def forward(self, output1, output2, label):\n",
    "        \"\"\"Define the computation performed at every call.\"\"\"\n",
    "        euclidean_distance = F.pairwise_distance(output1, output2)\n",
    "        distance_from_margin = torch.clamp(torch.pow(euclidean_distance, 2) - self.margin, max=50.0)\n",
    "        exp_distance_from_margin = torch.exp(distance_from_margin)\n",
    "        distance_based_loss = (1.0 + math.exp(-self.margin)) / (1.0 + exp_distance_from_margin)\n",
    "        similar_loss = -0.5 * (1 - label) * torch.log(distance_based_loss)\n",
    "        dissimilar_loss = -0.5 * label * torch.log(1.0 - distance_based_loss)\n",
    "        return torch.mean(similar_loss + dissimilar_loss)\n",
    "    \n",
    "    def predict(self, output1, output2, threshold_factor=0.5):\n",
    "        \"\"\"Predict a dissimilarity label given two embeddings.\n",
    "        Return `1` if dissimilar.\n",
    "        \"\"\"\n",
    "        return F.pairwise_distance(output1, output2) > self.margin * threshold_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastiveLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Contrastive loss function.\n",
    "    Based on: http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, margin):\n",
    "        \"\"\"Set parameters of contrastive loss function.\"\"\"\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, output1, output2, label):\n",
    "        \"\"\"Define the computation performed at every call.\"\"\"\n",
    "        euclidean_distance = F.pairwise_distance(output1, output2)\n",
    "        clamped = torch.clamp(self.margin - euclidean_distance, min=0.0)\n",
    "        similar_loss = (1 - label) * 0.5 * torch.pow(euclidean_distance, 2)\n",
    "        dissimilar_loss = label * 0.5 * torch.pow(clamped, 2)\n",
    "        contrastive_loss = similar_loss + dissimilar_loss\n",
    "\n",
    "        return torch.mean(contrastive_loss)\n",
    "\n",
    "    def predict(self, output1, output2, threshold_factor=0.5):\n",
    "        \"\"\"Predict a dissimilarity label given two embeddings.\n",
    "        Return `1` if dissimilar.\n",
    "        \"\"\"\n",
    "        return F.pairwise_distance(output1, output2) > self.margin * threshold_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_dim = 12\n",
    "img_dim = example_data[0].shape[-1]\n",
    "color_channels=1\n",
    "conv_dim = 32\n",
    "net_depth = 3\n",
    "beta = 5e0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "generator = betaVAE(beta=beta,\n",
    "                    net_depth=net_depth,\n",
    "                    z_dim=z_dim,\n",
    "                    img_dim=img_dim,\n",
    "                    nc=color_channels,\n",
    "                    conv_dim=conv_dim, \n",
    "                    use_cuda=use_cuda\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "betaVAE(\n",
       "  (encoder): Encoder(\n",
       "    (encoder): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): Conv2d(1, 32, kernel_size=(4, 4), stride=(1, 1))\n",
       "      )\n",
       "      (1): LeakyReLU(negative_slope=0.05)\n",
       "      (2): Sequential(\n",
       "        (0): Conv2d(32, 64, kernel_size=(4, 4), stride=(1, 1))\n",
       "      )\n",
       "      (3): LeakyReLU(negative_slope=0.05)\n",
       "      (4): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(1, 1))\n",
       "      )\n",
       "      (5): LeakyReLU(negative_slope=0.05)\n",
       "    )\n",
       "    (fc): Linear(in_features=46208, out_features=2048, bias=True)\n",
       "    (fc1): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "    (fc2): Linear(in_features=1024, out_features=24, bias=True)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (fc): Sequential(\n",
       "      (0): ConvTranspose2d(12, 256, kernel_size=(4, 4), stride=(1, 1))\n",
       "    )\n",
       "    (decoder): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): ConvTranspose2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (1): LeakyReLU(negative_slope=0.05)\n",
       "      (2): Sequential(\n",
       "        (0): ConvTranspose2d(512, 1024, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (3): LeakyReLU(negative_slope=0.05)\n",
       "      (4): Sequential(\n",
       "        (0): ConvTranspose2d(1024, 2048, kernel_size=(25, 25), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (5): LeakyReLU(negative_slope=0.05)\n",
       "    )\n",
       "    (final): Sequential(\n",
       "      (0): ConvTranspose2d(2048, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optim :\n",
    "lr = 1e-3\n",
    "optimizer = torch.optim.Adam(generator.parameters(), lr=lr)\n",
    "\n",
    "# Debug :\n",
    "# fixed inputs for debugging\n",
    "fixed_z = torch.Tensor(torch.randn(100, z_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_cuda:\n",
    "    fixed_z = fixed_z.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.exists('./beta-data'):\n",
    "    os.mkdir('./beta-data')\n",
    "\n",
    "path = 'test--mnist-beta{}-layers{}-z{}-conv{}-lr{}'.format(beta,net_depth,z_dim,conv_dim,lr)\n",
    "\n",
    "if not os.path.exists('./beta-data/{}/'.format(path)):\n",
    "    os.mkdir('./beta-data/{}/'.format(path))\n",
    "\n",
    "if not os.path.exists('./beta-data/{}/gen_images/'.format(path)):\n",
    "    os.mkdir('./beta-data/{}/gen_images/'.format(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta-data  model-latent-space.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iter = iter(train_loader)\n",
    "iter_per_epoch = len(train_loader)\n",
    "fixed_x, _ = next(data_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.utils import save_image\n",
    "fixed_x = fixed_x.view( (-1, color_channels, img_dim, img_dim) )\n",
    "save_image(fixed_x.cpu(), './beta-data/{}/real_images.png'.format(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_x = torch.Tensor(fixed_x.view(fixed_x.size(0), color_channels, img_dim, img_dim))\n",
    "if use_cuda:\n",
    "    fixed_x = fixed_x.cuda()\n",
    "out = torch.zeros((1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_mean = torch.ones((z_dim))\n",
    "mu_mean = torch.zeros((z_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 64\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Distribution(object) :\n",
    "    def sample(self) :\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def log_prob(self,values) :\n",
    "        raise NotImplementedError\n",
    "\n",
    "class Bernoulli(Distribution) :\n",
    "    def __init__(self, probs) :\n",
    "        self.probs = probs\n",
    "\n",
    "    def sample(self) :\n",
    "        return torch.bernoulli(self.probs)\n",
    "\n",
    "    def log_prob(self,values) :\n",
    "        log_pmf = ( torch.stack( [1-self.probs, self.probs] ) ).log()\n",
    "        dum = values.unsqueeze(0).long()\n",
    "        return log_pmf.gather( 0, dum ).squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_LAUNCH_BLOCKING=1\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_LAUNCH_BLOCKING=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]/opt/miniconda3/envs/bvaa/lib/python3.6/site-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "cuda runtime error (710) : device-side assert triggered at /opt/conda/conda-bld/pytorch_1573049304260/work/aten/src/THC/generic/THCStorage.cpp:39",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-108cd86c5ba9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;31m# Backprop + Optimize :\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0mtotal_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/bvaa/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \"\"\"\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/bvaa/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuda runtime error (710) : device-side assert triggered at /opt/conda/conda-bld/pytorch_1573049304260/work/aten/src/THC/generic/THCStorage.cpp:39"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "generator.train()\n",
    "for epoch in tqdm(range(50)):\n",
    "    reconsturcted_images, _, _ = generator(fixed_x)\n",
    "#     print(reconsturcted_images.shape)\n",
    "    reconsturcted_images = reconsturcted_images.view(-1, color_channels, img_dim, img_dim)\n",
    "    \n",
    "    save_image(reconsturcted_images.data.cpu(),'./beta-data/{}/reconst_images_{}.png'.format(path,(epoch+1)))\n",
    "    \n",
    "    # Save generated variable images :\n",
    "    nbr_steps = 8\n",
    "    mu_mean /= batch_size\n",
    "    sigma_mean /= batch_size\n",
    "    gen_images = torch.ones((8, color_channels, img_dim, img_dim))\n",
    "    \n",
    "    for latent in range(z_dim):\n",
    "        var_z0 = torch.zeros(nbr_steps, z_dim)\n",
    "        val = mu_mean[latent] - sigma_mean[latent]\n",
    "        step = 2.0 * sigma_mean[latent] / nbr_steps\n",
    "#         print(latent, mu_mean[latent], step)\n",
    "        for i in range(nbr_steps) :\n",
    "            var_z0[i] = mu_mean\n",
    "            var_z0[i][latent] = val\n",
    "            val += step\n",
    "\n",
    "        var_z0 = torch.Tensor(var_z0)\n",
    "        if use_cuda :\n",
    "            var_z0 = var_z0.cuda()\n",
    "        gen_images_latent = generator.decoder(var_z0)\n",
    "        gen_images_latent = gen_images_latent.view(-1, color_channels, img_dim, img_dim).cpu().data\n",
    "        gen_images = torch.cat([gen_images,gen_images_latent], dim=0)\n",
    "    save_image(gen_images,'./beta-data/{}/gen_images/{}.png'.format(path,(epoch+1)) )\n",
    "    \n",
    "    mu_mean = 0.0\n",
    "    sigma_mean = 0.0\n",
    "    \n",
    "    for i, (images, _) in enumerate(train_loader):\n",
    "        images = torch.Tensor((images.view(-1,1,img_dim, img_dim) ))\n",
    "        if use_cuda :\n",
    "            images = images.cuda() \n",
    "\n",
    "        out, mu, log_var = generator(images)\n",
    "\n",
    "        mu_mean += torch.mean(mu.data,dim=0)\n",
    "        sigma_mean += torch.mean(torch.sqrt(torch.exp(log_var.data)), dim=0 )\n",
    "\n",
    "        # Compute :\n",
    "        #reconstruction loss :\n",
    "        reconst_loss = F.binary_cross_entropy(out, images, size_average=False)\n",
    "        #reconst_loss = torch.mean( (out.view(-1) - images.view(-1))**2 )\n",
    "\n",
    "        # expected log likelyhood :\n",
    "        expected_log_lik = torch.mean(Bernoulli(out.view((-1))).log_prob(images.view((-1))))\n",
    "        #expected_log_lik = torch.mean( Bernoulli( out ).log_prob( images ) )\n",
    "\n",
    "        # kl divergence :\n",
    "        #kl_divergence = 0.5 * torch.mean( torch.sum( (mu**2 + torch.exp(log_var) - log_var -1), dim=1) )\n",
    "        kl_divergence = 0.5 * torch.sum((mu**2 + torch.exp(log_var) - log_var -1))\n",
    "\n",
    "        # ELBO :\n",
    "        elbo = expected_log_lik - generator.beta * kl_divergence\n",
    "\n",
    "        # TOTAL LOSS :\n",
    "        total_loss = reconst_loss + generator.beta*kl_divergence\n",
    "        #total_loss = reconst_loss\n",
    "        #total_loss = -elbo\n",
    "\n",
    "        # Backprop + Optimize :\n",
    "        optimizer.zero_grad()\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print (\"Epoch[%d/%d], Step [%d/%d], Total Loss: %.4f, \"\n",
    "                   \"Reconst Loss: %.4f, KL Div: %.7f, E[ |~| p(x|theta)]: %.7f \" \n",
    "                   %(epoch+1, 50, i+1, iter_per_epoch, total_loss.data[0], \n",
    "                     reconst_loss.data[0], kl_divergence.data[0],expected_log_lik.exp().data[0]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.Module._module"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
