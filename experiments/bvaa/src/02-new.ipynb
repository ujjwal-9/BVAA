{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision.utils import save_image\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer\n",
    "from collections import defaultdict\n",
    "from tqdm import trange\n",
    "\n",
    "class Trainer():\n",
    "    def __init__(self, model, optimizer, loss_f, device, save_dir=\"results\", is_progress_bar=True):\n",
    "            self.device = device\n",
    "            self.model = model.to(device)\n",
    "            self.loss_f = loss_f\n",
    "            self.optimizer = optimizer\n",
    "            self.save_dir = save_dir\n",
    "            self.is_progress_bar = is_progress_bar\n",
    "            \n",
    "    def __call__(self, data_loader, epochs=10, checkpoint_every=10):\n",
    "        start = default_timer()\n",
    "        self.model.train()\n",
    "        for epoch in range(epochs):\n",
    "            storer = defaultdict(list)\n",
    "            mean_epoch_loss = self._train_epoch(data_loader, storer, epoch)\n",
    "            mean_epoch_loss = self._test_epoch(data_loader, storer, epoch)\n",
    "            with torch.no_grad():\n",
    "                sample = torch.randn(64, self.model.latent_dim).to(device)\n",
    "                sample = self.model.decoder(sample).cpu()  # make sure on cpu\n",
    "                save_image(sample.view(64, 1, 32, 32),\n",
    "                           './results/samples/' + str(epoch) + '.png')\n",
    "            \n",
    "    def _train_epoch(self, data_loader, storer, epoch):\n",
    "        epoch_loss = 0.\n",
    "        kwargs = dict(desc=\"Epoch {}\".format(epoch + 1), leave=False,\n",
    "                      disable=not self.is_progress_bar)\n",
    "        with trange(len(data_loader), **kwargs) as t:\n",
    "            for _, (data, _) in enumerate(data_loader):\n",
    "                iter_loss = self._train_iteration(data, storer)\n",
    "                epoch_loss += iter_loss\n",
    "                t.set_postfix(loss=iter_loss)\n",
    "                t.update()\n",
    "        mean_epoch_loss = epoch_loss / len(data_loader)\n",
    "        return mean_epoch_loss\n",
    "    \n",
    "    def _train_iteration(self, data, storer):\n",
    "        batch_size, channel, height, width = data.size()\n",
    "        data = data.to(self.device)\n",
    "        recon_batch, latent_dist, latent_sample = self.model(data)\n",
    "        loss = self.loss_f(data, recon_batch, latent_dist, self.model.training, \n",
    "                           storer, latent_sample=latent_sample)\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "            \n",
    "        return loss.item()\n",
    "    \n",
    "    def _test_epoch(self, data_loader, storer, epoch):\n",
    "        epoch_loss = 0.\n",
    "        kwargs = dict(desc=\"Epoch {}\".format(epoch + 1), leave=False,\n",
    "                      disable=not self.is_progress_bar)\n",
    "        with trange(len(data_loader), **kwargs) as t:\n",
    "            for _, (data, _) in enumerate(data_loader):\n",
    "                iter_loss = self._train_iteration(data, storer)\n",
    "                epoch_loss += iter_loss\n",
    "                t.set_postfix(loss=iter_loss)\n",
    "                t.update()\n",
    "        mean_epoch_loss = epoch_loss / len(data_loader)\n",
    "        return mean_epoch_loss\n",
    "    \n",
    "    def _test_iteration(self, data, storer):\n",
    "        batch_size, channel, height, width = data.size()\n",
    "        data = data.to(self.device)\n",
    "        recon_batch, latent_dist, latent_sample = self.model(data)\n",
    "        loss = self.loss_f(data, recon_batch, latent_dist, self.model.training, \n",
    "                               storer, latent_sample=latent_sample)\n",
    "            \n",
    "        return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOSSES = [\"betaH\", \"betaB\"]\n",
    "RECON_DIST = [\"bernoulli\", \"laplace\", \"gaussian\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "mnist_dataset = datasets.MNIST('../../data', \n",
    "                   train=True, \n",
    "                   download=True, \n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.Resize(32),\n",
    "                       transforms.ToTensor()\n",
    "                   ]))\n",
    "\n",
    "mnist_dataset_test = datasets.MNIST('../../data', train=False, download=True, transform=transforms.Compose([\n",
    "                       transforms.Resize(32),\n",
    "                       transforms.ToTensor()\n",
    "                   ]))\n",
    "\n",
    "train_loader = DataLoader(mnist_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_loader = DataLoader(mnist_dataset_test, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vae import VAE\n",
    "from encoder import Encoder\n",
    "from decoder import Decoder\n",
    "from losses import get_loss_fn\n",
    "from torch import optim\n",
    "\n",
    "latent_dim = 12\n",
    "img_size = [1,32,32]\n",
    "\n",
    "lr = 5e-4\n",
    "\n",
    "betaB_args = {\"rec_dist\": \"bernoulli\",\n",
    "              \"reg_anneal\": 10000, \n",
    "              \"betaH_B\": 4,\n",
    "              \"betaB_initC\": 0,\n",
    "              \"betaB_finC\": 25,\n",
    "              \"betaB_G\": 100\n",
    "             }\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "loss_f = get_loss_fn(\"betaB\", n_data=len(train_loader.dataset), device=device, **betaB_args)\n",
    "\n",
    "encoder = Encoder(img_size, latent_dim)\n",
    "decoder = Decoder(img_size, latent_dim)\n",
    "\n",
    "generator_model = VAE(img_size, latent_dim, encoder, decoder).to(device)\n",
    "optimizer = optim.Adam(generator_model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator_model.load_state_dict(torch.load('test.pt'))\n",
    "# torch.save(trainer.model.state_dict(), 'test.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = enumerate(test_loader)\n",
    "batch_idx, (example_data, example_targets) = next(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f35b9b69898>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i=3\n",
    "recon_img,_,_ = generator_model(torch.FloatTensor(example_data[i]).unsqueeze(0).to(device))\n",
    "plt.imshow(recon_img[0][0].detach().cpu().numpy(), cmap='gray', interpolation='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f868be05e10>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(example_data[i][0].detach().cpu().numpy(), cmap='gray', interpolation='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.optim.lr_scheduler import StepLR\n",
    "# class Net(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(Net, self).__init__()\n",
    "#         self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "#         self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "#         self.dropout1 = nn.Dropout2d(0.25)\n",
    "#         self.dropout2 = nn.Dropout2d(0.5)\n",
    "#         self.fc1 = nn.Linear(12544, 128)\n",
    "#         self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.conv1(x)\n",
    "#         x = F.relu(x)\n",
    "#         x = self.conv2(x)\n",
    "#         x = F.max_pool2d(x, 2)\n",
    "#         x = self.dropout1(x)\n",
    "#         x = torch.flatten(x, 1)\n",
    "#         x = self.fc1(x)\n",
    "#         x = F.relu(x)\n",
    "#         x = self.dropout2(x)\n",
    "#         x = self.fc2(x)\n",
    "#         output = F.log_softmax(x, dim=1)\n",
    "#         return output\n",
    "\n",
    "# def train(model, device, train_loader, optimizer, epoch):\n",
    "#     model.train()\n",
    "#     for batch_idx, (data, target) in enumerate(train_loader):\n",
    "#         data, target = data.to(device), target.to(device)\n",
    "# #         data_hat,_,_ = vae_model(data)\n",
    "#         optimizer.zero_grad()\n",
    "#         output = model(data)\n",
    "#         loss = F.nll_loss(output, target)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         if batch_idx % log_interval == 0:\n",
    "#             print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "#                 epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "#                 100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "# def test(model, vae_model, device, test_loader):\n",
    "#     model.eval()\n",
    "#     test_loss = 0\n",
    "#     correct = 0\n",
    "#     with torch.no_grad():\n",
    "#         for data, target in test_loader:\n",
    "#             data, target = data.to(device), target.to(device)\n",
    "#             data_hat,_,_ = vae_model(data)\n",
    "#             data_hat.re\n",
    "#             output = model(data_hat)\n",
    "#             test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "#             pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "#             correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "#     test_loss /= len(test_loader.dataset)\n",
    "\n",
    "#     print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "#         test_loss, correct, len(test_loader.dataset),\n",
    "#         100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_batch_size = 1000\n",
    "# batch_size = 64\n",
    "# epochs = 2\n",
    "# lr = 0.1\n",
    "# gamma = 0.7\n",
    "# seed = 1\n",
    "# no_cuda = False\n",
    "# log_interval = 1000\n",
    "# save_model = True\n",
    "# use_cuda = True\n",
    "# torch.manual_seed(seed)\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')\n",
    "# kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
    "\n",
    "# model_classification = Net().to(device)\n",
    "# optimizer = optim.Adadelta(model_classification.parameters(), lr=lr)\n",
    "\n",
    "\n",
    "\n",
    "# scheduler = StepLR(optimizer, step_size=1, gamma=gamma)\n",
    "# for epoch in range(1, epochs + 1):\n",
    "#     train(model_classification, device, train_loader, optimizer, epoch)\n",
    "#     test(model_classification, generator_model, device, test_loader)\n",
    "#     scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
       "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
       "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "model = Net().to(device)\n",
    "\n",
    "# Load the pretrained model\n",
    "model.load_state_dict(torch.load('lenet_mnist_model.pth', map_location='cpu'))\n",
    "\n",
    "# Set the model in evaluation mode. In this case this is for the Dropout layers\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(mnist_dataset_test, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fgsm_attack(image, epsilon, data_grad):\n",
    "    # Collect the element-wise sign of the data gradient\n",
    "    sign_data_grad = data_grad.sign()\n",
    "    # Create the perturbed image by adjusting each pixel of the input image\n",
    "    perturbed_image = image + epsilon*sign_data_grad\n",
    "    # Adding clipping to maintain [0,1] range\n",
    "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
    "    # Return the perturbed image\n",
    "    return perturbed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self, generator, classifier, train=True):\n",
    "        super(Network, self).__init__()\n",
    "        self.generator = generator\n",
    "        self.classifier = classifier\n",
    "        self.train = train\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if self.train:\n",
    "            self.generator.train()\n",
    "        else:\n",
    "            self.generator.eval()\n",
    "        x, latent_distribution, latent_sample = self.generator(x)\n",
    "        x = F.interpolate(x, size=28)\n",
    "        x = self.classifier(x)\n",
    "        return x, latent_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_complete = Network(generator_model, model, train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test( model_complete, model, device, test_loader, epsilon ):\n",
    "\n",
    "    # Accuracy counter\n",
    "    correct = 0\n",
    "    adv_examples = []\n",
    "\n",
    "    # Loop over all examples in test set\n",
    "    for data, target in test_loader:\n",
    "\n",
    "        # Send the data and label to the device\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "#         data_hat, latent_distribution, latent_sample = generator(data)\n",
    "#         data_hat = F.interpolate(data_hat, size=28)\n",
    "#         print(latent_sample.requires_grad)\n",
    "        # Set requires_grad attribute of tensor. Important for Attack\n",
    "#         data_hat.requires_grad = True\n",
    "\n",
    "        # Forward pass the data through the model\n",
    "        output, latent_sample = model_complete(data)\n",
    "        init_pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "\n",
    "        # If the initial prediction is wrong, dont bother attacking, just move on\n",
    "        if init_pred.item() != target.item():\n",
    "            continue\n",
    "\n",
    "        # Calculate the loss\n",
    "        loss = F.nll_loss(output, target)\n",
    "\n",
    "        # Zero all existing gradients\n",
    "        model_complete.zero_grad()\n",
    "\n",
    "        # Calculate gradients of model in backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Collect datagrad\n",
    "        data_grad = latent_sample.grad.data\n",
    "\n",
    "        # Call FGSM Attack\n",
    "        perturbed_data = fgsm_attack(latent_sample, epsilon, data_grad)\n",
    "\n",
    "        # Re-classify the perturbed image\n",
    "        output = model(model_complete.generator.decoder(perturbed_data))\n",
    "\n",
    "        # Check for success\n",
    "        final_pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "        if final_pred.item() == target.item():\n",
    "            correct += 1\n",
    "            # Special case for saving 0 epsilon examples\n",
    "            if (epsilon == 0) and (len(adv_examples) < 5):\n",
    "                adv_ex = perturbed_data.squeeze().detach().cpu().numpy()\n",
    "                adv_examples.append( (init_pred.item(), final_pred.item(), adv_ex) )\n",
    "        else:\n",
    "            # Save some adv examples for visualization later\n",
    "            if len(adv_examples) < 5:\n",
    "                adv_ex = perturbed_data.squeeze().detach().cpu().numpy()\n",
    "                adv_examples.append( (init_pred.item(), final_pred.item(), adv_ex) )\n",
    "\n",
    "    # Calculate final accuracy for this epsilon\n",
    "    final_acc = correct/float(len(test_loader))\n",
    "    print(\"Epsilon: {}\\tTest Accuracy = {} / {} = {}\".format(epsilon, correct, len(test_loader), final_acc))\n",
    "\n",
    "    # Return the accuracy and an adversarial example\n",
    "    return final_acc, adv_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[-1, 320]' is invalid for input of size 500",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-c1d697e9cc0a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Run test for each epsilon\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0meps\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepsilons\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0maccuracies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mexamples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-985808a7d5ea>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(model_complete, model, device, test_loader, epsilon)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m# Forward pass the data through the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_complete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0minit_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# get the index of the max log-probability\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/bvaa/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-17c649075065>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2_drop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m320\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[-1, 320]' is invalid for input of size 500"
     ]
    }
   ],
   "source": [
    "epsilons = [0, .05, .1, .15, .2, .25, .3]\n",
    "use_cuda = True\n",
    "accuracies = []\n",
    "examples = []\n",
    "\n",
    "# Run test for each epsilon\n",
    "for eps in epsilons:\n",
    "    acc, ex = test(model, generator_model, device, test_loader, eps)\n",
    "    accuracies.append(acc)\n",
    "    examples.append(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "plt.plot(epsilons, accuracies, \"*-\")\n",
    "plt.yticks(np.arange(0, 1.1, step=0.1))\n",
    "plt.xticks(np.arange(0, .35, step=0.05))\n",
    "plt.title(\"Accuracy vs Epsilon\")\n",
    "plt.xlabel(\"Epsilon\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "plt.figure(figsize=(8,10))\n",
    "for i in range(len(epsilons)):\n",
    "    for j in range(len(examples[i])):\n",
    "        cnt += 1\n",
    "        plt.subplot(len(epsilons),len(examples[0]),cnt)\n",
    "        plt.xticks([], [])\n",
    "        plt.yticks([], [])\n",
    "        if j == 0:\n",
    "            plt.ylabel(\"Eps: {}\".format(epsilons[i]), fontsize=14)\n",
    "        orig,adv,ex = examples[i][j]\n",
    "        plt.title(\"{} -> {}\".format(orig, adv))\n",
    "        plt.imshow(ex, cmap=\"gray\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
