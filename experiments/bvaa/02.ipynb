{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision.utils import save_image\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "TRAIN_LOSSES_LOGFILE = \"train_losses.log\"\n",
    "\n",
    "class LossesLogger(object):\n",
    "    def __init__(self, file_path_name):\n",
    "        if os.path.isfile(file_path_name):\n",
    "            os.remove(file_path_name)\n",
    "        \n",
    "        self.logger = logging.getLogger(\"losses_logger\")\n",
    "        self.logger.setLevel(1)\n",
    "        file_handler = logging.FileHandler(file_path_name)\n",
    "        file_handler.setLevel(1)\n",
    "        self.logger.addHandler(file_handler)\n",
    "        \n",
    "        header = \",\".join([\"Epoch\", \"Loss\", \"Value\"])\n",
    "        self.logger.debug(header)\n",
    "    \n",
    "    def log(self, epoch, losses_storer):\n",
    "        for k, v in losses_storer.item():\n",
    "            log_string = \",\".join(str(item) for item in [epoch, k, sum(v)/len(l)])\n",
    "            self.logger.debug(log_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer\n",
    "from collections import defaultdict\n",
    "from tqdm import trange\n",
    "\n",
    "class Trainer():\n",
    "    def __init__(self, model, optimizer, loss_f, device, logger=logging.getLogger(__name__),\n",
    "                 save_dir=\"results\", is_progress_bar=True):\n",
    "            self.device = device\n",
    "            self.model = model.to(device)\n",
    "            self.loss_f = loss_f\n",
    "            self.optimizer = optimizer\n",
    "            self.save_dir = save_dir\n",
    "            self.is_progress_bar = is_progress_bar\n",
    "            self.logger = logger\n",
    "            self.losses_logger = LossesLogger(os.path.join(self.save_dir, TRAIN_LOSSES_LOGFILE))\n",
    "            self.logger.info(\"Training Device: {}\".format(self.device))\n",
    "            \n",
    "    def __call__(self, data_loader, epochs=10, checkpoint_every=10):\n",
    "        start = default_timer()\n",
    "        self.model.train()\n",
    "        for epoch in range(epochs):\n",
    "            storer = defaultdict(list)\n",
    "            mean_epoch_loss = self._train_epoch(data_loader, storer, epoch)\n",
    "            mean_epoch_loss = self._test_epoch(data_loader, storer, epoch)\n",
    "            with torch.no_grad():\n",
    "                sample = torch.randn(64, self.model.latent_dim).to(device)\n",
    "                sample = self.model.decoder(sample).cpu()  # make sure on cpu\n",
    "                save_image(sample.view(64, 1, 32, 32),\n",
    "                           './results/samples/' + str(epoch) + '.png')\n",
    "            \n",
    "    def _train_epoch(self, data_loader, storer, epoch):\n",
    "        epoch_loss = 0.\n",
    "        kwargs = dict(desc=\"Epoch {}\".format(epoch + 1), leave=False,\n",
    "                      disable=not self.is_progress_bar)\n",
    "        with trange(len(data_loader), **kwargs) as t:\n",
    "            for _, (data, _) in enumerate(data_loader):\n",
    "                iter_loss = self._train_iteration(data, storer)\n",
    "                epoch_loss += iter_loss\n",
    "                t.set_postfix(loss=iter_loss)\n",
    "                t.update()\n",
    "        mean_epoch_loss = epoch_loss / len(data_loader)\n",
    "        return mean_epoch_loss\n",
    "    \n",
    "    def _train_iteration(self, data, storer):\n",
    "        batch_size, channel, height, width = data.size()\n",
    "        data = data.to(self.device)\n",
    "        recon_batch, latent_dist, latent_sample = self.model(data)\n",
    "        loss = self.loss_f(data, recon_batch, latent_dist, self.model.training, \n",
    "                           storer, latent_sample=latent_sample)\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "            \n",
    "        return loss.item()\n",
    "    \n",
    "    def _test_epoch(self, data_loader, storer, epoch):\n",
    "        epoch_loss = 0.\n",
    "        kwargs = dict(desc=\"Epoch {}\".format(epoch + 1), leave=False,\n",
    "                      disable=not self.is_progress_bar)\n",
    "        with trange(len(data_loader), **kwargs) as t:\n",
    "            for _, (data, _) in enumerate(data_loader):\n",
    "                iter_loss = self._train_iteration(data, storer)\n",
    "                epoch_loss += iter_loss\n",
    "                t.set_postfix(loss=iter_loss)\n",
    "                t.update()\n",
    "        mean_epoch_loss = epoch_loss / len(data_loader)\n",
    "        return mean_epoch_loss\n",
    "    \n",
    "    def _test_iteration(self, data, storer):\n",
    "        batch_size, channel, height, width = data.size()\n",
    "        data = data.to(self.device)\n",
    "        recon_batch, latent_dist, latent_sample = self.model(data)\n",
    "        loss = self.loss_f(data, recon_batch, latent_dist, self.model.training, \n",
    "                               storer, latent_sample=latent_sample)\n",
    "            \n",
    "        return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOSSES = [\"betaH\", \"betaB\"]\n",
    "RECON_DIST = [\"bernoulli\", \"laplace\", \"gaussian\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "mnist_dataset = datasets.MNIST('../../data', \n",
    "                   train=True, \n",
    "                   download=True, \n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.Resize(32),\n",
    "                       transforms.ToTensor()\n",
    "                   ]))\n",
    "\n",
    "mnist_dataset_test = datasets.MNIST('../../data', train=False, download=True, transform=transforms.Compose([\n",
    "                       transforms.Resize(32),\n",
    "                       transforms.ToTensor()\n",
    "                   ]))\n",
    "\n",
    "train_loader = DataLoader(mnist_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_loader = DataLoader(mnist_dataset_test, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RES_DIR = \"./results\"\n",
    "# formatter = logging.Formatter('%(asctime)s %(levelname)s - %(funcName)s: %(message)s',\n",
    "#                                   \"%H:%M:%S\")\n",
    "# logger = logging.getLogger(__name__)\n",
    "# logger.setLevel(1)\n",
    "# stream = logging.StreamHandler()\n",
    "# stream.setLevel(1)\n",
    "# stream.setFormatter(formatter)\n",
    "# logger.addHandler(stream)\n",
    "\n",
    "# exp_dir = os.path.join(RES_DIR, \"first\")\n",
    "# logger.info(\"Root directory for saving and loading experiments: {}\".format(exp_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vae import VAE\n",
    "from encoder import Encoder\n",
    "from decoder import Decoder\n",
    "from losses import get_loss_fn\n",
    "from torch import optim\n",
    "\n",
    "latent_dim = 12\n",
    "img_size = [1,32,32]\n",
    "\n",
    "lr = 5e-4\n",
    "\n",
    "betaB_args = {\"rec_dist\": \"bernoulli\",\n",
    "              \"reg_anneal\": 10000, \n",
    "              \"betaH_B\": 4,\n",
    "              \"betaB_initC\": 0,\n",
    "              \"betaB_finC\": 25,\n",
    "              \"betaB_G\": 100\n",
    "             }\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "loss_f = get_loss_fn(\"betaB\", n_data=len(train_loader.dataset), device=device, **betaB_args)\n",
    "\n",
    "encoder = Encoder(img_size, latent_dim)\n",
    "decoder = Decoder(img_size, latent_dim)\n",
    "\n",
    "generator_model = VAE(img_size, latent_dim, encoder, decoder).to(device)\n",
    "optimizer = optim.Adam(generator_model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:16:39 INFO - __init__: Training Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# trainer = Trainer(generator_model, optimizer, loss_f, device, logger=logger,\n",
    "#                  save_dir=exp_dir, is_progress_bar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs = 100\n",
    "# checkpoint_every = 10\n",
    "# trainer(train_loader, epochs=epochs, checkpoint_every=checkpoint_every)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator_model.load_state_dict(torch.load('test.pt'))\n",
    "# torch.save(trainer.model.state_dict(), 'test.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = enumerate(test_loader)\n",
    "batch_idx, (example_data, example_targets) = next(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f86ca698be0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i=3\n",
    "recon_img,_,_ = generator_model(torch.FloatTensor(example_data[i]).unsqueeze(0).to(device))\n",
    "plt.imshow(recon_img[0][0].detach().cpu().numpy(), cmap='gray', interpolation='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f868be05e10>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(example_data[i][0].detach().cpu().numpy(), cmap='gray', interpolation='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.optim.lr_scheduler import StepLR\n",
    "# class Net(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(Net, self).__init__()\n",
    "#         self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "#         self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "#         self.dropout1 = nn.Dropout2d(0.25)\n",
    "#         self.dropout2 = nn.Dropout2d(0.5)\n",
    "#         self.fc1 = nn.Linear(12544, 128)\n",
    "#         self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.conv1(x)\n",
    "#         x = F.relu(x)\n",
    "#         x = self.conv2(x)\n",
    "#         x = F.max_pool2d(x, 2)\n",
    "#         x = self.dropout1(x)\n",
    "#         x = torch.flatten(x, 1)\n",
    "#         x = self.fc1(x)\n",
    "#         x = F.relu(x)\n",
    "#         x = self.dropout2(x)\n",
    "#         x = self.fc2(x)\n",
    "#         output = F.log_softmax(x, dim=1)\n",
    "#         return output\n",
    "\n",
    "# def train(model, device, train_loader, optimizer, epoch):\n",
    "#     model.train()\n",
    "#     for batch_idx, (data, target) in enumerate(train_loader):\n",
    "#         data, target = data.to(device), target.to(device)\n",
    "# #         data_hat,_,_ = vae_model(data)\n",
    "#         optimizer.zero_grad()\n",
    "#         output = model(data)\n",
    "#         loss = F.nll_loss(output, target)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         if batch_idx % log_interval == 0:\n",
    "#             print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "#                 epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "#                 100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "# def test(model, vae_model, device, test_loader):\n",
    "#     model.eval()\n",
    "#     test_loss = 0\n",
    "#     correct = 0\n",
    "#     with torch.no_grad():\n",
    "#         for data, target in test_loader:\n",
    "#             data, target = data.to(device), target.to(device)\n",
    "#             data_hat,_,_ = vae_model(data)\n",
    "#             data_hat.re\n",
    "#             output = model(data_hat)\n",
    "#             test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "#             pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "#             correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "#     test_loss /= len(test_loader.dataset)\n",
    "\n",
    "#     print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "#         test_loss, correct, len(test_loader.dataset),\n",
    "#         100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_batch_size = 1000\n",
    "# batch_size = 64\n",
    "# epochs = 2\n",
    "# lr = 0.1\n",
    "# gamma = 0.7\n",
    "# seed = 1\n",
    "# no_cuda = False\n",
    "# log_interval = 1000\n",
    "# save_model = True\n",
    "# use_cuda = True\n",
    "# torch.manual_seed(seed)\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')\n",
    "# kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
    "\n",
    "# model_classification = Net().to(device)\n",
    "# optimizer = optim.Adadelta(model_classification.parameters(), lr=lr)\n",
    "\n",
    "\n",
    "\n",
    "# scheduler = StepLR(optimizer, step_size=1, gamma=gamma)\n",
    "# for epoch in range(1, epochs + 1):\n",
    "#     train(model_classification, device, train_loader, optimizer, epoch)\n",
    "#     test(model_classification, generator_model, device, test_loader)\n",
    "#     scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
       "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
       "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "model = Net().to(device)\n",
    "\n",
    "# Load the pretrained model\n",
    "model.load_state_dict(torch.load('lenet_mnist_model.pth', map_location='cpu'))\n",
    "\n",
    "# Set the model in evaluation mode. In this case this is for the Dropout layers\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(mnist_dataset_test, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fgsm_attack(image, epsilon, data_grad):\n",
    "    # Collect the element-wise sign of the data gradient\n",
    "    sign_data_grad = data_grad.sign()\n",
    "    # Create the perturbed image by adjusting each pixel of the input image\n",
    "    perturbed_image = image + epsilon*sign_data_grad\n",
    "    # Adding clipping to maintain [0,1] range\n",
    "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
    "    # Return the perturbed image\n",
    "    return perturbed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self, generator, classifier, train=True):\n",
    "        super(Network, self).__init__()\n",
    "        self.generator = generator\n",
    "        self.classifier = classifier\n",
    "        self.train = train\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if self.train:\n",
    "            self.generator.train()\n",
    "        else:\n",
    "            self.generator.eval()\n",
    "        x, latent_distribution, latent_sample = self.generator(x)\n",
    "        x = F.interpolate(x, size=28)\n",
    "        x = self.classifier(x)\n",
    "        return x, latent_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_complete = Network(generator_model, model, train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test( model_complete, model, device, test_loader, epsilon ):\n",
    "\n",
    "    # Accuracy counter\n",
    "    correct = 0\n",
    "    adv_examples = []\n",
    "\n",
    "    # Loop over all examples in test set\n",
    "    for data, target in test_loader:\n",
    "\n",
    "        # Send the data and label to the device\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "#         data_hat, latent_distribution, latent_sample = generator(data)\n",
    "#         data_hat = F.interpolate(data_hat, size=28)\n",
    "#         print(latent_sample.requires_grad)\n",
    "        # Set requires_grad attribute of tensor. Important for Attack\n",
    "#         data_hat.requires_grad = True\n",
    "\n",
    "        # Forward pass the data through the model\n",
    "        output, latent_sample = model_complete(data)\n",
    "        init_pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "\n",
    "        # If the initial prediction is wrong, dont bother attacking, just move on\n",
    "        if init_pred.item() != target.item():\n",
    "            continue\n",
    "\n",
    "        # Calculate the loss\n",
    "        loss = F.nll_loss(output, target)\n",
    "\n",
    "        # Zero all existing gradients\n",
    "        model_complete.zero_grad()\n",
    "\n",
    "        # Calculate gradients of model in backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Collect datagrad\n",
    "        data_grad = latent_sample.grad.data\n",
    "\n",
    "        # Call FGSM Attack\n",
    "        perturbed_data = fgsm_attack(latent_sample, epsilon, data_grad)\n",
    "\n",
    "        # Re-classify the perturbed image\n",
    "        output = model(model_complete.generator.decoder(perturbed_data))\n",
    "\n",
    "        # Check for success\n",
    "        final_pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "        if final_pred.item() == target.item():\n",
    "            correct += 1\n",
    "            # Special case for saving 0 epsilon examples\n",
    "            if (epsilon == 0) and (len(adv_examples) < 5):\n",
    "                adv_ex = perturbed_data.squeeze().detach().cpu().numpy()\n",
    "                adv_examples.append( (init_pred.item(), final_pred.item(), adv_ex) )\n",
    "        else:\n",
    "            # Save some adv examples for visualization later\n",
    "            if len(adv_examples) < 5:\n",
    "                adv_ex = perturbed_data.squeeze().detach().cpu().numpy()\n",
    "                adv_examples.append( (init_pred.item(), final_pred.item(), adv_ex) )\n",
    "\n",
    "    # Calculate final accuracy for this epsilon\n",
    "    final_acc = correct/float(len(test_loader))\n",
    "    print(\"Epsilon: {}\\tTest Accuracy = {} / {} = {}\".format(epsilon, correct, len(test_loader), final_acc))\n",
    "\n",
    "    # Return the accuracy and an adversarial example\n",
    "    return final_acc, adv_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[-1, 320]' is invalid for input of size 500",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-c1d697e9cc0a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Run test for each epsilon\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0meps\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepsilons\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0maccuracies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mexamples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-985808a7d5ea>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(model_complete, model, device, test_loader, epsilon)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m# Forward pass the data through the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_complete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0minit_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# get the index of the max log-probability\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/bvaa/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-17c649075065>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2_drop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m320\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[-1, 320]' is invalid for input of size 500"
     ]
    }
   ],
   "source": [
    "epsilons = [0, .05, .1, .15, .2, .25, .3]\n",
    "use_cuda = True\n",
    "accuracies = []\n",
    "examples = []\n",
    "\n",
    "# Run test for each epsilon\n",
    "for eps in epsilons:\n",
    "    acc, ex = test(model, generator_model, device, test_loader, eps)\n",
    "    accuracies.append(acc)\n",
    "    examples.append(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "plt.plot(epsilons, accuracies, \"*-\")\n",
    "plt.yticks(np.arange(0, 1.1, step=0.1))\n",
    "plt.xticks(np.arange(0, .35, step=0.05))\n",
    "plt.title(\"Accuracy vs Epsilon\")\n",
    "plt.xlabel(\"Epsilon\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "plt.figure(figsize=(8,10))\n",
    "for i in range(len(epsilons)):\n",
    "    for j in range(len(examples[i])):\n",
    "        cnt += 1\n",
    "        plt.subplot(len(epsilons),len(examples[0]),cnt)\n",
    "        plt.xticks([], [])\n",
    "        plt.yticks([], [])\n",
    "        if j == 0:\n",
    "            plt.ylabel(\"Eps: {}\".format(epsilons[i]), fontsize=14)\n",
    "        orig,adv,ex = examples[i][j]\n",
    "        plt.title(\"{} -> {}\".format(orig, adv))\n",
    "        plt.imshow(ex, cmap=\"gray\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
