{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a JointVAE model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get MNIST data\n",
    "Build a simple JointVAE model on MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "VAE_TRAIN = False\n",
    "FIND_DIST = False\n",
    "FOLDER = \"dist5-celeba\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloaders import get_celeba_dataloader\n",
    "\n",
    "train_loader, test_loader = get_celeba_dataloader(path_to_data='/home/data/bvaa/CelebA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchvision import datasets, transforms\n",
    "# all_transforms = transforms.Compose([\n",
    "#         transforms.Resize(32),\n",
    "#         transforms.ToTensor()\n",
    "#     ])\n",
    "# train_data = datasets.CIFAR10('/home/data/bvaa/', train=True, download=True,\n",
    "#                                 transform=all_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = enumerate(test_loader)\n",
    "batch_idx, (example_data,target) = next(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f76025939b0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD7CAYAAACscuKmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO29a5Bc13UeutY5/Z73GwMMCIAEQIA0RZCEKEqkLEqiFMVWSa5cPyInKSWlhPmhpJRKci3pum7KiZ1ELlf5UamUb3glx0rsWFISKVR4E9kSTVqSLVGCSPAJkHgQ73lh3jM9/Tq974/uOetbq6cbQwLoodT7q5qafXrv3meffc7us9Zea32LnXPk4eHxk49guwfg4eHRHvjF7uHRIfCL3cOjQ+AXu4dHh8Avdg+PDoFf7B4eHYLrWuzM/CFmfpWZTzPzZ27UoDw8PG48+M3a2Zk5JKLXiOgDRHSJiH5IRB9zzr1y44bn4eFxo5C4ju/eT0SnnXNniYiY+UtE9FEiarrYB/p63c7RkdoB29qGD5pUtWrHW2lFjpvX6lO16qXFkFzLszf9WrUaxeVypYwVql2pJHVBoIWzcqkUlwuFQlyOoki1Y7g20z1VKpVN26VSKd0QLqBqOqk6OQ6DkJohiuRcgZnvTCYTl8tluGbW19zd0xOXs105cwbpU8+VPpejN/fSw5flFp+Wxj62drClustT07SwtLTpUK5nse8iootwfImI3tHqCztHR+hPfu/f1g7MA8Ch3Ai7VjghbVlNqXmI4GYG9gEL4OHGHwXzgKnvhaYPbIoPnFGG2Mm0OrPIgkBuUkC6Lr+2GpdnZ6ficmV9VbW7culKXM5l9cN96cKluPzaidfi8vLSomqXSCbjcqGgxzF7dSEuh9Bu994J1S5MyoXn82uqbn19PS73wGK0WFyQc+Uy+nE8dOD2uDwzOR2X0+mMaveuhx+Oy2+77x5V51h+oHJdXXHZ3nf8sbILHxd01dZFeD8F3OK3w7H9YcT+qpuW6wOBOn3PXL2TX3z0k03Pez06+2a/Hg2XyMyPMvMxZj62sLR8Hafz8PC4HlzPm/0SEe2G4wkiumIbOeceI6LHiIjuPHCbI97890XtHWxVfL4J2Kowt9UROtsSf8VNFYrxOB8o6hIRMYqjZs9FvaHwTdBqkK3UmhZSUKtOG9puMj4icy0t4EAtsONNp416oU7QrL/mg+cGEb9V929C/LdfeRP7ZvYbGxJHq56u583+QyI6wMz7mDlFRH+TiL5+Hf15eHjcRLzpN7tzrsLM/4iI/pRqyvMfOOdevmEj8/DwuKG4HjGenHP/i4j+1w0ai4eHx03EdS32n0TciN0C7MOak1CrctXm+jYisnoudGnVPTSxvVmzkPoenKzVtVjTnjUJNkMIVhgzHXoXvNr8WlJJ0NlNH1b/jj8317JVf5M3os+/1eDdZT08OgR+sXt4dAh+7MR4LTaxOZLjBsecG2zNw+6sBLh10c6Kkpu3qkZWjIffaHNdzcR4OwFaRNb94zCU6c2I5o42N/MRaTG+pZkLriVs8epR6oQZRwjOTxyYCbHHNxNu0yIRvRE16uYpBv7N7uHRIfCL3cOjQ+AXu4dHh2AbdPYbp0O1dmN8c53cEHfZrXbSoOxvbvKyZq1QucvqLpoFdLQM7jD9IwLQeRtdYDFyTvePJjU8NboE6x6IEgn9OOKYUS+3+w+owzeY2rbinm3r7M5Qi5vtmpTfrKnzzTO7X/uL/s3u4dEh8Ivdw6ND0H4xfkNOeSO2sCYmpKoV5/C4QXwD0w0KWVbqa3ZeW9tKtNui51pD8BOUUTStVnTUm75O3UcZ2kbQo/XNC5VobWtRnUATmmmGps5IVwYgdjvsvyFKT0gpEom0qZPvtYq+C1H8b7C8oQcgXEsLtaalardVjpW3IPyb3cOjQ+AXu4dHh6D9Yvx1yjrNdj+vVfdmXOje/FCbk0ZwkzKRFnexrtVueWMwDe7stmKXgD4aOpWiDn4xoi+qCWYcQRPPNWe56uA4NDRgaIVoNW8JVBnewC77DUdLnQ2tJNsD/2b38OgQ+MXu4dEh8Ivdw6ND8GMR9dZMxwktQUJLV6cmvbQgUWzwGGtCyNCoJyK9sOVMFz3UklKgjooc7WVjemP4jV5e1oy9SOmM/O8V5KEnoiTQQFu9H3XbUrlEzRBVZPwNRJIwd0gWWXXW5LX5d+y4AvDIY2NWxWMbIZhI4Tg291C8NnBvwlS1YhJ5i8G/2T08OgR+sXt4dAi2QYyviToNIhuUG3nDNidQCEzgBLXwsmomwlmRUHnoGZlNkSS0MEklAhHBrViJxwXImkJE1AUZSxYX5+Ly6sqKanfu3IW4fPXqnKpbXFiKy+WyiPHLS0uqXQSZZJaW86pueVky0Cwsyvcq1Dwgp1gsqjpMieIw+MVkQ1lclEw1gfHzG+wb2LRdV5cex+TUZFzO9ensM6ns5tlo3liOQ3xe3jRTydbO1MLG2HLMLVOO1eDf7B4eHQK/2D08OgR+sXt4dAjarrNz/L+5I2krkgTU560Zpxt03mJJm5qaRTxFRjFKZbNxuaurW9UVwaxVLkk65ARr8xqmK06YPGTptOiQ60WtswdOzFxXzp2Jy2fOvK7avf76+bi8vKT1+SrobhFEohWK2nwXRqKnLyxq893iqlxbKie6fSKj9d+R4WGpM2yR3d0yj0vzV+Py2rreH3CBRLqtmjEm4F4ks9LuwuWLqt1TT/95XF5Y1vNx8NDhuDwwOCh9p7OqXRpMndZtl1X0HWlg2mr1OFpzZrMaamq+a9DRW3SyMfutNPdrvtmZ+Q+YeYaZX4LPBpn5m8x8qv5/oFUfHh4e24+tiPF/SEQfMp99hoiedM4dIKIn68ceHh5vYVxTjHfOfZuZ95qPP0pED9fLXySip4no09c8G4MTWiviiVY8Yg5Mb0bcwsgr63UWhMm4nEyJSDi+Y0yfKyF9zly5rKqikpiXAjhXxaRUjpwcFyvGXJXOxOWJ3beouvlZMSFdvDwdly9f1OOYmZa6YkF7uKVAPEUxfj2vVYawW1SegvGg27V/f1z+B48+Gpd/eOyYavdn/1vS/OWNeRAc9Ki3R8a099bbVLu/8/f+flzmlCaveNc73xGXn/v+d+LyV/7oP6t2+MYqGnMmwX0fmdgDH2v1isHstzg3o+oS+Pg1D0Cka+Swhv70Oxa59zDCsWqeHTTburCJ92ULz8A3u0E35pybJCKq/x99k/14eHi0CTd9N56ZH2XmY8x8bGFp+dpf8PDwuCl4s7vx08w87pybZOZxIppp1tA59xgRPUZEdOfB/Y6CDTHZeLgFSBVsAx2gDtqlUxnVrlAobtqOiCgNu8rjE7vjciKp251+9RU5MGJUCXaSl+bn5bzra6rdyoJMx5IRb6vgXTcwulPVfegjPxeX7/3pvxaXv/+9Z1Q7nI8wocefhOOoJCJtZAJh1mH+H3z/+1Xdv/j1fx2Xv/741+Py1776VdWuAl5zoZFgWaRnWl+V+Tn5yiuqXaH4J3H5t/7fL6q6/Xccist//q1vxeWunl7VLr8qc3z5/FlVN3H7nXF5dJeI8VUb1ORkfi5dPqOq8ktyr/u6h1VdIpGEsiynVllsrWdmoSDWD1wVyVAvz0oZ7qHN3lv/oJVD35t9s3+diD5eL3+ciB5/k/14eHi0CVsxvf0JEX2PiG5n5kvM/Aki+hwRfYCZTxHRB+rHHh4eb2FsZTf+Y02q3t/kcw8Pj7cg2u5BV61rJTb9L+qhVp9Cr7kkmFLCBs81aJfU+vzOW/bG5VROTEELs1Oq3eTFc3F5x+iIqjv+7A/i8syVK3G5bCK+XFl0MEv+MDMv0VuU0h5673r4A3H5wfd8UMZ04YJq929/49fjcmT63wFRXiHsaRSq2nPtwYfeE5f/71/7DT1+UCk//x8ei8tVc5348KSMfplLg6kTqiLjFXb21Om4/JnPaHeNL3/5v8TlUkmuM2X2KdJwgmwqqeqUrQyfqyBpmsm40qE2y1FCjhcXFlVV/8Dm/mTWCxT1+VbRayrVdbW5B50l7ozim9ai76Y1Hh4eP1Hwi93Do0PQXjGeiXjDJGZJI9AbzgTiM5jRMhAcUS5pz7UkiFs7wLxGRJRMi3eWA7Vgfk6TP+RXxBdgKaHHWAEPugTwoifS2vMrAd5pqYQRK0H1OH1ee8ZdPi8BLiM7ZPwf+cVfVu2++sQ34vIP/uovVd38iowRPf723XZQtfuVz/xqXB4e0j5Rf/GkBJZE69LHaG+faqcCkcz9TLLcG5S619e0OrFeEHPSc9/X1/Kdb8l1lvNyX8aGteiM11kua1UjozjoylA296UK7Yr6+etKyP2s5rQ5dg6en7Ex8ca0HPWKA7/B7Adce/CsR8YLtFUaqkT9vd1I/CLwb3YPjw6BX+weHh0Cv9g9PDoE7Sec3Ph5Caxe3jzdMrrSOjCzFCKt/+V6+qXc16/qOMDIItF+1lZ0H4ND4g5ZLmsX0937IGJrr0SG9fUNqnbJrIy3lF9VdVe/8WdxeWFBxwq8ePz5uHzPOx6Kyzlw9SUi+vuP/qO4/L2/0HruIkTEEewXfOpXf02127lPxs8Vbb47/qO/iss7xkRPLxf1OK7OihtpuaR15Vy/fA/1yMqKbsdAYhmUtT78R5//j3H5vrvFdTY0RKMriwtx2Ub3BUmZA8w/x4E2XZWdjGtu5aqqGwAijsCY5cKMjCVfFrfdrnQXacg4Kia9dRjCfgHy7TdEf+JxE9P1TYh68/Dw+DGDX+weHh2CNpveODaxNfC1g4gVmro08I+VIJLL8tgNDg1JH5ZTHn/XQGxNmai3IpAaGKmSdt0iUWoBRp4ZEo1CQcTzF14+oerOvCYeY5aCXKVyUlweej7efv/b4/I9b7tL1V169YW4vP+uu+PyQ+95j2qnCBOMiedHP3w2Ll94XfjeSkWt1uAYsxkt3kYRpp6ScjKl7wt6GBpjGL3yvKg1u0bEM7Bc0KoREnjMGw+3EDwptcnLmMZgHLMz2qsy6cTUl+3RKlsWryfCNFeqGSUToMqYBwtTC+Cz5GzOgRYi/oZn6s2IevPw8Pgxg1/sHh4dgraK8cwBJdO1Hd1K2WQmVSmZ9PfS4Mm2vCxECDaoIgUim2tIhyMiUakou6b5lXnVanVFxMDuLu2ptbIk4mM3eMm5qhZvz58R8oOzr53So4DrtiQGeSDHwLowqX+Tu2B3eO8eTYCRLsn1fOxjvySf5zR1Mm4IFwt6h3wZUz6BiJww74buHpmD0TFN6pDPy7XMAwX3et5QSSuaZqM3RTKvLz53PC6nUnocYyMSsJTPa8tC1YFYjF5y+kzkIGCmsKqtJKsJqSsa+u+u7l4oowVCjxHpxS3hCGa5bRUkw00PpM9W2Wn9m93Do0PgF7uHR4fAL3YPjw5BW3X2RCJBAyO1CKvZac1RWQbTR2Q8uioQyVQEvTaT0+mI0NxWtbz0oBeVC6KzL8ycV+36esDEs6Z1t7k5+d6lsowjCPT+w4vPvRiXJy9cUnVI8mAJH9LAm85IHNlAhCC/0ftu0Tr72pSY9u46IqY3S8CJexjlsibMrJTkuK9H9kGSpPtIgblNpWUmTSiRgvFWTCRhFQ6TNhoMCCsWIbpsYFBH32H6qkrFeMaBmYth/Gw9OGETo7SmTXtLFZmPrEkJnQRT2UCf7B2UzH4Mw622ajW7rb1z0XTIRrff8BT0OruHh4df7B4enYK2ivFhIkm9w7UA/7l57elULIhJo6dbBxHkl8UUlAGPt6SVTNGEYaoi1UxMOtG6FtUTXeLHlTOmt5eeF/H8u995Oi5XK9qcxIGIvlnDbY8eUtmMJr0YGhLvLBTTjGRKIYiIO0a1R1cAHnUjO5CUwmYVFdUjirTpbWKniKMJ8FazqaaCpIzfehEWQRVLgsicy+n5iMDVLDAXiimZcPyRCSRZgky2JVOXzeGzhNlSVTMqAb/egiE0qcBtSnfp8TvILRAif1yk1RrFLdegYoJ4jkFfZPrg5qbDDRW2hRTv3+weHp0Cv9g9PDoEfrF7eHQI2hv1FoSUyNbcC7OG8EGpGmXtkphWZhLRY8olbSKpFEW3T2S13l9xmwf+54yuuTArJsGxvVpnf/uDkkL47FnJKfbysWdVO86CS2y31q5wwism2mxiQsxoqK+xMzzmoA+PDGszVHfPHXIAEXyBda9ELv6kfgwOTEzE5R2gBE6u6X2WPOjYlTWtzyfANTU5IPcimdP3pQpkEJZgcW1ZdPFUStqxjTKENM0l00dSbezgHoB+z62BuW3d8OOHcC2Vop6rDPD0l+G+VEzEWpJB1zec9QxPRQCkqVyyLuXwLBlTp6vr/Y1u4nDapjXxCXg3Mz/FzCeY+WVm/lT980Fm/iYzn6r/35wt38PD4y2BrYjxFSL6Z865w0T0ABF9kpnvIKLPENGTzrkDRPRk/djDw+Mtiq3kepskosl6eYWZTxDRLiL6KBE9XG/2RSJ6mog+3aovZvFcGhjUYvxKJCLQylWd5hjNUFWITsIoMSKiq5PirbazV3OhB5BDGAP/A0NykYafv/K6HkclkspL5yWarVTSHmjJUMY4N6tVjXIJxC+Tomps5664jLxtoTPRcSvCuZY148+mhXuvimmardgH0l5ovOvGdgj/+SiYB4eMp90UEEUszWoRf3kRyCuqIprm+rQAODqxNy7/n7/+b1Qd3psCpGX+z489ptodA+78+dlZVdenuAgxslKLu0sQ6be0pM2xA+MS0dfdo3n4UD2qAGFHNqPVlQSkLSPjOak9+4JNy3r09oCIwzpv/I0yvTHzXiK6h4ieIaKx+g/Bxg/CaPNvenh4bDe2vNiZuZuI/jsR/RPn3PK12sP3HmXmY8x8bHb26rW/4OHhcVOwpcXOzEmqLfQ/ds59tf7xNDOP1+vHiWhms+865x5zzh11zh0dGRnerImHh0cbcE2dnWvKzReI6IRz7reh6utE9HEi+lz9/+PX6ss5YWDJdWmdZn1BhpJMatNEHphDHOj2keEqLy4LSwtH1rVT9MYw0ZxUMgQ9d+6KTpWMrCR/+5d+Li4/8fj/p9ohg87pM+dU3TKYqAZ36n2LHtAvkUyTnTZFTl8Qs1/GmKFSaWGkWQX9dWBkl2rnwPyTSGm33cEx0ciWgfd+pEtz8SfBHJY2UVjphOwzLALDz+qS3gfJ9MhxzuScw7x+BESjFcPUubwsexiZtH5/9fZClBqM0eZiWy9Kmu2eHp1KG02TQaC/V4Rx9SSF8DRp3KQZTIzO7JHgHlIIpkIXNlfAuarrEhtrpoXSvhU7+4NE9HeI6EVm3uAG+r+otsi/wsyfIKILRPQLW+jLw8Njm7CV3fjvUsPeX4z339jheHh43Cy0Pf3ThsmjbDydCgURo9BbiohoBSOIQBTLmaix/JKI8fPTV1Rd/y5Jd5TKQDqfhO6jkhcTEpMmkpy6IOa2vfsOxOV3vONe1e61kyfj8gUjijkws+wAsxORNr2hsLgwqwkwFmYm43LWpIROQpqrVUiLZFWeELj4Q6M2DY5K1BvNy6bq/ILelhkeELVmsFeLvpNXZP4ToXwvsabndLAfIv3YhjFilJo8A4lQmyJHRkVUT5kuMIISCSuqhtgdiR4rJmJtGdJ4R4ZcNIQ+MbLNpk4OgL3CGXMpqhQ6XVVDWKf0b10i43N78goPj46HX+weHh2C9mdxrYtLK0vWVC8iixWtuyEjaAnIFFxV77iXgDPu+b/8pqo78m4Rb7pHJOAka3aA1wuiCriS4SAHzvDFeQiY2alNiufPAEe9yQS7XJS6dz/yiKpLAO/cOninnX/hedUuADFzg4d/AwyWBmS9mJu8rNoN3iq7xSFrtWlsZE9cjmZkHLhjTUS0DqpXV1aL8RM7RCXJJmWM565oD7eREfGoSxoRFC0SjuVautJavN23W85Visx8g/rSB6J6YHaziyviHfjqiZOq7vDBW+Ly6rKxJnTJs4m8GTb9WCIt811pIBJB7nxQC0K7PMED0HDchQnPQefh4VGHX+weHh0Cv9g9PDoE7dXZnYs54fNrhqQRooKMkxJle8TEE4GeXi2blLZl0SHXpjUf/PFv/8+4fOQ9PxuXh0e1zn7ijKQ8Hkzr/Gi93eJBNjMtJqm+0THVDj28Fla1yWt4561x+YN//QOqbnFW9OrzL4re6MxcpbOi/wVmjOgpiKaslXlNopgGs1l/t95zGNsjZsr56WkZu9M6+9WrUleuaHNVAtJMd3eLPj84qm/uGBB2JIw5CYkYMEqvv0dztwfDYCo0KaFnJ8UEOLFzN/RnCDBgbyUyxBOlvFz3siFKzcAzgXsaiZwhz4RnImFScFeRjBKmB811tT7we4Yco75X43V2Dw8Pv9g9PDoFbRXjo6hCywt1cbLanBN7k8h8KIq4n6wavjHwHhvo0uItFcUs9/K3n4jLu/cfUs32H5KUSedPvKLqvvGt78Xl1VUxw/3MR7QJbc8h4YH72Z49qu5t9z4Ul1999vuqLkWiomRJrjNrPAp1YIb5vUbTDXpgGTF7+ZSoOXyLnsfcoIj4uVEwLRV6VbshSNk1D8EoRDoNdBHMZuleLYLf/lPCc0/Wqw3SfiEP+/qaVieUaG2e6Gf+p6hvB/bdFpe7UPQnoj5IOc1GfK4WZPwLC/o6U30yPzml1hgxHlSDnn7D9Q/8+xGk9A7D5u/iqlF5Umkvxnt4eNThF7uHR4fAL3YPjw5BW3X2ajWiwlrN3dCaWQJMB1zVv0GlCrg5gjtoYAgTuvtF77L9R0BmgRa7helJ1S6dE720YPKGHX3nO+Py+Ki4eU5NaZKLUUijfOfR21Xd733u38Xl2/dPqLoPvP/dcTmD5jWjlwdgggls9BOaZ1B/M+YeBpKOS6dfU3XZAdGrx8bFrBjmNeEkwX0pGnOVch0NZO73juoU02Xga//Gf/q87j4p4z9835G4vGvnLardUEbcca/OT6u6q1MX4/Jjv/1bcfmX/sE/VO0O7pcoxvvf9ZCqm78E+xspTboyODIel0fGxbQXJjR5RQG46FMFvefQBTo7zmLCRDS6AGqddZfdyPXmdXYPj46HX+weHh2CtorxTEThhphhxI0Qf3cCEzEEHGkMZpzApNFxECXEhpO9WBQvtBSapAy5BKbMPXiHNssRmJoWZkQ8fO3kC6rZe39KvOQyoTZ5Jasiwu0Y1GaobBp48uCak8YUhBFVluBAZf+BOY4Mb1sBiDlCY8IsTE7F5TxEV7ExBXWB2pRMa/E2uyrRg0tLEuk2d/GcanfxxAkZR0F7CmJc5MKC9HHX4SOqXe+tcp9On9MqSZXl3jx7/Hhc/uw//KRq996/9sG4/PAHP6jqJiflXu8Y3qHq9hwQb8NEVtSJZEKbS6OSzOPais4lUAIzJRK3REZUx2eTXROTq0/Z7OHh4Re7h0eHoM3kFUxhsLFraGqUmGl26iMRX6oOPOgMyUUQiCgZlbVYmXEQQAMEB8Zpi9gBiQZrMcpF4jV37qKU73v3T6t2u8bFU+u5H72k6iqRiPHjsHtLRJRMSFBFQCISBkYkDGCX1mY0JRTrYafespklYXe+anb7kdoYb0tU1GQelYqIn6VIi+AOOONCUK8wKIaIKAXegKW8Hke2LCffuVMsFyN79G58Dnjmbu3XZB75kqR1Gp+RYKAXnj2u2j31tT+KyzMnn1F1d993NC7f9v6fUXWh4ozD8Vt5WlSldI9+NssFeZbyRaDWzho6ahTdjRhfqnswOsOfh/Bvdg+PDoFf7B4eHQK/2D08OgTtNb0xU7Chs1sPOvWzY7yDqjJMTNnsjMkoBP0vm9URWlWMmsqLflkxJIoREGAECUMyAL+Nt98p5p/AmO9OnDgXl//wC19Wdfv3iMfV8PCQqquAV5urireaY60rJ1LIha71eUzzWwUPw8hEvWHUoTN1OjUSmjp1F2EIhAwN9xO8/NATLNTm0iLsYSwvrZo6OIAxZnNal03A8VBmXNW97Z63ywHYJedntaddNzw7QyYyL4R5TCT1PhHOcSPvPQD2SCxPfxJMqWVI/121kaGKR99ECNbzMDjzuf7+NcDMGWb+ATM/z8wvM/O/rH++j5mfYeZTzPxlZkNR6uHh8ZbCVsT4IhG9zzl3NxEdIaIPMfMDRPSbRPQ7zrkDRLRARJ+4ecP08PC4Xmwl15sjog35Kln/c0T0PiL65frnXySiXyOi32/ZGTOFdTGIjUcXK+I5XZcCOx2a7Cz3dwl43gNjkkqnhMwChZACazKCtbKYPqZndd3QiPDVcSD9vfDyy6rd5/+fP5D+jVfYfffdB3VahZhfOCfjKIpIXyoZDjpIX9XbO6DqenuEGCGbFXE/TBhPOyV+GtEPxX/wGiTrabcu41pYmFd1c0AoMQeEDxcu67RcK8DDHqzrbLXpjIjnzx/7QVzef/iwajfaJyqbM/c90yPkEocO3ynjndI8+itXhVOwt1/P6cq63IuFhSVV1wvkFZhSas3wBmbgWhLGlLoMabqck3OlkvpaGMV6relC0Mx1BsIwc1jP4DpDRN8kojNEtOic27j7l4hoV7Pve3h4bD+2tNidc5Fz7ggRTRDR/UR0eLNmm32XmR9l5mPMfGxubn6zJh4eHm3AGzK9OecWiehpInqAiPpZyLomiOhKk+885pw76pw7OjQ0uFkTDw+PNuCaOjszjxBR2Tm3yMxZInqEaptzTxHRzxPRl4jo40T0+LX6qlYd5et6qjUrzAOveTqrzRv9fWIKKQMrQlQwpjcwbywaM053lyg5SOpXKGted86JPjzapd0az515PS5PXxHTzQ++r90r0SS4f/9eVbdrl5iGujLatXNgUIgiloDQcnJam4mmpiQC7MI5/Rubhsi50WGJSusxXOtIethredhBISzBnsPqis7Pd+WK6L3T01OqbhlIIZEsJJPV50Le9axVN53MY0+XzNXkBZ0TYGBEItEyvfqFUs6JTh0kRC8/fEiTihz/gejia+v6mejqEt15eVk/V6+/LmPBCERLOLIO+xEHDx5QdRcunJPxp8UsVyrqPQxcMlFJC9L76i7EUQt32a3Y2ceJ6ItcMyIGRPQV59wTzPwKEX2JmX+DiJ4joi9soe5+P2UAACAASURBVC8PD49twlZ2418gons2+fws1fR3Dw+PHwO01YPOOUfFUs20sG5MUseefTYuH75D7/9duizi4o4xEXXL69qzbHZKRNpsRl/a4IBEW509e0o+H9VebFdAZH7X2/Vv2a4J4YCfPH9JxjRsRMdIIrS6u3SUVzYn4milrEWxb3/r6bh87rxc8933PaDaffcvj8XlC+fOqrqfuuOgfO+nhNTBUpAPDosZMWvUphKInGurYhpbXtSpj1AdQoIRIqKelFzn3KL08Rff/Z5qt7YqHmMHbtMc+8U1Ea3337ovLqO5i4iIwJR65B3vVlXZLlEbFKWgUSOX5yFVd0KbRB/+yC/G5cGd2ug0Cqm/KhWZj/PntaoxPi7qWyajcxqMjQsvXzIhusyaUZuSoVzn6opeP1fnaipKJdKqLcL7xnt4dAj8Yvfw6BC0VYwvlYp0/mJNvBkY0KJvUomB+jcIUy1l94pY5sp6t7IAYnGf4XfrHRJxPTUr9NFX57WoVI1kN7S7X9Me9/ZJ//tul++VS1qdGJkQEXnVpCpKdcs4EoZS4vY7ZId4dFzmZ/eBfardwpp44WV7tUh4+yFRgVJAFNE3rK8lC4QPaSNWViCj6TJ4uC0tae8xBlKKubWyqttzUK5l/71y7gtTOptsfkHUpt079RgzCVGHwkh2yM+c1IQgDjgLbz14UNUN7RKii6V1uGeFFdWuG4KQopz2cMuMyD3L5vRchXButDD19upArFB59hkK9B6wyoD3ohvUGYaRS4VNH65+7mxGBwkh/Jvdw6ND4Be7h0eHwC92D48OQVt19nQmQwfrOpX19DlyRMgg1tZ0mqG7oS4Jgf9p44E2PC46ztzcVVXnEqK/7jsgOm/KpEMuAJlFultHP1Uhhc+OPUIqWTKpj7p7pM/pSe1Zlk6LTpU2RA4HQN+cuyqeZbNTOkXVfvDCuwVSDRMRFSFKbecu0Xl3TmhShxQQSjibKhmuBwPiqobkoq9H9NKHjr5d1S0XpO0KpNi667b9qt3VSRlHaMgf+mHPIcGiK2eyWm+ugrmpYMhIHHjhReAZh/tARESDYFbdf79O/zQMKatsAIhzSO4h785UUj9XSAhStXzw8M5FXdxSw+vv6JEE8Y3y6Z88PDoefrF7eHQI2irGF9YL9Eo93U+1qkWZoUExNb3yyiuqrq9fRFo0/7x25pxqdxhIDcomHmB0fC8c8abFGkAsc9obaWVdzp3IiYi55/Bdqh1QilHvwJiqq4LHWGi8uJKBqCWjIDoO9WkvPxRVq4aAPwGBMKmMmDMtmUcSTEYVYzosggcdcvclTCbYaknmx3KSjfeL6bMA/Q8f0kEgpT1ynYWinu/impjKXFVEcJvKKgmqWNpwrVeKMt/RspRXlrW4f/hd4nm35+53qLoEeANWLQM/msqgvGi8DfF5L5ngqyHgIgyRs9/cW/xeYOqSG0QXPv2Th4eHX+weHh0Cv9g9PDoEbdXZ8/k8HX/uOSIiuuUWna9rYpdEE62saFfGc68LacR994mJ5/vff1a1m+oT18tb92kX0xB5zUHlczbpHNg7XKRdQEvgYtkPewwr61r/S2fEFbXXmO/mz0uUmstrIoQy6PAJSDmNqYCJiFKgGwaGr51BaUNzDxs+8QDMbZHR2VfBRXYd9hhKxqwVgvlueUXrqP3AKZ9LSbus4V0vJGW8yTXDjw/zXwKikpLR2fv7JQouZ+ZqbVmi2c68dDIuWw783t17pY8x7bbrnOwJWHJOpxvGRfsMv/aapJK25Jxvu1v2fJBDPpvW+w9lyLWXMtzzXfX8cXYvDOHf7B4eHQK/2D08OgRtFeN7e3vpkQ98kIiIJie1V1gI3mR7992q6m7bLxFUU9MzcXl8h/YK6waesquzM6puzy0TcNQ8PXQE/HHlkjaRZHLAww4eUqGx84XIEU4a6ayY7PLGUzAA0xaaypwR50JlAtNiJRJKRBUR+xqo4eE6LeHB6qqYvJaXRDzPm6i3QgH6N6mycl0yZob0WIHxkgtBnk4a82AZuO7LIbbT50KCkPyaiWKEPvbfI6mX9x86pNqN3i7ei86kAg8hjXe5bNNWy9yhCG1Nb0X0vtyxQ9VNz8iz2g0RiNlx/XyfPClqyNiojojrKfTUx+fJKzw8Oh5+sXt4dAjay0FHRFE9ZVPVePmnwSPtCIhbREQjoyNwJCLhbfu1N5al71XnbrYbb8XgKuwAm53NEHbZy5B6ypI/2KyuiDQEd6wt6PRSriqea5jqJ4j0GDFVlnNahWDMC4QZb23gBIzRpobCtFRra0BesajHS0tynMjoPvoGZYc8BUEsNuimCkE3VeOx6ICtIYAxZro1r186JY9xZCwG/btEXH/nz4moHobm0cfn0en7h55xpbK20Hz3O9+Jy+jBOTWlA6D275cAoERSn/v4cbEq7bxLduYbVV2Zg66cpjlP1tVK63WH8G92D48OgV/sHh4dAr/YPTw6BG3V2TPpDB04UNOz5+e1F9EsmB/uvPNOVRdCWh3USZwxwaDpyuou2rNMYNNQIdJpY4IBnQnNLHavAFP3Vo3nWghRaZzWXlBRRfTNChAcsPFwC+C6nSFCqKC5DaYgafRE/F53j9aBB4FgcXlR9kuiitap19ZWoazNiColNMxPo84u82/nCvdZksBt3wtRkERE2S40iZpHmptEkTU8H3BeMoBxoYcbEdHEhJh0T58+HZfPntV8/rfdJmQnuwyx5uOPfy0uDw/K3B8we1JnTkn/995zr6p78eUaCWfJPCuILb/Z62mbn2PmJ+rH+5j5GWY+xcxfZkx67uHh8ZbDGxHjP0VEJ+D4N4nod5xzB4hogYg+cSMH5uHhcWOxJTGemSeI6GeJ6F8T0T/lmjz0PiL65XqTLxLRrxHR77fsJ+CYQ25wsHn65kaxeHORuUHsIxEJQ+ONhWIl9lc1pqtEIrFpOyKjQjQhLSAiCtG0Z9SEKlxaqlsHbSBBgytIuRpp0Qwd3mxgRgTBIyGI+2uGcw09uirGK6wIomA3BJn09Gsu/iIEANm5SoKHoZor0w5VnsjcC/QiRL72vgEtxqdANQqMmG0DhTbQkDBWR7TotnDf7XO1e/fuuPzDY5KW67777lPt1PyYk/eDWjIG6c1sZlzkS7Tj2OB0tM8iYqtv9t8lol8hoXEZIqJFJ2x+l4ho12Zf9PDweGvgmoudmT9MRDPOuR/hx5s03fQnhZkfZeZjzHzs6tWrmzXx8PBoA7byZn+QiD7CzOeI6EtUE99/l4j6mXlDZpogoiubfdk595hz7qhz7ujw8PBmTTw8PNqAreRn/ywRfZaIiJkfJqJ/7pz7W8z8X4no56n2A/BxInr8Wn0VC4XYPIG6CZHWxa2b4Fpe0tN2Qcpj++ORh3aWWxxFkTK4PPb0ardDJJxs5XqIOljC6om4J2C+FwDpQKpLjzEqyvgxmsqyZ0aQl6zBdAhDrsLZbcrmNOh/5aKO7ksA2cTAkOytXLp0UZ8K3Hgx4rA2fhkjRvexcZPGa4mMGRHHgWmaM4ZUsgSbGNb1NwEEG63cqVvda6UGm3ZZeM7+j7/xN2QcRqfGc09N6+f77rvvjstISsE5PacYLTc/p3PmHaxH7WVuUq63T1Nts+401XT4L1xHXx4eHjcZb8ipxjn3NBE9XS+fJaL7b/yQPDw8bgba6kFXLJXo7Os1z6Kl45oI4ZY9kn6n20Q1LQNpwvi4eB899dRTqh2aQS5cuKDqHnjggbj8XJ0Hj4jo4fc+rNqhqcZaMdCsgWQbbPnUQdSrWo64AKO3dP/FVYkwC4Aj3AS9aTHeiL4hnDsAjvPAKBQJiDBbN1x7CYhEy4HJK2miwQrAibbmdLRZGeYKxXFLosGg8rikFltzkF4q1yXlgPVjW4HjRJc2DyYTINbifWluodoEyPlnHwopdoNa1kAWAseVojZ1YpThBeCuGxkZUe0uXL4UlxPG+3IgrKlb1hyN8L7xHh4dAr/YPTw6BG0V4yuVCs3XCRv27t3bULcBS8OL4lcEO6+WywtFd0segP0vglpQNdlkuUUwDQJ3V60Yj6QL9vcU+0yk9M5pEmiQo5KIdklDK1YCSc1mPmW4TiTiWFnVtNVrkAqpZLj2MJhibloClvIrxpMPrBpRWasJDsTdqlJ/VDNKwvhzxjrR3Suiexp2pitGnch0g7jfp6m78dlxLdN+4eC3LuOrNEwY/GOeCaTythlYlWUE5n7BBIstwz0sGhKNkR0165YNeFJjbVrj4eHxEwW/2D08OgR+sXt4dAjaqrP39fXRhz/8YSJq9GZC80Nk9GjUt1dXRG+xJBf7IOVTxRAtoMfbffdK4L8l/0NShwYCjCY6fEOkEdhdbNAV6nJhqHX2vkExtZQhbTIbfTgJXmFl8BokIrp8UbzcXjgm4Qwzk3oP49ZbhBhhaEhHICL3OO6fLC9qc+mly+fjcqZLE30MjAsJw849QvCQMvsUSBDS16PNZl3d4t0YgF4bhNrsNLRDYrCCpNb7lWlS3QtLXuGaVWmvObNfgK9Ldpvr7w3jMI9LD/DeY3l9XUcq7oWUaWxshxvc85433sPDwy92D49OQVvF+EQiQX0Q0IDoBTOLRbMAhsDIWygStgp6QFgON5SOrCpgA1420CDct/LUAjHemW8m0pD9dVgChVbKOgDFAed72RA+DAyI6ekQpDiqGvFubkVEcutBh2oUEmBML+rgC8UjOGfUpkDmdXQnmEizxuyUkXuGJiginWk1gnH0j2uTaw6uuWTiggInpiz0jmx8PuBeNBBeNE8XpntoznGXgD73Ax8dUWuvN9V/q8Cs+hgzhjcR4d/sHh4dAr/YPTw6BH6xe3h0CNqqsxOJXtPSrGXNVfCBtp402LWa1qG7IuY9szo7HluyyCAAznfaGuwQK0h8aS12oEfmeoSEsLyu0xCvIhlESt/ClBPT1u59e+NyT1ZHlJVmMC2z7h/JPRYgH92ulO6je1xMXrlBbTYbHBczYgKuKwiMey+mpjbz7WDyeoGgdGhc865HgZjiIssWAtF9lUpzsyqSTSST2rSn+2tFgIHtDBmqMr2ZvHvN+tvyU2bMfk3g3+weHh0Cv9g9PDoEbRXjq0RUSNTEjYQVYUG0DqtaJCkDETtyBySNSFUCOSptUxQjbzeYhSjUJiOMGguMiI9plFVKI5Oi2SE5vBlHSM09qaogijEQMnT3jat2K/MQwVbQEWsRpH+KktJfZkRHg1WBqy3IGBGwIJ5buW4Qb0vabDqYkTGGOS2eh8qLUOYjmdDmNQ7E461qzEYMabzTvaIWONZecjiNAWkzIipcKD1bDzRUISoVc8/A7MctTLrVVjx2rTz0mojrNjquFTZO3UqY9292D48OgV/sHh4dgraK8YFzlDZi5wZClG6NWJwpA3kFilSGuAFlmIoR05ATrKz4lvUURCUR46tWZEMdAnM8GcKxRDPrAWnxnFp5+YHMub6qA1DwmA23XAhplyIHqaDSZk4HxGNxKKeDU6pAEFLENFQVvVteiqSuUNIBOVXg0EM652xOU3f3wS77jgmdVKgIl5aD7wU2tReet0XKrgQSWUQ2ey+SXBgRH7b4rbcb9t+sbPtspQrg7bSGBXXeJl20Evz9m93Do0PgF7uHR4fAL3YPjw5BW3X2wuwKnfkP366duFd7Y4VAZhhMDKm67JLof6V+Mc/kdmlz0lJRPMuQ4IGIqL9bPLwW18R0lTamoOq6nCsc1nUDtwKPdxXNgYY3HlJHN1AJhDJ+tqmeofXqwkxcnjr9omqHpISRIZVPg87OKRlXKqnbpTCFktnfQFJPJKwoGDIFl5c9AdegAotejWSRA6OaC30XEI8mTOqmIt4L0NNxfEREVYwkNObSBrIJGaA60sSRpgssN6QJhx6hzkbVuRaWtxacGk37aAimbP61GFvNz36OiFaIKCKiinPuKDMPEtGXiWgvEZ0jol90zi0068PDw2N78UbE+Pc65444547Wjz9DRE865w4Q0ZP1Yw8Pj7corkeM/ygRPVwvf5FqOeA+3fIb+TK54zXxdC6jf2d2gCfVWkWLz/lnz8bl9TERCXuMyDY1L+QKXSZoYzUQ8Xl5XcxE6T6dg2k9LSJi+m1anRicEDNRNQ3jt6IiHhoTDJq1Qqd52JenzsXlydMvxeXKuuZ8r4IqQAmTPbWJQOeM6BugudCI8cgbj+JzaERT9IxLJbX3WyolprI0pJBaXdNpoqoQGLOwuKj7AA86FItd0Mr0ZgNQwOSlRGlzX+B7rUXiFve6yXk3qdSHLYLAtnKurWKrb3ZHRH/GzD9i5kfrn4055yaJiOr/R69vKB4eHjcTW32zP+icu8LMo0T0TWY+udUT1H8cHiUiGu8aukZrDw+Pm4Utvdmdc1fq/2eI6GtUS9U8zczjRET1/zNNvvuYc+6oc+7oQLp7syYeHh5twDXf7MzcRUSBc26lXv4gEf0rIvo6EX2ciD5X///4NfvKJSm4uybth0Wtu0UF+d0p9Wj9Mr0H8nz1iW5YzmiSSgdqYynUev+OHZLO+eqpU3HZul6GEI7njL6NoypBPreE0WW5RWRbVBAe9qkLZ1Td3NlXZBwFIZRwoflNBpNaIq1vYQCmRHTzLEd6f6BSFDNapWRyuEFKaNTnrckrDOXc2V4diQZVNL8s15ILtEm0BM/B/KLObTYB5KTruM+S1O69qAIbb1l1z5BHMm1MloHNiw2oqu0ZG00JLrJwn5zN9abccTUY+2hy3lo7fK4s6Uqz3gVbEePHiOhrdV/fBBH9F+fcN5j5h0T0FWb+BBFdIKJf2EJfHh4e24RrLnbn3FkiunuTz+eI6P03Y1AeHh43Hm31oAvDkAbq0VbdY5qQoeegpLapfvU7qs6Ni64/khARLjImjNHDIqr3D+qURjN5Mevsu+WuuJx2WowvFcVri7sMOQZ48lEgU5dwmjChSCIWL89Nq7qFi+fi8tLUpP7eqngAhiDQpYyZMpUEc5hN2QzHSIbhqLm5qtKQbkuuBwkUAptuGebA8ukVy9JnKi0ifsp4NhKI8c74G1bheHbmSlzemTbelynp35n7mQZSimoIfPjOmCJBZs4bVSAPJCA9lj8OQvOKWSAEMfclCaJ61cjnDrbOknAr0BOTiCgfyH0J1rUavBFlZ1OQq7E2rfHw8PiJgl/sHh4dAr/YPTw6BG3V2aN8gRaPna6V779V1fGAmKTCv3pd1V09NByXR98u+nblOydUu4F7Dsbl6T89puqy9+6PyzPffS4u9/RoR59LSxLl1ec0qw73Qr6xpETcrS1ovXxq5Wpczs9q94OVeTm2DDQRKL5hAvLWpTUneyrA22ZTD2P0luhvgSXgBHOhjTZjh3p1c3MPdlmNDA87KPjlqujHliFmYU7Mbem0NqmVQS+dmxVX6NC8o0Z27onLQVoz4ZRY9NwKsAulzHiXj8szt3JiVtVlesQEuNSn9xzKl2T8a7fLc9prCJnCgly3G9f3MwKWnwj2EoYm9L5WoQLRn5d13j2uu29HBW1GRfg3u4dHh8Avdg+PDkF70z91pYneVRPfi1PaW6p0XkRfvnVY1UU9MszCDvEQm7pFi1Rdh0Qkz67oFEHnFy7H5fFeEReDXt3H3j37pP9jP1R1ZTDfzcJ4K4taVF9cE4+x9Xl9nfllOS6VtaznQhlLKifXXDE8+mhSsyavaglMWWX0hGug0YjBlr0QD9G7y6bUUiqDEfFRTQCRvlLSZsoliHQbGhtTdetLotqtzckcz5lzocrQPaTTOWdZzHTJlLRLrOmJm3tZ+q++tqLqolDu03rOkIvOyXxzSsT9109qVTQDJrqRd9+l6pa+JxGO3bdKPNlivyb6yD/xgpxLB0LSSqY2r+XlzQldifyb3cOjY+AXu4dHh6CtYjx3pyjzUM1Trq8woeom87IznTRBCaOj4g0XrMpu4+2//KBql4Lsm907tajUD+JtLikeV6Wi5lXLz4t4Xg11oM2Sk13ayqKIS8UFLaovr4gYmF/WImEZd0sttz14alEkt8ZmJi3jByaIxeGOPgauWDG7RcAE4zuA0aXLpkzCA0vctjk5hokjUUE4dohXZ6ficnFJxP2CIXFY75Pno2Lc/BZyYtXIsqhv3cbRrGsUrAfrJjMuEHNUzPOSgOCX5DpYVwZ0IBatQkotzfNB+VvkOeu6XUT3+X49IakheW6jVc3Tn56t9R9UmrPN+ze7h0eHwC92D48OgV/sHh4dgrbq7GurK/SXf/EkERHlTORSBOl/9wxok8OF10R329HVH5evnHpFtRvuF90nKuuooNK6RJTt3ifRcWdOn1Lt1uaFDbuvT4+xuCJeSzOTYspDcxcRURK8zqKS8cJDvvmGXHWgjEJeOUsaUS6Aea3SXFfGADBmQ3YA5cDowBFtntusgUSxivq8Ne3xpmXLp47bM8WCJpycn5OoQIZ9irVlbXfKgnkzZ8yUyQXImZeSZ6xoSDToIKSjvk2npi4k5HtpM36MTkxAn2Gg5yqEHH+RIUMdOiwR5NUEmCaz+p5lHjkcl3Mn9N7B8kxtDoI/1V6ICP9m9/DoEPjF7uHRIWirGJ/NZumuu2omsZIxGWEOWpWaiIh2VETsQR7z3bftUe2mr1yKy1Fei3o7hyVwZWlS2hXmrqp2+SXxfts52K/qzpySwJsFCHDJpLRImAOVxBmPsQB/X01q6hDF/whSK1WMeQ3mrmpMSJj+qIpms8CK4FJMJPX4MY0RBq5UKkZUB/UiqtgADPCgS4mtKTRBN5Wy9DEN94WIqAj3MIRHtVrR8zY3BSa6olabwpSYwJIQaBManvsAjtnwFxKYsywvXBWCkiKwKyZC3T+nZY4LRnsLgIwkA3pNX1lfZxekF7/43EuqrjfV3zBWC/9m9/DoEPjF7uHRIfCL3cOjQ9DeqDdiCurujGM7dGA+6qglY67q6wH3ViBDtA6f3aArF0vGnoTmKkgF3JPS+lnPCJBSLGp9vgv42hnGxCZfcVQG/TWyJi/Qh23yLjDLIXFgyXDsM9jUEqE+N+rsjnC/wOpyYDIqG+55MC9FMH57XxxcZ2T0eQZu91SX6K8pM994bSvz2vTmYEMCUypXTY68lSUgcgiNuapb7qfK51bW7ZIZmI+kjQKUuqiBBET6ScLzESbNvYX3atiQtA3uO1xnYPZjAthLye7SrtylszW3bEsOsvkIPDw8fqLhF7uHR4egrWJ8uVymK1dqXlFJY+6ZA3KCxQXNr5UCsQq9vWanNfcbWjQWDffbeUidM9QrItDrr2uSga4uET9npzWvO1hIqBfSEOeyxsyCaYIt4QNIgYER5zBdUxXEYis6FqsS8VQJtPiMXm7VKkSUGQ5yTN1UMSmwEngMQ7QRXxFyvhudKgl5/VJZSL1swt6qYLKLytpMiSpQFcRlNidj6LO0pqMM0xnheyugWSrU56rA9KSz5r7AJDz/8suqbmxMyDKyOeG/6+nXZluG+Z4Y0wQbiDK8fovGK7GQlvFn33dQ1VWP1C4geEJ75yG29GZn5n5m/m/MfJKZTzDzO5l5kJm/ycyn6v8Hrt2Th4fHdmGrYvzvEdE3nHOHqJYK6gQRfYaInnTOHSCiJ+vHHh4eb1FsJYtrLxH9NBH9XSIi51yJiErM/FEierje7ItE9DQRfbpVX5lshg7feScRNQZfvHZSxKNDBzXNdAYylRZWRUxLF3QAfxnEwN6dWlSqgkiI5x7eMaraReDR1T+kA3KiEhAQ9IKYarKsOvTisswTuCNMpgpTFaGXnHFcQ9E94ObUwaREd5PiCYJwAnMzUMRHj0W74+7AChEZz60EBr8Atx5VjfiMO/w2kyqK8TiPNlUr0C9XjWUkSMrzkkiJilYyNOGJkvQZ2iAZCIRZWND0393dohKuAfX12Pgu1e75F1+My2yvE7wbry6LRWLm0hXV7P57743LcybQa3amZjlaL2tVS52maY3gViKaJaL/yMzPMfPn66mbx5xzk0RE9f+jrTrx8PDYXmxlsSeI6F4i+n3n3D1EtEZvQGRn5keZ+RgzH5ufm7/2Fzw8PG4KtrLYLxHRJefcM/Xj/0a1xT/NzONERPX/M5t92Tn3mHPuqHPu6ODQ4GZNPDw82oCt5GefYuaLzHy7c+5VquVkf6X+93Ei+lz9/+PX6ivggLrq0UVVQwJw9J0PxeVMQutdK1Pn4nJxXvSY7pzhU2cxgZXL5ncMeLsLQH4wnNZTUAKPtN5Ut6qrRmJuq4Le6IwOyWBWdAlD0qh0Tz1EpYti/8Z85yBFtK1TBBhoogrsXCGhhKkDnT2COkteEcG+QqGgdchqINGDNATjtTo7eOE5cykR6v2b83oQEVEIWwlVQ/SxCs9LV5/sweSdefTLkBqqS3unJcD02dWtn4kx4LpfXROClAUTTZmDyMjJ6cuqjmBfBKNBU2ntbdgLL8sLL+uoN/F6tDtBgq3a2f8xEf0xM6eI6CwR/T2qSQVfYeZPENEFIvqFLfbl4eGxDdjSYnfOHSeio5tUvf/GDsfDw+Nmoa0edAEzpZI10SQyslgCxMrS2oKqm5qU7QC3LqYFZ5gbIggCKZugjVJevldaFnGrXNamqyo1DyTQ3mnVTcu1cVU3/Q6R9qBLWD4zIPCIwKXL9o8Odc541zW03ejPfI5UbYExHWIgDJreGvjjQOQsl7T4vDIthBK5nIi+A4NaRK6A2M1GBFVEFzCPgVFd8NgZbvv8qqhs+RJw6neb/SNIDWUJMBiu++hR/c7DwJ7ePuGus33cdpuYk63qFSRlGWZz4gFnBfJUWtTUgwdv12Os95nJeA46D4+Oh1/sHh4dAr/YPTw6BG3V2R0JYR+b6Kd1SHO8anKnjY6K6+v6spi/Zq5cVO0K6+I+WzamoDLUlZDIwrhXog4cmFTGVdgTiKLmOnVz4wdpggpjQlLfQ6uZ0ZVxjImw+S3EcbEZY2STrmH/TbjiG3jjb8hlBwAABDdJREFUYX6SST2OPOytXLlwNi4HpHP8ITlGmGhOooFkHvYN5cD9tGwi51YgCq7g5BkYyWpueCTxtPr24BCkAs9mVd08cNZj+eTJk6rdI488EpeX1zQZahr6HB6WdOX2WtAs98orOmfC/fffT0SNzwrCv9k9PDoEfrF7eHQIuEE0u5knY54lovNENExEV6/R/GbjrTAGIj8OCz8OjTc6jj3OuZHNKtq62OOTMh9zzm3mpNNRY/Dj8ONo5zi8GO/h0SHwi93Do0OwXYv9sW06L+KtMAYiPw4LPw6NGzaObdHZPTw82g8vxnt4dAjautiZ+UPM/Cozn2bmtrHRMvMfMPMMM78En7WdCpuZdzPzU3U67peZ+VPbMRZmzjDzD5j5+fo4/mX9833M/Ex9HF+u8xfcdDBzWOc3fGK7xsHM55j5RWY+zszH6p9txzNy02jb27bYmTkkon9PRH+diO4goo8x8x1tOv0fEtGHzGfbQYVdIaJ/5pw7TEQPENEn63PQ7rEUieh9zrm7iegIEX2ImR8got8kot+pj2OBiD5xk8exgU9RjZ58A9s1jvc6546AqWs7npGbR9vunGvLHxG9k4j+FI4/S0SfbeP59xLRS3D8KhGN18vjRPRqu8YCY3iciD6wnWMhohwRPUtE76Ca80Zis/t1E88/UX+A30dET1AtRGA7xnGOiIbNZ229L0TUS0SvU30v7UaPo51i/C4iwsiVS/XPtgvbSoXNzHuJ6B4iemY7xlIXnY9TjSj0m0R0hogWnYtJ2Nt1f36XiH6FhJFvaJvG4Yjoz5j5R8z8aP2zdt+Xm0rb3s7FvlkwWEeaApi5m4j+OxH9E+fc8rXa3ww45yLn3BGqvVnvJ6LDmzW7mWNg5g8T0Yxz7kf4cbvHUceDzrl7qaZmfpKZf7oN57S4Ltr2a6Gdi/0SEe2G4wkiutKkbTuwJSrsGw1mTlJtof+xc+6r2zkWIiLn3CLVsvk8QET9zLwRZ9qO+/MgEX2Emc8R0ZeoJsr/7jaMg5xzV+r/Z4joa1T7AWz3fbku2vZroZ2L/YdEdKC+05oior9JRF9v4/ktvk41CmyiLVJhXy+4RhT2BSI64Zz77e0aCzOPMHN/vZwlokeothH0FBH9fLvG4Zz7rHNuwjm3l2rPw5875/5Wu8fBzF3M3LNRJqIPEtFL1Ob74pybIqKLzLxBMLdB235jxnGzNz7MRsPPENFrVNMPf7WN5/0TIpokojLVfj0/QTXd8EkiOlX/P9iGcTxENZH0BSI6Xv/7mXaPhYjeRkTP1cfxEhH9i/rntxLRD4joNBH9VyJKt/EePUxET2zHOOrne77+9/LGs7lNz8gRIjpWvzf/g4gGbtQ4vAedh0eHwHvQeXh0CPxi9/DoEPjF7uHRIfCL3cOjQ+AXu4dHh8Avdg+PDoFf7B4eHQK/2D08OgT/Px2yxjOPPn/KAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(example_data[3].permute(1,2,0).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define latent distribution of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Classifiers\n",
    "##########################\n",
    "### MODEL\n",
    "##########################\n",
    "\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classes, grayscale):\n",
    "        self.inplanes = 64\n",
    "        if grayscale:\n",
    "            in_dim = 1\n",
    "        else:\n",
    "            in_dim = 3\n",
    "        super(ResNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_dim, 64, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        self.avgpool = nn.AvgPool2d(7, stride=1, padding=2)\n",
    "        self.fc = nn.Linear(1024 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, (2. / n)**.5)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.float()\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "#         x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "#         print(\"x shape:\", x.shape)\n",
    "        logits = self.fc(x)\n",
    "        probas = F.softmax(logits, dim=1)\n",
    "        return logits, probas\n",
    "\n",
    "\n",
    "\n",
    "def resnet152(num_classes, grayscale):\n",
    "    \"\"\"Constructs a ResNet-152 model.\"\"\"\n",
    "    model = ResNet(block=Bottleneck, \n",
    "                   layers=[3, 4, 36, 3],\n",
    "                   num_classes=NUM_CLASSES,\n",
    "                   grayscale=grayscale)\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Add here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SETTINGS\n",
    "##########################\n",
    "\n",
    "# Hyperparameters\n",
    "RANDOM_SEED = 1\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_EPOCHS = 10\n",
    "\n",
    "# Architecture\n",
    "NUM_FEATURES = 64*64\n",
    "NUM_CLASSES = 2\n",
    "BATCH_SIZE = 64\n",
    "DEVICE = 'cuda:0' # default GPU device\n",
    "GRAYSCALE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "# ##########################\n",
    "# ### COST AND OPTIMIZER\n",
    "# ##########################\n",
    "\n",
    "# model = resnet152(NUM_CLASSES, GRAYSCALE)\n",
    "# model.to(DEVICE)\n",
    "\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "\n",
    "# from tqdm.notebook import tqdm\n",
    "\n",
    "# def compute_accuracy(model, data_loader, device):\n",
    "#     correct_pred, num_examples = 0, 0\n",
    "#     for i, (features, targets) in enumerate(data_loader):\n",
    "            \n",
    "#         features = features.to(device)\n",
    "#         targets = targets.to(device)\n",
    "\n",
    "#         logits, probas = model(features)\n",
    "#         _, predicted_labels = torch.max(probas, 1)\n",
    "#         num_examples += targets.size(0)\n",
    "#         correct_pred += (predicted_labels == targets).sum()\n",
    "#     return correct_pred.float()/num_examples * 100\n",
    "    \n",
    "\n",
    "# start_time = time.time()\n",
    "# for epoch in tqdm(range(NUM_EPOCHS)):\n",
    "    \n",
    "#     model.train()\n",
    "#     for batch_idx, (features, targets) in enumerate(train_loader):\n",
    "        \n",
    "#         features = features.to(DEVICE)\n",
    "#         targets = targets.to(DEVICE)\n",
    "            \n",
    "#         ### FORWARD AND BACK PROP\n",
    "#         logits, probas = model(features)\n",
    "#         cost = F.cross_entropy(logits, targets)\n",
    "#         optimizer.zero_grad()\n",
    "        \n",
    "#         cost.backward()\n",
    "        \n",
    "#         ### UPDATE MODEL PARAMETERS\n",
    "#         optimizer.step()\n",
    "        \n",
    "#         ### LOGGING\n",
    "#         if not batch_idx % 50:\n",
    "#             print ('Epoch: %03d/%03d | Batch %04d/%04d | Cost: %.4f' \n",
    "#                    %(epoch+1, NUM_EPOCHS, batch_idx, \n",
    "#                      len(train_loader), cost))\n",
    "\n",
    "        \n",
    "\n",
    "#     model.eval()\n",
    "#     with torch.set_grad_enabled(False): # save memory during inference\n",
    "#         print('Epoch: %03d/%03d | Train: %.3f%% | Valid: %.3f%%' % (\n",
    "#               epoch+1, NUM_EPOCHS, \n",
    "#               compute_accuracy(model, train_loader, device=DEVICE),\n",
    "#               compute_accuracy(model, test_loader, device=DEVICE)))\n",
    "        \n",
    "#     print('Time elapsed: %.2f min' % ((time.time() - start_time)/60))\n",
    "    \n",
    "# print('Total Training Time: %.2f min' % ((time.time() - start_time)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), './models/celeba/classifier.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (6): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (7): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (8): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (9): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (10): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (11): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (12): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (13): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (14): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (15): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (16): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (17): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (18): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (19): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (20): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (21): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (22): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (23): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (24): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (25): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (26): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (27): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (28): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (29): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (30): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (31): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (32): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (33): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (34): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (35): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=2)\n",
       "  (fc): Linear(in_features=4096, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = resnet152(NUM_CLASSES, GRAYSCALE)\n",
    "classifier.to(DEVICE)\n",
    "\n",
    "classifier.load_state_dict(torch.load('models/celeba/classifier.pt'))\n",
    "classifier.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Latent distribution will be joint distribution of 10 gaussian normal distributions\n",
    "# and one 10 dimensional Gumbel Softmax distribution\n",
    "latent_spec = {'cont': 32,\n",
    "               'disc': [10]}\n",
    "latent_dim = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from celeba.models import VAE\n",
    "\n",
    "model = VAE(latent_spec=latent_spec, img_size=(3, 64, 64), use_cuda=True).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from celeba.training import Trainer\n",
    "\n",
    "# Define the capacities\n",
    "# Continuous channels\n",
    "cont_capacity = [0.0, 50.0, 100000, 100.0]  # Starting at a capacity of 0.0, increase this to 5.0\n",
    "                                         # over 25000 iterations with a gamma of 30.0\n",
    "# Discrete channels\n",
    "disc_capacity = [0.0, 10.0, 100000, 100.0]  # Starting at a capacity of 0.0, increase this to 5.0\n",
    "                                         # over 25000 iterations with a gamma of 30.0\n",
    "\n",
    "# Build optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=5e-4)\n",
    "    \n",
    "# Build a trainer\n",
    "trainer = Trainer(model, optimizer,\n",
    "                  cont_capacity=cont_capacity,\n",
    "                  disc_capacity=disc_capacity, use_cuda=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Build a visualizer which will be passed to trainer to visualize progress during training\n",
    "# from visualize import Visualizer\n",
    "\n",
    "# viz = Visualizer(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model for 10 epochs\n",
    "# Note this should really be a 100 epochs and trained on a GPU, but this is just to demo\n",
    "\n",
    "# trainer.train(train_loader, epochs=100, save_training_gif=('./training.gif', viz))\n",
    "if VAE_TRAIN:\n",
    "    trainer.train(train_loader, epochs=300)\n",
    "    torch.save(model.state_dict(), 'models/celeba/model.pt')\n",
    "else:\n",
    "    model.load_state_dict(torch.load('models/celeba/model.pt'))\n",
    "    model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "for param in classifier.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloaders import CelebADataset\n",
    "from torchvision import transforms\n",
    "train_data = CelebADataset('/home/data/bvaa/CelebA', transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5964afa736d64fc59b0aad72d4d3673d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=120000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "list_index = {}\n",
    "for i in tqdm(range(len(train_data))):\n",
    "    index = train_data[i][1]\n",
    "    if index not in list_index.keys():\n",
    "        list_index[index] = [i]\n",
    "    else:\n",
    "        list_index[index].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_sample_list = {}\n",
    "def get_average_latent_space(list_index):\n",
    "    for i in tqdm(list_index.keys()):\n",
    "        for j in list_index[i]:\n",
    "            output, l_dist = model(train_data[j][0].unsqueeze(0).cuda())\n",
    "            l_sample_x = model.reparameterize(l_dist)\n",
    "            if i not in l_sample_list.keys():\n",
    "                l_sample_list[i] = [l_sample_x]\n",
    "            else:\n",
    "                l_sample_list[i].append(l_sample_x)\n",
    "        l_sample_list[i] = {'mean':torch.mean(torch.stack(l_sample_list[i]), dim=0),\n",
    "                           'std':torch.std(torch.stack(l_sample_list[i]), dim=0)}\n",
    "        \n",
    "get_average_latent_space(list_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def added_noise(image, digit, alphax=0.2, betay=1, plot=False):\n",
    "    output, l_dist = model(image.unsqueeze(0).float().cuda())\n",
    "    l_sample_x = model.reparameterize(l_dist)\n",
    "    alpha = torch.clamp(torch.randn(l_sample_list[digit]['std'].shape).cuda(), min=-1, max=1)\n",
    "    test_sample = l_sample_list[digit]['mean'] + alpha*l_sample_list[digit]['std']\n",
    "    test_sample = betay * l_sample_x + alphax * test_sample\n",
    "    test = model.decode(test_sample)\n",
    "#     preds = torch.argmax(classifier(F.upsample(test, (28,28), mode='bilinear', align_corners=True)))\n",
    "#     print(preds.item())\n",
    "    if plot:\n",
    "        plt.imshow(test[0].permute(1, 2, 0).cpu().detach().numpy(), interpolation='none')\n",
    "    return test_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(example_data[3].permute(1,2,0).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "added_noise(example_data[3], 1, alphax=0.8, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def check_distribution(digit, plot=False):\n",
    "    alpha = torch.clamp(torch.randn(l_sample_list[digit]['std'].shape).cuda(), min=-1, max=1)\n",
    "    test_sample = l_sample_list[digit]['mean'] + alpha*l_sample_list[digit]['std']\n",
    "    test = model.decode(test_sample)\n",
    "#     preds = torch.argmax(classifier(F.upsample(test, (28,28), mode='bilinear', align_corners=True)))\n",
    "#     print(preds.item())\n",
    "    if plot:\n",
    "        plt.imshow(test[0].permute(1, 2, 0).cpu().detach().numpy(), interpolation='none')\n",
    "    return test_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_distribution(1, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def digits_add(digit1, digit2, alpha=1, beta=1, plot=False):\n",
    "    l_1 = check_distribution(digit1)\n",
    "    l_2 = check_distribution(digit2)\n",
    "    if plot:\n",
    "        test = model.decode(beta*l_1+alpha*l_2)\n",
    "        plt.imshow(test[0].permute(1,2,0).cpu().detach().numpy(), interpolation='none')\n",
    "#         preds = classifier(F.upsample(test, (28,28), mode='bilinear', align_corners=True))\n",
    "#         print(preds.dtype)\n",
    "#         print(torch.argmax(preds).item())\n",
    "    return torch.norm(l_1-l_2), l_1, l_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg_dist(digit1, digit2, exp=10000):\n",
    "    cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "    distance = []\n",
    "    similarity = []\n",
    "    for i in range(exp):\n",
    "        dist, l1, l2 = digits_add(digit1,digit2)\n",
    "        similar = cos(l1,l2)\n",
    "        distance.append(dist.item())\n",
    "        similarity.append(similar.item())\n",
    "    a = round(sum(distance)/len(distance),5)\n",
    "    b = round(sum(similarity)/len(similarity),5)\n",
    "    return a,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def digit_to_study(digit):\n",
    "    distance = {}\n",
    "    similarity = {}\n",
    "    for i in tqdm(range(10)):\n",
    "        distance[i], similarity[i] = get_avg_dist(digit,i)\n",
    "    return distance, similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_avg_dist(1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_avg_dist(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_avg_dist(2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits_add(1,-1,0,plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# digits_add(1,3,0.3,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# digits_add(1,2,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# digit_to_study(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# digit_to_study(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check_distribution(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if FIND_DIST is True:\n",
    "#     l_means = []\n",
    "#     l_stds = []\n",
    "#     for i in l_sample_list.keys():\n",
    "#         l_means.append(l_sample_list[i]['mean'])\n",
    "#         l_stds.append(l_sample_list[i]['std'])\n",
    "\n",
    "#     l_mean_tensor = torch.stack(l_means).squeeze(1)\n",
    "#     # print(l_mean_tensor.shape)\n",
    "\n",
    "#     l_std_tensor = torch.stack(l_stds).squeeze(1)\n",
    "#     # print(l_std_tensor.shape)\n",
    "\n",
    "#     torch.save(l_mean_tensor, 'tensor/latent_mean.pt')\n",
    "#     torch.save(l_std_tensor, 'tensor/latent_std.pt')\n",
    "\n",
    "# else:\n",
    "#     l_mean_tensor = torch.load('tensor/latent_mean.pt')\n",
    "#     l_std_tensor = torch.load('tensor/latent_std.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = enumerate(test_loader)\n",
    "batch_idx, (example_data,target) = next(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check(i, digit1, digit2):\n",
    "    \n",
    "    alpha = torch.clamp(torch.randn(l_sample_list[digit1]['std'].shape).cuda(), min=-1, max=1)\n",
    "    test_sample = l_sample_list[digit1]['mean'] + F.normalize(alpha)*l_sample_list[digit1]['std']\n",
    "    \n",
    "    alpha = torch.clamp(torch.randn(l_sample_list[digit2]['std'].shape).cuda(), min=-1, max=1)\n",
    "    test_sample += l_sample_list[digit2]['mean'] + F.normalize(alpha)*l_sample_list[digit2]['std']\n",
    "    \n",
    "    example_img = example_data[i,:,:,:].unsqueeze(0).cuda()\n",
    "    output, l_dist = model(example_img)\n",
    "    l_sample = model.reparameterize(l_dist)\n",
    "    test_sample = l_sample + 0.4*test_sample\n",
    "    test = model.decode(test_sample)\n",
    "    preds = torch.argmax(classifier(F.upsample(test, (28,28), mode='bilinear', align_corners=True)))\n",
    "    print(preds)\n",
    "    plt.imshow(model.decode(test_sample)[0,0].cpu().detach().numpy(), cmap='gray', interpolation='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check(2,1,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_64(data):\n",
    "#     l_sample = None\n",
    "#     for i in range(data.shape[0]):\n",
    "#         output, l_dist_x = model(data[i,:,:,:].unsqueeze(0).cuda())\n",
    "#         l_sample_x = model.reparameterize(l_dist_x)\n",
    "#         if l_sample is None:\n",
    "#             l_sample = l_sample_x\n",
    "#         else:\n",
    "#             l_sample += l_sample_x\n",
    "#     l_sample = l_sample / data.shape[0]\n",
    "#     new_output = model.decode(l_sample)\n",
    "#     plt.imshow(new_output[0][0].detach().cpu().numpy(), cmap='gray', interpolation='none')\n",
    "#     pred = classifier(F.upsample(new_output, (28,28), mode='bilinear', align_corners=True))\n",
    "#     print(pred)\n",
    "#     print(torch.argmax(pred))\n",
    "#     return l_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_batch_avg(data):\n",
    "#     l_sample = None\n",
    "#     for i in range(data.shape[0]):\n",
    "#         output, l_dist_x = model(data[i,:,:,:].unsqueeze(0).cuda())\n",
    "#         l_sample_x = model.reparameterize(l_dist_x)\n",
    "#         if l_sample is None:\n",
    "#             l_sample = l_sample_x\n",
    "#         else:\n",
    "#             l_sample += l_sample_x\n",
    "#     l_sample = l_sample / data.shape[0]\n",
    "# #     new_output = model.decode(l_sample)\n",
    "# #     plt.imshow(new_output[0][0].detach().cpu().numpy(), cmap='gray', interpolation='none')\n",
    "# #     pred = classifier(F.upsample(new_output, (28,28), mode='bilinear', align_corners=True))\n",
    "# #     print(pred)\n",
    "# #     print(torch.argmax(pred))\n",
    "#     return l_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_avg_mnist(img1, data):\n",
    "# #     new_l_sample = None\n",
    "# #     count = len(list_to_process)\n",
    "#     output, l_dist_x = model(img1.cuda())\n",
    "#     l_sample_x = model.reparameterize(l_dist_x)\n",
    "#     l_sample_y = get_batch_avg(data)\n",
    "# #     output, l_dist_y = model(img2.cuda())\n",
    "# #     l_sample_y = model.reparameterize(l_dist_y)\n",
    "    \n",
    "#     l_sample = 1*l_sample_x + 0.4*l_sample_y\n",
    "    \n",
    "#     new_output = model.decode(l_sample)\n",
    "# #     for i in list_to_process:\n",
    "# #         example_img = example_data[i,:,:,:].unsqueeze(0).cuda()\n",
    "# #         output, l_dist = model(example_img)\n",
    "# #         l_sample = model.reparameterize(l_dist)\n",
    "# #         if new_l_sample is None:\n",
    "# #             new_l_sample = l_sample\n",
    "# #         else:\n",
    "# #             new_l_sample += l_sample\n",
    "# #     new_l_sample = new_l_sample / count\n",
    "# #     new_output = model.decode(new_l_sample)\n",
    "#     plt.imshow(new_output[0][0].detach().cpu().numpy(), cmap='gray', interpolation='none')\n",
    "#     pred = classifier(F.upsample(new_output, (28,28), mode='bilinear', align_corners=True))\n",
    "#     print(pred)\n",
    "#     print(torch.argmax(pred))\n",
    "#     print(pred[0,2].item(), pred[0,5].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_mnist(list_to_process):\n",
    "#     new_l_sample = None\n",
    "#     count = len(list_to_process)\n",
    "#     for i in list_to_process:\n",
    "#         example_img = example_data[i,:,:,:].unsqueeze(0).cuda()\n",
    "#         output, l_dist = model(example_img)\n",
    "#         l_sample = model.reparameterize(l_dist)\n",
    "#         if new_l_sample is None:\n",
    "#             new_l_sample = l_sample\n",
    "#         else:\n",
    "#             new_l_sample += l_sample\n",
    "#     new_l_sample = new_l_sample / count\n",
    "#     new_output = model.decode(new_l_sample)\n",
    "#     plt.imshow(new_output[0][0].detach().cpu().numpy(), cmap='gray', interpolation='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def check(i, j, alpha, beta):\n",
    "#     im1 = example_data[i,:,:,:].unsqueeze(0).cuda()\n",
    "#     im2 = example_data[j,:,:,:].unsqueeze(0).cuda()\n",
    "#     out1, l_dist1 = model(im1)\n",
    "#     out2, l_dist2 = model(im2)\n",
    "#     l_sample1 = model.reparameterize(l_dist1)\n",
    "#     l_sample2 = model.reparameterize(l_dist2)\n",
    "#     l_sample = alpha*l_sample1 + beta*l_sample2\n",
    "#     new_out = model.decode(l_sample)\n",
    "# #     new_out1 = model.decode(l_sample1)\n",
    "# #     new_out2 = model.decode(l_sample2)\n",
    "#     plt.figure(figsize=(10,15))\n",
    "#     plt.subplot(1,3,1)\n",
    "#     plt.imshow(example_data[i][0].detach().cpu().numpy(), cmap='gray', interpolation='none')\n",
    "#     plt.subplot(1,3,2)\n",
    "#     plt.imshow(example_data[j][0].detach().cpu().numpy(), cmap='gray', interpolation='none')\n",
    "#     plt.subplot(1,3,3)\n",
    "#     plt.imshow(new_out[0][0].detach().cpu().numpy(), cmap='gray', interpolation='none')\n",
    "#     print(torch.argmax(classifier(F.upsample(new_out, (28,28), mode='bilinear', align_corners=True))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpha=1\n",
    "# beta = 1.2\n",
    "# check(19,11, alpha, beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Attack(nn.Module):\n",
    "#     def __init__(self, attack_digit=attack_digit, target_digit=target_digit, vae=model, classifier=classifier, avg_latent=l_sample_list):\n",
    "#         super(self, Attack).__init__()\n",
    "#         self.classifier = classifier\n",
    "#         self.classifier.eval()\n",
    "#         self.vae = vae\n",
    "#         self.vae.eval()\n",
    "#         self.avg_latent = avg_latent\n",
    "#         self.attack_digit = attack_digit\n",
    "#         self.target_digit = target_digit\n",
    "#         self.hidden_layers = hidden_layers\n",
    "#         self.hidden_layers.insert(0, latent_dim)\n",
    "#         self.hidden_layers.append(latent_dim)\n",
    "#         self.layers = []\n",
    "        \n",
    "#         for i in range(len(self.hidden_layers)-1):\n",
    "#             self.layers.append(nn.Linear(self.hidden_layers[i], self.hidden_layers[i+1]))\n",
    "        \n",
    "#         self.layers = nn.ModuleList(self.layers)\n",
    "        \n",
    "#     def forward(self, x, y):\n",
    "#         _, l_dist_x = self.vae(x)\n",
    "#         _, l_dist_y = self.vae(y)\n",
    "#         l_sample_x = self.vae.reparameterize(l_dist_x)\n",
    "#         l_sample_y = self.vae.reparameterize(l_dist_y)\n",
    "#         noised_sample = l_sample\n",
    "#         for layer in self.layers:\n",
    "#             noised_sample = layer(noised_sample)\n",
    "#         noised_images = self.vae.decoder(noised_sample)\n",
    "#         preds = self.classifier(F.upsample(noised_image, (28,28), mode='bilinear', align_corners=True))\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import exp\n",
    "\n",
    "def gaussian(window_size, sigma):\n",
    "    gauss = torch.Tensor([exp(-(x - window_size//2)**2/float(2*sigma**2)) for x in range(window_size)])\n",
    "    return gauss/gauss.sum()\n",
    "\n",
    "def create_window(window_size, channel):\n",
    "    _1D_window = gaussian(window_size, 1.5).unsqueeze(1)\n",
    "    _2D_window = _1D_window.mm(_1D_window.t()).float().unsqueeze(0).unsqueeze(0)\n",
    "    window = torch.Tensor(_2D_window.expand(channel, 1, window_size, window_size).contiguous())\n",
    "    return window\n",
    "\n",
    "def _ssim(img1, img2, window, window_size, channel, size_average = True):\n",
    "    mu1 = F.conv2d(img1, window, padding = window_size//2, groups = channel)\n",
    "    mu2 = F.conv2d(img2, window, padding = window_size//2, groups = channel)\n",
    "\n",
    "    mu1_sq = mu1.pow(2)\n",
    "    mu2_sq = mu2.pow(2)\n",
    "    mu1_mu2 = mu1*mu2\n",
    "\n",
    "    sigma1_sq = F.conv2d(img1*img1, window, padding = window_size//2, groups = channel) - mu1_sq\n",
    "    sigma2_sq = F.conv2d(img2*img2, window, padding = window_size//2, groups = channel) - mu2_sq\n",
    "    sigma12 = F.conv2d(img1*img2, window, padding = window_size//2, groups = channel) - mu1_mu2\n",
    "\n",
    "    C1 = 0.01**2\n",
    "    C2 = 0.03**2\n",
    "\n",
    "    ssim_map = ((2*mu1_mu2 + C1)*(2*sigma12 + C2))/((mu1_sq + mu2_sq + C1)*(sigma1_sq + sigma2_sq + C2))\n",
    "\n",
    "    if size_average:\n",
    "        return ssim_map.mean()\n",
    "    else:\n",
    "        return ssim_map.mean(1).mean(1).mean(1)\n",
    "\n",
    "class SSIM(nn.Module):\n",
    "    def __init__(self, window_size = 11, size_average = True):\n",
    "        super(SSIM, self).__init__()\n",
    "        self.window_size = window_size\n",
    "        self.size_average = size_average\n",
    "        self.channel = 1\n",
    "        self.window = create_window(window_size, self.channel)\n",
    "\n",
    "    def forward(self, img1, img2):\n",
    "        (_, channel, _, _) = img1.size()\n",
    "\n",
    "        if channel == self.channel and self.window.data.type() == img1.data.type():\n",
    "            window = self.window\n",
    "        else:\n",
    "            window = create_window(self.window_size, channel)\n",
    "            \n",
    "            if img1.is_cuda:\n",
    "                window = window.cuda(img1.get_device())\n",
    "            window = window.type_as(img1)\n",
    "            \n",
    "            self.window = window\n",
    "            self.channel = channel\n",
    "\n",
    "\n",
    "        return _ssim(img1, img2, window, self.window_size, channel, self.size_average)\n",
    "\n",
    "def ssim(img1, img2, window_size = 11, size_average = True):\n",
    "    (_, channel, _, _) = img1.size()\n",
    "    window = create_window(window_size, channel)\n",
    "    \n",
    "    if img1.is_cuda:\n",
    "        window = window.cuda(img1.get_device())\n",
    "    window = window.type_as(img1)\n",
    "    \n",
    "    return _ssim(img1, img2, window, window_size, channel, size_average)\n",
    "\n",
    "ssim_loss = SSIM(window_size = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = True\n",
    "device = torch.device('cuda' if use_cuda else 'cpu')\n",
    "\n",
    "# Constrained Translator\n",
    "class Noise(nn.Module):\n",
    "    def __init__(self, hidden_layers=[50, 100, latent_dim], latent_dim=latent_dim):\n",
    "        super(Noise, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.hidden_layers.insert(0, latent_dim)\n",
    "        self.layers = []\n",
    "        \n",
    "        for i in range(len(self.hidden_layers)-1):\n",
    "            self.layers.append(nn.Linear(self.hidden_layers[i], self.hidden_layers[i+1]))\n",
    "        \n",
    "        self.layers = nn.ModuleList(self.layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constrained Cofficients\n",
    "class Cofficients(nn.Module):\n",
    "    def __init__(self, hidden_layers=[40, 20, 10, 1], latent_dim=latent_dim):\n",
    "        super(Cofficients, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.hidden_layers.insert(0, latent_dim)\n",
    "        self.layers = []\n",
    "        \n",
    "        for i in range(len(self.hidden_layers)-1):\n",
    "            self.layers.append(nn.Linear(self.hidden_layers[i], self.hidden_layers[i+1]))\n",
    "        \n",
    "        self.layers = nn.ModuleList(self.layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# use_cuda = True\n",
    "# device = torch.device('cuda' if use_cuda else 'cpu')\n",
    "\n",
    "\n",
    "# def create_logits(preds, device=device):\n",
    "#     preds = preds.cpu()\n",
    "#     logits = preds.cpu()\n",
    "    \n",
    "#     sorted_ = torch.argsort(preds, dim=1, descending=True)\n",
    "#     first = sorted_[:,0]\n",
    "#     second = sorted_[:,1]\n",
    "#     print(first)\n",
    "#     print(second)\n",
    "    \n",
    "#     p_first = preds.gather(1, first.view(-1,1))\n",
    "#     p_second = preds.gather(1, second.view(-1,1))\n",
    "#     means = torch.mean(torch.stack([p_first, p_second]), dim=0).squeeze(1)\n",
    "#     print(means)\n",
    "#     diff = 0.1*(first - second)\n",
    "#     print(diff)\n",
    "#     print((means-diff).shape)\n",
    "#     j = torch.arange(logits.size(0)).long()\n",
    "#     logits[j, first] = torch.FloatTensor(means - diff)\n",
    "#     logits[j, second] = torch.FloatTensor(means + diff)\n",
    "# #     print(logits[0])\n",
    "#     return logits.to(device), first, second\n",
    "\n",
    "# a = torch.randn((10,4)).cuda()\n",
    "# b = create_logits(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "use_cuda = True\n",
    "device = torch.device('cuda' if use_cuda else 'cpu')\n",
    "\n",
    "\n",
    "def create_logits(preds, device=device):\n",
    "    preds = preds.cpu()\n",
    "    logits = preds\n",
    "    \n",
    "    sorted_ = torch.argsort(preds, dim=1, descending=True)\n",
    "    first = sorted_[:,0]\n",
    "    second = sorted_[:,1]\n",
    "    \n",
    "    p_first = preds.gather(1, first.view(-1,1))\n",
    "    p_second = preds.gather(1, second.view(-1,1))\n",
    "#     print(p_first.shape)\n",
    "    \n",
    "    means = torch.mean(torch.stack([p_first, p_second]), dim=0).squeeze(1)\n",
    "#     print(means.shape)\n",
    "    diff = 0.5*(p_first - p_second).squeeze(1)\n",
    "#     print(diff.shape)\n",
    "    j = torch.arange(logits.size(0)).long()\n",
    "    \n",
    "    logits[j, first] = torch.FloatTensor(means - diff)\n",
    "    logits[j, second] = torch.FloatTensor(means + diff)\n",
    "    \n",
    "    return logits.to(device), first, second\n",
    "\n",
    "def structural(org_image, noised_image):\n",
    "    batch_size, channels, width, height = org_image.shape\n",
    "    loss1 = 0\n",
    "    for b_ in range(batch_size):\n",
    "        ch_loss = 0\n",
    "        for ch_ in range(channels):\n",
    "            ch_loss += 1-ssim(org_image[b_][ch_].detach().cpu().numpy(), noised_image[b_][ch_].detach().cpu().numpy())\n",
    "        loss1 += ch_loss/channels\n",
    "    return loss1\n",
    "            \n",
    "class T_Loss(nn.Module):\n",
    "    def __init__(self, decoder=model.decode, classifier=classifier,\n",
    "                 latent_dim=latent_dim, l_samples=l_sample_list,\n",
    "                 classes=len(l_sample_list.keys())):\n",
    "        super(T_Loss, self).__init__()\n",
    "        self.decoder = decoder\n",
    "        self.classifier = classifier\n",
    "#         self.means = means\n",
    "#         self.stds = stds\n",
    "        self.l_samples = l_samples\n",
    "        self.classes = classes\n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "        \n",
    "    def forward(self, coffs, noises, org_x, targets, alpha=0.6, beta=1):\n",
    "        \n",
    "        org_image = self.decoder(org_x)\n",
    "        \n",
    "        preds = self.classifier(org_image)[1]\n",
    "#         print(preds)\n",
    "        \n",
    "        alt_target, first, second = create_logits(preds)\n",
    "        \n",
    "        means = []\n",
    "        stds = []\n",
    "        \n",
    "        for key in second:\n",
    "            means.append(self.l_samples[key.item()]['mean'])\n",
    "            stds.append(self.l_samples[key.item()]['std'])\n",
    "        \n",
    "        means = torch.stack(means)\n",
    "        stds = torch.stack(stds)\n",
    "        noised_latent = means.squeeze(1) + torch.clamp(noises, min=-5, max=5) * stds.squeeze(1)\n",
    "        \n",
    "        noised_latent = torch.clamp(coffs, min=-3, max=3) * noised_latent\n",
    "#         noise_latent = F.normalize(coffs) * noise_latent\n",
    "        \n",
    "        noised_sample = beta * org_x + alpha * noised_latent\n",
    "        \n",
    "        noised_image = self.decoder(noised_sample)\n",
    "#         print(noised_image.shape)\n",
    "        preds = self.classifier(noised_image)[1]\n",
    "        \n",
    "        loss1 = ssim_loss(org_image, noised_image)\n",
    "        print(preds.shape)\n",
    "        print(alt_target.shape)\n",
    "        loss2 = nn.BCELoss(reduction='sum')(preds, alt_target)\n",
    "        \n",
    "        loss3 = torch.norm(org_image-noised_image, p=2)  \n",
    "\n",
    "        loss = 400*(1-loss1) + 0.6*loss2 + 20*loss3\n",
    "#         loss = 0.8*loss2 + 20*loss3\n",
    "#         loss = loss2 + 20*loss3\n",
    "#         loss.requires_grad = True\n",
    "        \n",
    "        out_labels = preds.argmax(dim=1, keepdim=True)\n",
    "#         print(out_labels)\n",
    "#         print(torch.empty(out_labels.shape).fill_(target_label))\n",
    "#         print(preds)\n",
    "#         correct = out_labels.eq(torch.Tensor([target_label]*out_labels.shape[0]).to(device)).sum()\n",
    "#         print(out_labels.shape)\n",
    "#         print((out_labels.squeeze(1)==targets.cuda()).sum())\n",
    "        correct = (out_labels.squeeze(1)==targets.cuda()).sum()\n",
    "#         print(out_labels.shape)\n",
    "#         print(correct)\n",
    "#         print(torch.Tensor([target_label]*out_labels.shape[0]))\n",
    "#         print(out_labels)\n",
    "        return loss, correct.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alt_target = 5\n",
    "noise = Noise().to(device)\n",
    "cofficient = Cofficients().to(device)\n",
    "\n",
    "for param in noise.parameters():\n",
    "    param.requires_grad=True\n",
    "    \n",
    "for param in cofficient.parameters():\n",
    "    param.requires_grad=True\n",
    "\n",
    "tloss = T_Loss().to(device)\n",
    "tloss.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count_digit = 0\n",
    "# for i in range(len(train_data)):\n",
    "#     if train_data[i][1]==5:\n",
    "#         count_digit += 1\n",
    "# print(count_digit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "attack_log_interval = 1\n",
    "\n",
    "noise.train()\n",
    "cofficient.train()\n",
    "\n",
    "optimizer1 = optim.Adam(noise.parameters(), lr=1e-4)\n",
    "# optimizer1 = torch.optim.SGD(noise.parameters(), lr=1e-4, momentum=0.9)\n",
    "\n",
    "# optimizer2 = torch.optim.SGD(cofficient.parameters(), lr=1e-4, momentum=0.9)\n",
    "optimizer2 = optim.Adam(cofficient.parameters(), lr=1e-4)\n",
    "\n",
    "\n",
    "# scheduler1 = torch.optim.lr_scheduler.CyclicLR(optimizer1, base_lr=1e-7, max_lr=0.1)\n",
    "# scheduler2 = torch.optim.lr_scheduler.CyclicLR(optimizer2, base_lr=1e-7, max_lr=0.1)\n",
    "\n",
    "for epoch in tqdm(range(150)):\n",
    "    epoch_loss = 0\n",
    "    epoch_correct = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data = data.float()\n",
    "        data = torch.Tensor(data).float().to(device)\n",
    "        print(data.type)\n",
    "        _, l_dist = model(data)\n",
    "        l_sample = model.reparameterize(l_dist)\n",
    "        \n",
    "        n = noise(l_sample)\n",
    "        c = cofficient(l_sample)\n",
    "\n",
    "        optimizer1.zero_grad()\n",
    "        optimizer2.zero_grad()\n",
    "        \n",
    "        loss, correct = tloss(c, n, l_sample, target, alpha=1, beta=0)\n",
    "\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer1.step()\n",
    "        optimizer2.step()\n",
    "\n",
    "#         scheduler1.step()\n",
    "#         scheduler2.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "        epoch_correct += correct\n",
    "        \n",
    "    if (epoch+1) % attack_log_interval == 0:\n",
    "        print('Train Epoch: {}\\tLoss: {:.6f}\\tCorrect: {}'.format(\n",
    "            epoch+1, epoch_loss/batch_idx, epoch_correct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(noise, 'models/{}/noise.pt'.format(FOLDER))\n",
    "torch.save(cofficient, 'models/{}/coff.pt'.format(FOLDER))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise.eval()\n",
    "cofficient.eval()\n",
    "total_correct = 0\n",
    "total_test = 0\n",
    "for batch_idx, (data, target) in enumerate(test_loader):\n",
    "    total_test += data.shape[0]\n",
    "    data = torch.FloatTensor(data).to(device)\n",
    "\n",
    "    _, l_dist = model(data)\n",
    "    l_sample = model.reparameterize(l_dist)\n",
    "    \n",
    "    noise_ = noise(l_sample)\n",
    "    coff_ = cofficient(l_sample)\n",
    "    \n",
    "    loss, correct = tloss(coff_, noise_, l_sample, target, 1, 0)\n",
    "    total_correct += correct\n",
    "#     print(correct)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         print(correct)\n",
    "#         epoch_loss += loss.item()\n",
    "    \n",
    "\n",
    "#     if (epoch+1) % attack_log_interval == 0:\n",
    "#         print('Train Epoch: \\tCorrect: {}'.format(\n",
    "#             epoch, epoch_correct))\n",
    "print(total_correct)\n",
    "print(\"Accuracy: \", 100*(total_correct/total_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check(i, alpha=0.6, beta=1):\n",
    "    _, l_dist = model(example_data[i].unsqueeze_(0).to(device))\n",
    "    l_sample = model.reparameterize(l_dist)\n",
    "\n",
    "    org_preds = classifier(F.upsample(model.decode(l_sample), (28,28), mode='bilinear', align_corners=True))\n",
    "#     print(\"original: \", torch.argmax(org_preds, dim=1))\n",
    "\n",
    "    noises = noise(l_sample)\n",
    "    coffs = cofficient(l_sample)\n",
    "\n",
    "    d = torch.argsort(org_preds, dim=1, descending=True)\n",
    "\n",
    "    noised_latent = l_sample_list[d[0,1].item()]['mean'].squeeze(1) + torch.clamp(noises, min=-5, max=5) * l_sample_list[d[0,1].item()]['std'].squeeze(1)\n",
    "    \n",
    "    noised_latent = torch.clamp(coffs, min=-3, max=3) * noised_latent\n",
    "#     noised_latent = F.normalize(coffs) * noised_latent\n",
    "\n",
    "    noised_sample = beta * l_sample + alpha * noised_latent\n",
    "\n",
    "    noised_image = model.decode(noised_sample)\n",
    "\n",
    "    fake_preds = classifier(F.upsample(noised_image, (28,28), mode='bilinear', align_corners=True))\n",
    "#     print(\"noised: \", torch.argmax(fake_preds, dim=1))\n",
    "\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(example_data[i][0].detach().cpu().numpy(), cmap='gray', interpolation='none')\n",
    "    plt.title(\"org:{}\".format(torch.argmax(org_preds, dim=1)))\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(noised_image[0][0].detach().cpu().numpy(), cmap='gray', interpolation='none')\n",
    "    plt.title(\"fake:{}\".format(torch.argmax(fake_preds, dim=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(64):\n",
    "    check(i,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(i, means=l_mean_tensor, stds=l_std_tensor, latent_dim=latent_dim, classes=len(train_data.classes)):\n",
    "    _, l_dist = model(example_data[i].unsqueeze_(0).to(device))\n",
    "    l_sample = model.reparameterize(l_dist)\n",
    "    noises = noise(l_sample)\n",
    "    coffs = cofficient(l_sample)\n",
    "#     print(coffs.shape)\n",
    "#     print(noises.shape)\n",
    "    noised_latent = means + noises.reshape(noises.shape[0], classes, latent_dim)*stds\n",
    "    noised_latent = coffs[:,:,None]*noised_latent\n",
    "#     print(noised_latent.shape)\n",
    "#     print(l_sample.shape)\n",
    "#     print(torch.transpose(coff[:,None].cuda()*avg_latent.T, 1, 2).sum(1).shape)\n",
    "#     noised_latent = l_sample + 2e-1*torch.transpose(coff[:,None].cuda()*avg_latent.T, 1, 2).sum(1)\n",
    "#     print(noised_latent.shape)\n",
    "#     print(noised_sample)\n",
    "#     print(l_sample)\n",
    "#     noised_sample = 1 * ((l_sample - l_sample.min())/(l_sample.max() - l_sample.min())) + 1e-2 * ((noised_sample - noised_sample.min())/(noised_sample.max() - noised_sample.min()))\n",
    "#     noised_sample = 1 * l_sample + 2e-2 * noised_sample\n",
    "#     noised_sample = l_sample + 1e-7 * noised_sample\n",
    "    final = model.decode(l_sample+1e-12*noised_latent.sum(dim=1))\n",
    "#     print(final.shape)\n",
    "    pred_org = torch.argmax(classifier(F.upsample(example_data[i,:,:,:].unsqueeze(0).cuda(), (28,28), mode='bilinear', align_corners=True)))\n",
    "    pred = torch.argmax(classifier(F.upsample(final, (28,28), mode='bilinear', align_corners=True)), dim=1)\n",
    "#     print(pred)\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(example_data[i][0].detach().cpu().numpy(), cmap='gray', interpolation='none')\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(final[0][0].detach().cpu().numpy(), cmap='gray', interpolation='none')\n",
    "    plt.title(\"Prediction: {}, {}\".format(pred_org.item(), pred.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(64):\n",
    "    test(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.transpose(torch.clamp(coff[:,None].cuda(), min=-0.8, max=0.3)*self.avg_latent.T, 1, 2).sum(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
