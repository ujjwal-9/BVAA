{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a JointVAE model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get MNIST data\n",
    "Build a simple JointVAE model on MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "VAE_TRAIN = True\n",
    "FIND_DIST = False\n",
    "FOLDER = \"dist4-svhn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: /home/data/bvaa/train_32x32.mat\n",
      "Using downloaded and verified file: /home/data/bvaa/test_32x32.mat\n"
     ]
    }
   ],
   "source": [
    "from dataloaders import get_svhn_dataloader\n",
    "# train_loader, test_loader = get_mnist_dataloaders_attack(2, 5, train_batch_size=64, test_batch_size=64, path_to_data='/home/data/bvaa')\n",
    "train_loader, test_loader = get_svhn_dataloader(batch_size=64, path_to_data='/home/data/bvaa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: /home/data/bvaa/train_32x32.mat\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "all_transforms = transforms.Compose([\n",
    "        transforms.Resize(32),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "train_data = datasets.SVHN('/home/data/bvaa/', split='train', download=True,\n",
    "                                transform=all_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 32, 32])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[1][0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define latent distribution of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Latent distribution will be joint distribution of 10 gaussian normal distributions\n",
    "# and one 10 dimensional Gumbel Softmax distribution\n",
    "latent_spec = {'cont': 15,\n",
    "               'disc': [15]}\n",
    "latent_dim = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import VAE\n",
    "\n",
    "model = VAE(latent_spec=latent_spec, img_size=(3, 32, 32), use_cuda=True).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "# Build optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Classifiers\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Add here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from training import Trainer\n",
    "\n",
    "# Define the capacities\n",
    "# Continuous channels\n",
    "cont_capacity = [0.0, 6.0, 25000, 30.0]  # Starting at a capacity of 0.0, increase this to 5.0\n",
    "                                         # over 25000 iterations with a gamma of 30.0\n",
    "# Discrete channels\n",
    "disc_capacity = [0.0, 6.0, 25000, 30.0]  # Starting at a capacity of 0.0, increase this to 5.0\n",
    "                                         # over 25000 iterations with a gamma of 30.0\n",
    "\n",
    "# Build a trainer\n",
    "trainer = Trainer(model, optimizer,\n",
    "                  cont_capacity=cont_capacity,\n",
    "                  disc_capacity=disc_capacity, use_cuda=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Build a visualizer which will be passed to trainer to visualize progress during training\n",
    "# from visualize import Visualizer\n",
    "\n",
    "# viz = Visualizer(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dc39ab534e24135b62f51b4c3250d15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=300.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Average loss: 685.21\n",
      "Epoch: 2 Average loss: 667.67\n",
      "Epoch: 3 Average loss: 661.96\n",
      "Epoch: 4 Average loss: 659.30\n",
      "Epoch: 5 Average loss: 657.73\n",
      "Epoch: 6 Average loss: 655.37\n",
      "Epoch: 7 Average loss: 653.67\n",
      "Epoch: 8 Average loss: 652.94\n",
      "Epoch: 9 Average loss: 652.30\n",
      "Epoch: 10 Average loss: 653.42\n",
      "Epoch: 11 Average loss: 654.29\n",
      "Epoch: 12 Average loss: 653.36\n",
      "Epoch: 13 Average loss: 652.76\n",
      "Epoch: 14 Average loss: 652.28\n",
      "Epoch: 15 Average loss: 651.80\n",
      "Epoch: 16 Average loss: 651.64\n",
      "Epoch: 17 Average loss: 651.23\n",
      "Epoch: 18 Average loss: 650.15\n",
      "Epoch: 19 Average loss: 649.39\n",
      "Epoch: 20 Average loss: 648.88\n",
      "Epoch: 21 Average loss: 648.35\n",
      "Epoch: 22 Average loss: 648.53\n",
      "Epoch: 23 Average loss: 647.29\n",
      "Epoch: 24 Average loss: 647.53\n",
      "Epoch: 25 Average loss: 647.48\n",
      "Epoch: 26 Average loss: 646.78\n",
      "Epoch: 27 Average loss: 646.78\n",
      "Epoch: 28 Average loss: 646.77\n",
      "Epoch: 29 Average loss: 646.76\n",
      "Epoch: 30 Average loss: 647.51\n",
      "Epoch: 31 Average loss: 646.81\n",
      "Epoch: 32 Average loss: 647.00\n",
      "Epoch: 33 Average loss: 646.23\n",
      "Epoch: 34 Average loss: 646.43\n",
      "Epoch: 35 Average loss: 645.84\n",
      "Epoch: 36 Average loss: 645.96\n",
      "Epoch: 37 Average loss: 645.90\n",
      "Epoch: 38 Average loss: 645.99\n",
      "Epoch: 39 Average loss: 645.73\n",
      "Epoch: 40 Average loss: 645.57\n",
      "Epoch: 41 Average loss: 645.96\n",
      "Epoch: 42 Average loss: 645.86\n",
      "Epoch: 43 Average loss: 645.75\n",
      "Epoch: 44 Average loss: 645.31\n",
      "Epoch: 45 Average loss: 645.56\n",
      "Epoch: 46 Average loss: 645.33\n",
      "Epoch: 47 Average loss: 645.43\n",
      "Epoch: 48 Average loss: 645.22\n",
      "Epoch: 49 Average loss: 645.43\n",
      "Epoch: 50 Average loss: 645.18\n",
      "Epoch: 51 Average loss: 645.20\n",
      "Epoch: 52 Average loss: 645.10\n",
      "Epoch: 53 Average loss: 645.02\n",
      "Epoch: 54 Average loss: 644.76\n",
      "Epoch: 55 Average loss: 645.09\n",
      "Epoch: 56 Average loss: 644.78\n",
      "Epoch: 57 Average loss: 644.73\n",
      "Epoch: 58 Average loss: 645.04\n",
      "Epoch: 59 Average loss: 644.50\n",
      "Epoch: 60 Average loss: 644.76\n",
      "Epoch: 61 Average loss: 645.24\n",
      "Epoch: 62 Average loss: 644.82\n",
      "Epoch: 63 Average loss: 644.88\n",
      "Epoch: 64 Average loss: 644.71\n",
      "Epoch: 65 Average loss: 644.38\n",
      "Epoch: 66 Average loss: 644.44\n",
      "Epoch: 67 Average loss: 644.74\n",
      "Epoch: 68 Average loss: 644.50\n",
      "Epoch: 69 Average loss: 644.57\n",
      "Epoch: 70 Average loss: 644.46\n",
      "Epoch: 71 Average loss: 644.63\n",
      "Epoch: 72 Average loss: 644.29\n",
      "Epoch: 73 Average loss: 644.49\n",
      "Epoch: 74 Average loss: 644.08\n",
      "Epoch: 75 Average loss: 644.20\n",
      "Epoch: 76 Average loss: 644.67\n",
      "Epoch: 77 Average loss: 644.15\n",
      "Epoch: 78 Average loss: 643.90\n",
      "Epoch: 79 Average loss: 644.53\n",
      "Epoch: 80 Average loss: 644.10\n",
      "Epoch: 81 Average loss: 644.23\n",
      "Epoch: 82 Average loss: 644.34\n",
      "Epoch: 83 Average loss: 644.54\n",
      "Epoch: 84 Average loss: 644.25\n",
      "Epoch: 85 Average loss: 644.52\n",
      "Epoch: 86 Average loss: 644.40\n",
      "Epoch: 87 Average loss: 644.23\n",
      "Epoch: 88 Average loss: 643.91\n",
      "Epoch: 89 Average loss: 643.95\n",
      "Epoch: 90 Average loss: 644.16\n",
      "Epoch: 91 Average loss: 644.16\n",
      "Epoch: 92 Average loss: 644.13\n",
      "Epoch: 93 Average loss: 643.89\n",
      "Epoch: 94 Average loss: 643.88\n",
      "Epoch: 95 Average loss: 643.88\n",
      "Epoch: 96 Average loss: 643.95\n",
      "Epoch: 97 Average loss: 643.88\n",
      "Epoch: 98 Average loss: 644.15\n",
      "Epoch: 99 Average loss: 644.12\n",
      "Epoch: 100 Average loss: 644.02\n",
      "Epoch: 101 Average loss: 643.77\n",
      "Epoch: 102 Average loss: 643.99\n",
      "Epoch: 103 Average loss: 643.94\n",
      "Epoch: 104 Average loss: 643.97\n",
      "Epoch: 105 Average loss: 643.60\n",
      "Epoch: 106 Average loss: 643.84\n",
      "Epoch: 107 Average loss: 643.75\n",
      "Epoch: 108 Average loss: 643.57\n",
      "Epoch: 109 Average loss: 643.65\n",
      "Epoch: 110 Average loss: 643.89\n",
      "Epoch: 111 Average loss: 644.71\n",
      "Epoch: 112 Average loss: 643.87\n",
      "Epoch: 113 Average loss: 643.80\n",
      "Epoch: 114 Average loss: 643.68\n",
      "Epoch: 115 Average loss: 643.66\n",
      "Epoch: 116 Average loss: 643.49\n",
      "Epoch: 117 Average loss: 643.60\n",
      "Epoch: 118 Average loss: 643.61\n",
      "Epoch: 119 Average loss: 643.45\n",
      "Epoch: 120 Average loss: 643.42\n",
      "Epoch: 121 Average loss: 643.64\n",
      "Epoch: 122 Average loss: 643.50\n",
      "Epoch: 123 Average loss: 643.60\n",
      "Epoch: 124 Average loss: 643.47\n",
      "Epoch: 125 Average loss: 643.27\n",
      "Epoch: 126 Average loss: 643.56\n",
      "Epoch: 127 Average loss: 643.34\n",
      "Epoch: 128 Average loss: 643.43\n",
      "Epoch: 129 Average loss: 643.52\n",
      "Epoch: 130 Average loss: 643.48\n",
      "Epoch: 131 Average loss: 643.22\n",
      "Epoch: 132 Average loss: 643.35\n",
      "Epoch: 133 Average loss: 643.43\n",
      "Epoch: 134 Average loss: 643.34\n",
      "Epoch: 135 Average loss: 643.31\n",
      "Epoch: 136 Average loss: 643.07\n",
      "Epoch: 137 Average loss: 643.51\n",
      "Epoch: 138 Average loss: 643.27\n",
      "Epoch: 139 Average loss: 643.27\n",
      "Epoch: 140 Average loss: 643.15\n",
      "Epoch: 141 Average loss: 643.80\n",
      "Epoch: 142 Average loss: 643.08\n",
      "Epoch: 143 Average loss: 643.50\n",
      "Epoch: 144 Average loss: 643.40\n",
      "Epoch: 145 Average loss: 643.39\n",
      "Epoch: 146 Average loss: 643.07\n",
      "Epoch: 147 Average loss: 643.10\n",
      "Epoch: 148 Average loss: 643.04\n",
      "Epoch: 149 Average loss: 643.15\n",
      "Epoch: 150 Average loss: 643.31\n",
      "Epoch: 151 Average loss: 643.33\n",
      "Epoch: 152 Average loss: 643.35\n",
      "Epoch: 153 Average loss: 643.33\n",
      "Epoch: 154 Average loss: 643.13\n",
      "Epoch: 155 Average loss: 643.42\n",
      "Epoch: 156 Average loss: 643.19\n",
      "Epoch: 157 Average loss: 642.90\n",
      "Epoch: 158 Average loss: 643.64\n",
      "Epoch: 159 Average loss: 643.26\n",
      "Epoch: 160 Average loss: 643.11\n",
      "Epoch: 161 Average loss: 643.53\n",
      "Epoch: 162 Average loss: 642.99\n",
      "Epoch: 163 Average loss: 643.02\n",
      "Epoch: 164 Average loss: 643.42\n",
      "Epoch: 165 Average loss: 643.03\n",
      "Epoch: 166 Average loss: 642.72\n",
      "Epoch: 167 Average loss: 643.14\n",
      "Epoch: 168 Average loss: 643.50\n",
      "Epoch: 169 Average loss: 643.01\n",
      "Epoch: 170 Average loss: 642.88\n",
      "Epoch: 171 Average loss: 643.09\n",
      "Epoch: 172 Average loss: 642.86\n",
      "Epoch: 173 Average loss: 643.73\n",
      "Epoch: 174 Average loss: 643.30\n",
      "Epoch: 175 Average loss: 642.81\n",
      "Epoch: 176 Average loss: 643.12\n",
      "Epoch: 177 Average loss: 643.06\n",
      "Epoch: 178 Average loss: 643.14\n",
      "Epoch: 179 Average loss: 643.01\n",
      "Epoch: 180 Average loss: 642.73\n",
      "Epoch: 181 Average loss: 642.76\n",
      "Epoch: 182 Average loss: 642.85\n",
      "Epoch: 183 Average loss: 643.06\n",
      "Epoch: 184 Average loss: 642.71\n",
      "Epoch: 185 Average loss: 642.72\n",
      "Epoch: 186 Average loss: 642.94\n",
      "Epoch: 187 Average loss: 643.03\n",
      "Epoch: 188 Average loss: 643.05\n",
      "Epoch: 189 Average loss: 643.19\n",
      "Epoch: 190 Average loss: 642.98\n",
      "Epoch: 191 Average loss: 643.00\n",
      "Epoch: 192 Average loss: 643.18\n",
      "Epoch: 193 Average loss: 642.80\n",
      "Epoch: 194 Average loss: 642.96\n",
      "Epoch: 195 Average loss: 643.00\n",
      "Epoch: 196 Average loss: 642.90\n",
      "Epoch: 197 Average loss: 642.95\n",
      "Epoch: 198 Average loss: 642.85\n",
      "Epoch: 199 Average loss: 642.97\n",
      "Epoch: 200 Average loss: 642.66\n",
      "Epoch: 201 Average loss: 642.80\n",
      "Epoch: 202 Average loss: 642.92\n",
      "Epoch: 203 Average loss: 642.76\n",
      "Epoch: 204 Average loss: 642.58\n",
      "Epoch: 205 Average loss: 642.86\n",
      "Epoch: 206 Average loss: 642.92\n",
      "Epoch: 207 Average loss: 642.65\n",
      "Epoch: 208 Average loss: 642.81\n",
      "Epoch: 209 Average loss: 642.89\n",
      "Epoch: 210 Average loss: 643.00\n",
      "Epoch: 211 Average loss: 643.01\n",
      "Epoch: 212 Average loss: 642.85\n",
      "Epoch: 213 Average loss: 642.94\n",
      "Epoch: 214 Average loss: 643.02\n",
      "Epoch: 215 Average loss: 642.59\n",
      "Epoch: 216 Average loss: 643.17\n",
      "Epoch: 217 Average loss: 643.08\n",
      "Epoch: 218 Average loss: 643.23\n",
      "Epoch: 219 Average loss: 643.09\n",
      "Epoch: 220 Average loss: 642.83\n",
      "Epoch: 221 Average loss: 642.77\n",
      "Epoch: 222 Average loss: 642.87\n",
      "Epoch: 223 Average loss: 642.79\n",
      "Epoch: 224 Average loss: 642.93\n",
      "Epoch: 225 Average loss: 642.68\n",
      "Epoch: 226 Average loss: 642.71\n",
      "Epoch: 227 Average loss: 642.61\n",
      "Epoch: 228 Average loss: 642.68\n",
      "Epoch: 229 Average loss: 642.93\n",
      "Epoch: 230 Average loss: 642.95\n",
      "Epoch: 231 Average loss: 642.94\n",
      "Epoch: 232 Average loss: 642.81\n",
      "Epoch: 233 Average loss: 642.77\n",
      "Epoch: 234 Average loss: 642.83\n",
      "Epoch: 235 Average loss: 642.74\n",
      "Epoch: 236 Average loss: 642.94\n",
      "Epoch: 237 Average loss: 642.70\n",
      "Epoch: 238 Average loss: 642.55\n",
      "Epoch: 239 Average loss: 642.74\n",
      "Epoch: 240 Average loss: 642.56\n",
      "Epoch: 241 Average loss: 642.75\n",
      "Epoch: 242 Average loss: 642.55\n",
      "Epoch: 243 Average loss: 642.73\n",
      "Epoch: 244 Average loss: 642.87\n",
      "Epoch: 245 Average loss: 643.27\n",
      "Epoch: 246 Average loss: 642.93\n",
      "Epoch: 247 Average loss: 642.84\n",
      "Epoch: 248 Average loss: 642.89\n",
      "Epoch: 249 Average loss: 642.68\n",
      "Epoch: 250 Average loss: 642.91\n",
      "Epoch: 251 Average loss: 642.51\n",
      "Epoch: 252 Average loss: 642.65\n",
      "Epoch: 253 Average loss: 642.57\n",
      "Epoch: 254 Average loss: 643.08\n",
      "Epoch: 255 Average loss: 642.53\n",
      "Epoch: 256 Average loss: 642.73\n",
      "Epoch: 257 Average loss: 642.72\n",
      "Epoch: 258 Average loss: 642.72\n",
      "Epoch: 259 Average loss: 642.48\n",
      "Epoch: 260 Average loss: 642.54\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 261 Average loss: 642.46\n",
      "Epoch: 262 Average loss: 642.96\n",
      "Epoch: 263 Average loss: 643.36\n",
      "Epoch: 264 Average loss: 642.84\n",
      "Epoch: 265 Average loss: 642.66\n",
      "Epoch: 266 Average loss: 642.45\n",
      "Epoch: 267 Average loss: 642.63\n",
      "Epoch: 268 Average loss: 642.80\n",
      "Epoch: 269 Average loss: 642.62\n",
      "Epoch: 270 Average loss: 642.63\n",
      "Epoch: 271 Average loss: 642.88\n",
      "Epoch: 272 Average loss: 643.01\n",
      "Epoch: 273 Average loss: 642.94\n",
      "Epoch: 274 Average loss: 642.60\n",
      "Epoch: 275 Average loss: 642.69\n",
      "Epoch: 276 Average loss: 642.55\n",
      "Epoch: 277 Average loss: 642.80\n",
      "Epoch: 278 Average loss: 642.57\n",
      "Epoch: 279 Average loss: 642.66\n",
      "Epoch: 280 Average loss: 642.48\n",
      "Epoch: 281 Average loss: 642.67\n",
      "Epoch: 282 Average loss: 642.53\n",
      "Epoch: 283 Average loss: 642.58\n",
      "Epoch: 284 Average loss: 642.62\n",
      "Epoch: 285 Average loss: 643.33\n",
      "Epoch: 286 Average loss: 643.21\n",
      "Epoch: 287 Average loss: 642.84\n",
      "Epoch: 288 Average loss: 643.17\n",
      "Epoch: 289 Average loss: 642.56\n",
      "Epoch: 290 Average loss: 642.53\n",
      "Epoch: 291 Average loss: 642.96\n",
      "Epoch: 292 Average loss: 643.22\n",
      "Epoch: 293 Average loss: 642.54\n",
      "Epoch: 294 Average loss: 642.52\n",
      "Epoch: 295 Average loss: 642.58\n",
      "Epoch: 296 Average loss: 642.46\n",
      "Epoch: 297 Average loss: 642.22\n",
      "Epoch: 298 Average loss: 642.57\n",
      "Epoch: 299 Average loss: 642.41\n",
      "Epoch: 300 Average loss: 642.56\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train model for 10 epochs\n",
    "# Note this should really be a 100 epochs and trained on a GPU, but this is just to demo\n",
    "\n",
    "# trainer.train(train_loader, epochs=100, save_training_gif=('./training.gif', viz))\n",
    "if VAE_TRAIN:\n",
    "    trainer.train(train_loader, epochs=300)\n",
    "    torch.save(model.state_dict(), 'models/vae_svhn.pth')\n",
    "else:\n",
    "    model.load_state_dict(torch.load('models/vae_svhn.pth'))\n",
    "    model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "# for param in classifier.parameters():\n",
    "#     param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_index = {}\n",
    "for i in range(len(train_data)):\n",
    "    index = train_data[i][1]\n",
    "    if index not in list_index.keys():\n",
    "        list_index[index] = [i]\n",
    "    else:\n",
    "        list_index[index].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c817875a10ab46ef8f72c61b834fccce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "l_sample_list = {}\n",
    "def get_average_latent_space(list_index):\n",
    "    for i in tqdm(list_index.keys()):\n",
    "        for j in list_index[i]:\n",
    "            output, l_dist = model(train_data[j][0].unsqueeze(0).cuda())\n",
    "            l_sample_x = model.reparameterize(l_dist)\n",
    "            if i not in l_sample_list.keys():\n",
    "                l_sample_list[i] = [l_sample_x]\n",
    "            else:\n",
    "                l_sample_list[i].append(l_sample_x)\n",
    "        l_sample_list[i] = {'mean':torch.mean(torch.stack(l_sample_list[i]), dim=0),\n",
    "                           'std':torch.std(torch.stack(l_sample_list[i]), dim=0)}\n",
    "        \n",
    "get_average_latent_space(list_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def check_distribution(digit, std=[-0.8, 0.8], plot=False):\n",
    "    alpha = torch.clamp(torch.randn(l_sample_list[digit]['std'].shape).cuda(), min=std[0], max=std[1])\n",
    "    test_sample = l_sample_list[digit]['mean'] + F.normalize(alpha)*l_sample_list[digit]['std']\n",
    "    test = model.decode(test_sample)\n",
    "#     preds = torch.argmax(classifier(F.upsample(test, (28,28), mode='bilinear', align_corners=True)))\n",
    "#     print(preds.item())\n",
    "    if plot:\n",
    "        plt.imshow(test[0].permute(1, 2, 0).cpu().detach().numpy(), interpolation='none')\n",
    "    return test_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_distribution(7, std=[-0.1,0.1], plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def digits_add(digit1, digit2, alpha=1, plot=False):\n",
    "    l_1 = check_distribution(digit1)\n",
    "    l_2 = check_distribution(digit2)\n",
    "    if plot:\n",
    "        test = model.decode(l_1+alpha*l_2)\n",
    "        plt.imshow(test[0,0].cpu().detach().numpy(), cmap='gray', interpolation='none')\n",
    "        preds = classifier(F.upsample(test, (28,28), mode='bilinear', align_corners=True))\n",
    "        print(preds.dtype)\n",
    "        print(torch.argmax(preds).item())\n",
    "    return torch.norm(l_1-l_2), l_1, l_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg_dist(digit1, digit2, exp=10000):\n",
    "    cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "    distance = []\n",
    "    similarity = []\n",
    "    for i in range(exp):\n",
    "        dist, l1, l2 = digits_add(digit1,digit2)\n",
    "        similar = cos(l1,l2)\n",
    "        distance.append(dist.item())\n",
    "        similarity.append(similar.item())\n",
    "    a = round(sum(distance)/len(distance),5)\n",
    "    b = round(sum(similarity)/len(similarity),5)\n",
    "    return a,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def digit_to_study(digit):\n",
    "    distance = {}\n",
    "    similarity = {}\n",
    "    for i in tqdm(range(10)):\n",
    "        distance[i], similarity[i] = get_avg_dist(digit,i)\n",
    "    return distance, similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_avg_dist(1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_avg_dist(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_avg_dist(2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits_add(2,3,0.56,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# digits_add(1,3,0.3,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# digits_add(1,2,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# digit_to_study(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# digit_to_study(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check_distribution(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if FIND_DIST is True:\n",
    "#     l_means = []\n",
    "#     l_stds = []\n",
    "#     for i in l_sample_list.keys():\n",
    "#         l_means.append(l_sample_list[i]['mean'])\n",
    "#         l_stds.append(l_sample_list[i]['std'])\n",
    "\n",
    "#     l_mean_tensor = torch.stack(l_means).squeeze(1)\n",
    "#     # print(l_mean_tensor.shape)\n",
    "\n",
    "#     l_std_tensor = torch.stack(l_stds).squeeze(1)\n",
    "#     # print(l_std_tensor.shape)\n",
    "\n",
    "#     torch.save(l_mean_tensor, 'tensor/latent_mean.pt')\n",
    "#     torch.save(l_std_tensor, 'tensor/latent_std.pt')\n",
    "\n",
    "# else:\n",
    "#     l_mean_tensor = torch.load('tensor/latent_mean.pt')\n",
    "#     l_std_tensor = torch.load('tensor/latent_std.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = enumerate(test_loader)\n",
    "batch_idx, (example_data,target) = next(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check(i, digit1, digit2):\n",
    "    \n",
    "    alpha = torch.clamp(torch.randn(l_sample_list[digit1]['std'].shape).cuda(), min=-1, max=1)\n",
    "    test_sample = l_sample_list[digit1]['mean'] + F.normalize(alpha)*l_sample_list[digit1]['std']\n",
    "    \n",
    "    alpha = torch.clamp(torch.randn(l_sample_list[digit2]['std'].shape).cuda(), min=-1, max=1)\n",
    "    test_sample += l_sample_list[digit2]['mean'] + F.normalize(alpha)*l_sample_list[digit2]['std']\n",
    "    \n",
    "    example_img = example_data[i,:,:,:].unsqueeze(0).cuda()\n",
    "    output, l_dist = model(example_img)\n",
    "    l_sample = model.reparameterize(l_dist)\n",
    "    test_sample = l_sample + 0.4*test_sample\n",
    "    test = model.decode(test_sample)\n",
    "    preds = torch.argmax(classifier(F.upsample(test, (28,28), mode='bilinear', align_corners=True)))\n",
    "    print(preds)\n",
    "    plt.imshow(model.decode(test_sample)[0,0].cpu().detach().numpy(), cmap='gray', interpolation='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check(2,1,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_64(data):\n",
    "#     l_sample = None\n",
    "#     for i in range(data.shape[0]):\n",
    "#         output, l_dist_x = model(data[i,:,:,:].unsqueeze(0).cuda())\n",
    "#         l_sample_x = model.reparameterize(l_dist_x)\n",
    "#         if l_sample is None:\n",
    "#             l_sample = l_sample_x\n",
    "#         else:\n",
    "#             l_sample += l_sample_x\n",
    "#     l_sample = l_sample / data.shape[0]\n",
    "#     new_output = model.decode(l_sample)\n",
    "#     plt.imshow(new_output[0][0].detach().cpu().numpy(), cmap='gray', interpolation='none')\n",
    "#     pred = classifier(F.upsample(new_output, (28,28), mode='bilinear', align_corners=True))\n",
    "#     print(pred)\n",
    "#     print(torch.argmax(pred))\n",
    "#     return l_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_batch_avg(data):\n",
    "#     l_sample = None\n",
    "#     for i in range(data.shape[0]):\n",
    "#         output, l_dist_x = model(data[i,:,:,:].unsqueeze(0).cuda())\n",
    "#         l_sample_x = model.reparameterize(l_dist_x)\n",
    "#         if l_sample is None:\n",
    "#             l_sample = l_sample_x\n",
    "#         else:\n",
    "#             l_sample += l_sample_x\n",
    "#     l_sample = l_sample / data.shape[0]\n",
    "# #     new_output = model.decode(l_sample)\n",
    "# #     plt.imshow(new_output[0][0].detach().cpu().numpy(), cmap='gray', interpolation='none')\n",
    "# #     pred = classifier(F.upsample(new_output, (28,28), mode='bilinear', align_corners=True))\n",
    "# #     print(pred)\n",
    "# #     print(torch.argmax(pred))\n",
    "#     return l_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_avg_mnist(img1, data):\n",
    "# #     new_l_sample = None\n",
    "# #     count = len(list_to_process)\n",
    "#     output, l_dist_x = model(img1.cuda())\n",
    "#     l_sample_x = model.reparameterize(l_dist_x)\n",
    "#     l_sample_y = get_batch_avg(data)\n",
    "# #     output, l_dist_y = model(img2.cuda())\n",
    "# #     l_sample_y = model.reparameterize(l_dist_y)\n",
    "    \n",
    "#     l_sample = 1*l_sample_x + 0.4*l_sample_y\n",
    "    \n",
    "#     new_output = model.decode(l_sample)\n",
    "# #     for i in list_to_process:\n",
    "# #         example_img = example_data[i,:,:,:].unsqueeze(0).cuda()\n",
    "# #         output, l_dist = model(example_img)\n",
    "# #         l_sample = model.reparameterize(l_dist)\n",
    "# #         if new_l_sample is None:\n",
    "# #             new_l_sample = l_sample\n",
    "# #         else:\n",
    "# #             new_l_sample += l_sample\n",
    "# #     new_l_sample = new_l_sample / count\n",
    "# #     new_output = model.decode(new_l_sample)\n",
    "#     plt.imshow(new_output[0][0].detach().cpu().numpy(), cmap='gray', interpolation='none')\n",
    "#     pred = classifier(F.upsample(new_output, (28,28), mode='bilinear', align_corners=True))\n",
    "#     print(pred)\n",
    "#     print(torch.argmax(pred))\n",
    "#     print(pred[0,2].item(), pred[0,5].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_mnist(list_to_process):\n",
    "#     new_l_sample = None\n",
    "#     count = len(list_to_process)\n",
    "#     for i in list_to_process:\n",
    "#         example_img = example_data[i,:,:,:].unsqueeze(0).cuda()\n",
    "#         output, l_dist = model(example_img)\n",
    "#         l_sample = model.reparameterize(l_dist)\n",
    "#         if new_l_sample is None:\n",
    "#             new_l_sample = l_sample\n",
    "#         else:\n",
    "#             new_l_sample += l_sample\n",
    "#     new_l_sample = new_l_sample / count\n",
    "#     new_output = model.decode(new_l_sample)\n",
    "#     plt.imshow(new_output[0][0].detach().cpu().numpy(), cmap='gray', interpolation='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def check(i, j, alpha, beta):\n",
    "#     im1 = example_data[i,:,:,:].unsqueeze(0).cuda()\n",
    "#     im2 = example_data[j,:,:,:].unsqueeze(0).cuda()\n",
    "#     out1, l_dist1 = model(im1)\n",
    "#     out2, l_dist2 = model(im2)\n",
    "#     l_sample1 = model.reparameterize(l_dist1)\n",
    "#     l_sample2 = model.reparameterize(l_dist2)\n",
    "#     l_sample = alpha*l_sample1 + beta*l_sample2\n",
    "#     new_out = model.decode(l_sample)\n",
    "# #     new_out1 = model.decode(l_sample1)\n",
    "# #     new_out2 = model.decode(l_sample2)\n",
    "#     plt.figure(figsize=(10,15))\n",
    "#     plt.subplot(1,3,1)\n",
    "#     plt.imshow(example_data[i][0].detach().cpu().numpy(), cmap='gray', interpolation='none')\n",
    "#     plt.subplot(1,3,2)\n",
    "#     plt.imshow(example_data[j][0].detach().cpu().numpy(), cmap='gray', interpolation='none')\n",
    "#     plt.subplot(1,3,3)\n",
    "#     plt.imshow(new_out[0][0].detach().cpu().numpy(), cmap='gray', interpolation='none')\n",
    "#     print(torch.argmax(classifier(F.upsample(new_out, (28,28), mode='bilinear', align_corners=True))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpha=1\n",
    "# beta = 1.2\n",
    "# check(19,11, alpha, beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Attack(nn.Module):\n",
    "#     def __init__(self, attack_digit=attack_digit, target_digit=target_digit, vae=model, classifier=classifier, avg_latent=l_sample_list):\n",
    "#         super(self, Attack).__init__()\n",
    "#         self.classifier = classifier\n",
    "#         self.classifier.eval()\n",
    "#         self.vae = vae\n",
    "#         self.vae.eval()\n",
    "#         self.avg_latent = avg_latent\n",
    "#         self.attack_digit = attack_digit\n",
    "#         self.target_digit = target_digit\n",
    "#         self.hidden_layers = hidden_layers\n",
    "#         self.hidden_layers.insert(0, latent_dim)\n",
    "#         self.hidden_layers.append(latent_dim)\n",
    "#         self.layers = []\n",
    "        \n",
    "#         for i in range(len(self.hidden_layers)-1):\n",
    "#             self.layers.append(nn.Linear(self.hidden_layers[i], self.hidden_layers[i+1]))\n",
    "        \n",
    "#         self.layers = nn.ModuleList(self.layers)\n",
    "        \n",
    "#     def forward(self, x, y):\n",
    "#         _, l_dist_x = self.vae(x)\n",
    "#         _, l_dist_y = self.vae(y)\n",
    "#         l_sample_x = self.vae.reparameterize(l_dist_x)\n",
    "#         l_sample_y = self.vae.reparameterize(l_dist_y)\n",
    "#         noised_sample = l_sample\n",
    "#         for layer in self.layers:\n",
    "#             noised_sample = layer(noised_sample)\n",
    "#         noised_images = self.vae.decoder(noised_sample)\n",
    "#         preds = self.classifier(F.upsample(noised_image, (28,28), mode='bilinear', align_corners=True))\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import exp\n",
    "\n",
    "def gaussian(window_size, sigma):\n",
    "    gauss = torch.Tensor([exp(-(x - window_size//2)**2/float(2*sigma**2)) for x in range(window_size)])\n",
    "    return gauss/gauss.sum()\n",
    "\n",
    "def create_window(window_size, channel):\n",
    "    _1D_window = gaussian(window_size, 1.5).unsqueeze(1)\n",
    "    _2D_window = _1D_window.mm(_1D_window.t()).float().unsqueeze(0).unsqueeze(0)\n",
    "    window = torch.Tensor(_2D_window.expand(channel, 1, window_size, window_size).contiguous())\n",
    "    return window\n",
    "\n",
    "def _ssim(img1, img2, window, window_size, channel, size_average = True):\n",
    "    mu1 = F.conv2d(img1, window, padding = window_size//2, groups = channel)\n",
    "    mu2 = F.conv2d(img2, window, padding = window_size//2, groups = channel)\n",
    "\n",
    "    mu1_sq = mu1.pow(2)\n",
    "    mu2_sq = mu2.pow(2)\n",
    "    mu1_mu2 = mu1*mu2\n",
    "\n",
    "    sigma1_sq = F.conv2d(img1*img1, window, padding = window_size//2, groups = channel) - mu1_sq\n",
    "    sigma2_sq = F.conv2d(img2*img2, window, padding = window_size//2, groups = channel) - mu2_sq\n",
    "    sigma12 = F.conv2d(img1*img2, window, padding = window_size//2, groups = channel) - mu1_mu2\n",
    "\n",
    "    C1 = 0.01**2\n",
    "    C2 = 0.03**2\n",
    "\n",
    "    ssim_map = ((2*mu1_mu2 + C1)*(2*sigma12 + C2))/((mu1_sq + mu2_sq + C1)*(sigma1_sq + sigma2_sq + C2))\n",
    "\n",
    "    if size_average:\n",
    "        return ssim_map.mean()\n",
    "    else:\n",
    "        return ssim_map.mean(1).mean(1).mean(1)\n",
    "\n",
    "class SSIM(nn.Module):\n",
    "    def __init__(self, window_size = 11, size_average = True):\n",
    "        super(SSIM, self).__init__()\n",
    "        self.window_size = window_size\n",
    "        self.size_average = size_average\n",
    "        self.channel = 1\n",
    "        self.window = create_window(window_size, self.channel)\n",
    "\n",
    "    def forward(self, img1, img2):\n",
    "        (_, channel, _, _) = img1.size()\n",
    "\n",
    "        if channel == self.channel and self.window.data.type() == img1.data.type():\n",
    "            window = self.window\n",
    "        else:\n",
    "            window = create_window(self.window_size, channel)\n",
    "            \n",
    "            if img1.is_cuda:\n",
    "                window = window.cuda(img1.get_device())\n",
    "            window = window.type_as(img1)\n",
    "            \n",
    "            self.window = window\n",
    "            self.channel = channel\n",
    "\n",
    "\n",
    "        return _ssim(img1, img2, window, self.window_size, channel, self.size_average)\n",
    "\n",
    "def ssim(img1, img2, window_size = 11, size_average = True):\n",
    "    (_, channel, _, _) = img1.size()\n",
    "    window = create_window(window_size, channel)\n",
    "    \n",
    "    if img1.is_cuda:\n",
    "        window = window.cuda(img1.get_device())\n",
    "    window = window.type_as(img1)\n",
    "    \n",
    "    return _ssim(img1, img2, window, window_size, channel, size_average)\n",
    "\n",
    "ssim_loss = SSIM(window_size = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = True\n",
    "device = torch.device('cuda' if use_cuda else 'cpu')\n",
    "\n",
    "# Constrained Translator\n",
    "class Noise(nn.Module):\n",
    "    def __init__(self, hidden_layers=[50, 100, latent_dim], latent_dim=latent_dim):\n",
    "        super(Noise, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.hidden_layers.insert(0, latent_dim)\n",
    "        self.layers = []\n",
    "        \n",
    "        for i in range(len(self.hidden_layers)-1):\n",
    "            self.layers.append(nn.Linear(self.hidden_layers[i], self.hidden_layers[i+1]))\n",
    "        \n",
    "        self.layers = nn.ModuleList(self.layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constrained Cofficients\n",
    "class Cofficients(nn.Module):\n",
    "    def __init__(self, hidden_layers=[40, 20, 10, 1], latent_dim=latent_dim):\n",
    "        super(Cofficients, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.hidden_layers.insert(0, latent_dim)\n",
    "        self.layers = []\n",
    "        \n",
    "        for i in range(len(self.hidden_layers)-1):\n",
    "            self.layers.append(nn.Linear(self.hidden_layers[i], self.hidden_layers[i+1]))\n",
    "        \n",
    "        self.layers = nn.ModuleList(self.layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# use_cuda = True\n",
    "# device = torch.device('cuda' if use_cuda else 'cpu')\n",
    "\n",
    "\n",
    "# def create_logits(preds, device=device):\n",
    "#     preds = preds.cpu()\n",
    "#     logits = preds.cpu()\n",
    "    \n",
    "#     sorted_ = torch.argsort(preds, dim=1, descending=True)\n",
    "#     first = sorted_[:,0]\n",
    "#     second = sorted_[:,1]\n",
    "#     print(first)\n",
    "#     print(second)\n",
    "    \n",
    "#     p_first = preds.gather(1, first.view(-1,1))\n",
    "#     p_second = preds.gather(1, second.view(-1,1))\n",
    "#     means = torch.mean(torch.stack([p_first, p_second]), dim=0).squeeze(1)\n",
    "#     print(means)\n",
    "#     diff = 0.1*(first - second)\n",
    "#     print(diff)\n",
    "#     print((means-diff).shape)\n",
    "#     j = torch.arange(logits.size(0)).long()\n",
    "#     logits[j, first] = torch.FloatTensor(means - diff)\n",
    "#     logits[j, second] = torch.FloatTensor(means + diff)\n",
    "# #     print(logits[0])\n",
    "#     return logits.to(device), first, second\n",
    "\n",
    "# a = torch.randn((10,4)).cuda()\n",
    "# b = create_logits(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "use_cuda = True\n",
    "device = torch.device('cuda' if use_cuda else 'cpu')\n",
    "\n",
    "\n",
    "def create_logits(preds, device=device):\n",
    "    preds = preds.cpu()\n",
    "    logits = preds\n",
    "    \n",
    "    sorted_ = torch.argsort(preds, dim=1, descending=True)\n",
    "    first = sorted_[:,0]\n",
    "    second = sorted_[:,1]\n",
    "    \n",
    "    p_first = preds.gather(1, first.view(-1,1))\n",
    "    p_second = preds.gather(1, second.view(-1,1))\n",
    "#     print(p_first.shape)\n",
    "    \n",
    "    means = torch.mean(torch.stack([p_first, p_second]), dim=0).squeeze(1)\n",
    "#     print(means.shape)\n",
    "    diff = 0.5*(p_first - p_second).squeeze(1)\n",
    "#     print(diff.shape)\n",
    "    j = torch.arange(logits.size(0)).long()\n",
    "    \n",
    "    logits[j, first] = torch.FloatTensor(means - diff)\n",
    "    logits[j, second] = torch.FloatTensor(means + diff)\n",
    "    \n",
    "    return logits.to(device), first, second\n",
    "\n",
    "def structural(org_image, noised_image):\n",
    "    batch_size, channels, width, height = org_image.shape\n",
    "    loss1 = 0\n",
    "    for b_ in range(batch_size):\n",
    "        ch_loss = 0\n",
    "        for ch_ in range(channels):\n",
    "            ch_loss += 1-ssim(org_image[b_][ch_].detach().cpu().numpy(), noised_image[b_][ch_].detach().cpu().numpy())\n",
    "        loss1 += ch_loss/channels\n",
    "    return loss1\n",
    "            \n",
    "class T_Loss(nn.Module):\n",
    "    def __init__(self, decoder=model.decode, classifier=classifier,\n",
    "                 latent_dim=latent_dim, l_samples=l_sample_list,\n",
    "                 classes=len(train_data.classes)):\n",
    "        super(T_Loss, self).__init__()\n",
    "        self.decoder = decoder\n",
    "        self.classifier = classifier\n",
    "#         self.means = means\n",
    "#         self.stds = stds\n",
    "        self.l_samples = l_samples\n",
    "        self.classes = classes\n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "        \n",
    "    def forward(self, coffs, noises, org_x, targets, alpha=0.6, beta=1):\n",
    "        \n",
    "        org_image = self.decoder(org_x)\n",
    "        \n",
    "        preds = self.classifier(F.upsample(org_image, (28,28), mode='bilinear', align_corners=True))\n",
    "        \n",
    "        alt_target, first, second = create_logits(preds)\n",
    "        \n",
    "        means = []\n",
    "        stds = []\n",
    "        \n",
    "        for key in second:\n",
    "            means.append(self.l_samples[key.item()]['mean'])\n",
    "            stds.append(self.l_samples[key.item()]['std'])\n",
    "        \n",
    "        means = torch.stack(means)\n",
    "        stds = torch.stack(stds)\n",
    "        noised_latent = means.squeeze(1) + torch.clamp(noises, min=-5, max=5) * stds.squeeze(1)\n",
    "        \n",
    "        noised_latent = torch.clamp(coffs, min=-3, max=3) * noised_latent\n",
    "#         noise_latent = F.normalize(coffs) * noise_latent\n",
    "        \n",
    "        noised_sample = beta * org_x + alpha * noised_latent\n",
    "        \n",
    "        noised_image = self.decoder(noised_sample)\n",
    "        \n",
    "        preds = self.classifier(F.upsample(noised_image, (28,28), mode='bilinear', align_corners=True))\n",
    "        \n",
    "        loss1 = ssim_loss(org_image, noised_image)\n",
    "        \n",
    "        loss2 = nn.BCELoss(reduction='sum')(preds, alt_target.float())\n",
    "        \n",
    "        loss3 = torch.norm(org_image-noised_image, p=2)  \n",
    "\n",
    "        loss = 400*(1-loss1) + 0.6*loss2 + 20*loss3\n",
    "#         loss = 0.8*loss2 + 20*loss3\n",
    "#         loss = loss2 + 20*loss3\n",
    "#         loss.requires_grad = True\n",
    "        \n",
    "        out_labels = preds.argmax(dim=1, keepdim=True)\n",
    "#         print(out_labels)\n",
    "#         print(torch.empty(out_labels.shape).fill_(target_label))\n",
    "#         print(preds)\n",
    "#         correct = out_labels.eq(torch.Tensor([target_label]*out_labels.shape[0]).to(device)).sum()\n",
    "#         print(out_labels.shape)\n",
    "#         print((out_labels.squeeze(1)==targets.cuda()).sum())\n",
    "        correct = (out_labels.squeeze(1)==targets.cuda()).sum()\n",
    "#         print(out_labels.shape)\n",
    "#         print(correct)\n",
    "#         print(torch.Tensor([target_label]*out_labels.shape[0]))\n",
    "#         print(out_labels)\n",
    "        return loss, correct.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alt_target = 5\n",
    "noise = Noise().to(device)\n",
    "cofficient = Cofficients().to(device)\n",
    "\n",
    "for param in noise.parameters():\n",
    "    param.requires_grad=True\n",
    "    \n",
    "for param in cofficient.parameters():\n",
    "    param.requires_grad=True\n",
    "\n",
    "tloss = T_Loss().to(device)\n",
    "tloss.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count_digit = 0\n",
    "# for i in range(len(train_data)):\n",
    "#     if train_data[i][1]==5:\n",
    "#         count_digit += 1\n",
    "# print(count_digit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "attack_log_interval = 1\n",
    "\n",
    "noise.train()\n",
    "cofficient.train()\n",
    "\n",
    "optimizer1 = optim.Adam(noise.parameters(), lr=1e-4)\n",
    "# optimizer1 = torch.optim.SGD(noise.parameters(), lr=1e-4, momentum=0.9)\n",
    "\n",
    "# optimizer2 = torch.optim.SGD(cofficient.parameters(), lr=1e-4, momentum=0.9)\n",
    "optimizer2 = optim.Adam(cofficient.parameters(), lr=1e-4)\n",
    "\n",
    "\n",
    "# scheduler1 = torch.optim.lr_scheduler.CyclicLR(optimizer1, base_lr=1e-7, max_lr=0.1)\n",
    "# scheduler2 = torch.optim.lr_scheduler.CyclicLR(optimizer2, base_lr=1e-7, max_lr=0.1)\n",
    "\n",
    "for epoch in tqdm(range(150)):\n",
    "    epoch_loss = 0\n",
    "    epoch_correct = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        \n",
    "        data = torch.FloatTensor(data).to(device)\n",
    "        _, l_dist = model(data)\n",
    "        l_sample = model.reparameterize(l_dist)\n",
    "        \n",
    "        n = noise(l_sample)\n",
    "        c = cofficient(l_sample)\n",
    "\n",
    "        optimizer1.zero_grad()\n",
    "        optimizer2.zero_grad()\n",
    "        \n",
    "        loss, correct = tloss(c, n, l_sample, target, alpha=1, beta=0)\n",
    "\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer1.step()\n",
    "        optimizer2.step()\n",
    "\n",
    "#         scheduler1.step()\n",
    "#         scheduler2.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "        epoch_correct += correct\n",
    "        \n",
    "    if (epoch+1) % attack_log_interval == 0:\n",
    "        print('Train Epoch: {}\\tLoss: {:.6f}\\tCorrect: {}'.format(\n",
    "            epoch+1, epoch_loss/batch_idx, epoch_correct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(noise, 'models/{}/noise.pt'.format(FOLDER))\n",
    "torch.save(cofficient, 'models/{}/coff.pt'.format(FOLDER))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise.eval()\n",
    "cofficient.eval()\n",
    "total_correct = 0\n",
    "total_test = 0\n",
    "for batch_idx, (data, target) in enumerate(test_loader):\n",
    "    total_test += data.shape[0]\n",
    "    data = torch.FloatTensor(data).to(device)\n",
    "\n",
    "    _, l_dist = model(data)\n",
    "    l_sample = model.reparameterize(l_dist)\n",
    "    \n",
    "    noise_ = noise(l_sample)\n",
    "    coff_ = cofficient(l_sample)\n",
    "    \n",
    "    loss, correct = tloss(coff_, noise_, l_sample, target, 1, 0)\n",
    "    total_correct += correct\n",
    "#     print(correct)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         print(correct)\n",
    "#         epoch_loss += loss.item()\n",
    "    \n",
    "\n",
    "#     if (epoch+1) % attack_log_interval == 0:\n",
    "#         print('Train Epoch: \\tCorrect: {}'.format(\n",
    "#             epoch, epoch_correct))\n",
    "print(total_correct)\n",
    "print(\"Accuracy: \", 100*(total_correct/total_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check(i, alpha=0.6, beta=1):\n",
    "    _, l_dist = model(example_data[i].unsqueeze_(0).to(device))\n",
    "    l_sample = model.reparameterize(l_dist)\n",
    "\n",
    "    org_preds = classifier(F.upsample(model.decode(l_sample), (28,28), mode='bilinear', align_corners=True))\n",
    "#     print(\"original: \", torch.argmax(org_preds, dim=1))\n",
    "\n",
    "    noises = noise(l_sample)\n",
    "    coffs = cofficient(l_sample)\n",
    "\n",
    "    d = torch.argsort(org_preds, dim=1, descending=True)\n",
    "\n",
    "    noised_latent = l_sample_list[d[0,1].item()]['mean'].squeeze(1) + torch.clamp(noises, min=-5, max=5) * l_sample_list[d[0,1].item()]['std'].squeeze(1)\n",
    "    \n",
    "    noised_latent = torch.clamp(coffs, min=-3, max=3) * noised_latent\n",
    "#     noised_latent = F.normalize(coffs) * noised_latent\n",
    "\n",
    "    noised_sample = beta * l_sample + alpha * noised_latent\n",
    "\n",
    "    noised_image = model.decode(noised_sample)\n",
    "\n",
    "    fake_preds = classifier(F.upsample(noised_image, (28,28), mode='bilinear', align_corners=True))\n",
    "#     print(\"noised: \", torch.argmax(fake_preds, dim=1))\n",
    "\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(example_data[i][0].detach().cpu().numpy(), cmap='gray', interpolation='none')\n",
    "    plt.title(\"org:{}\".format(torch.argmax(org_preds, dim=1)))\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(noised_image[0][0].detach().cpu().numpy(), cmap='gray', interpolation='none')\n",
    "    plt.title(\"fake:{}\".format(torch.argmax(fake_preds, dim=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(64):\n",
    "    check(i,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(i, means=l_mean_tensor, stds=l_std_tensor, latent_dim=latent_dim, classes=len(train_data.classes)):\n",
    "    _, l_dist = model(example_data[i].unsqueeze_(0).to(device))\n",
    "    l_sample = model.reparameterize(l_dist)\n",
    "    noises = noise(l_sample)\n",
    "    coffs = cofficient(l_sample)\n",
    "#     print(coffs.shape)\n",
    "#     print(noises.shape)\n",
    "    noised_latent = means + noises.reshape(noises.shape[0], classes, latent_dim)*stds\n",
    "    noised_latent = coffs[:,:,None]*noised_latent\n",
    "#     print(noised_latent.shape)\n",
    "#     print(l_sample.shape)\n",
    "#     print(torch.transpose(coff[:,None].cuda()*avg_latent.T, 1, 2).sum(1).shape)\n",
    "#     noised_latent = l_sample + 2e-1*torch.transpose(coff[:,None].cuda()*avg_latent.T, 1, 2).sum(1)\n",
    "#     print(noised_latent.shape)\n",
    "#     print(noised_sample)\n",
    "#     print(l_sample)\n",
    "#     noised_sample = 1 * ((l_sample - l_sample.min())/(l_sample.max() - l_sample.min())) + 1e-2 * ((noised_sample - noised_sample.min())/(noised_sample.max() - noised_sample.min()))\n",
    "#     noised_sample = 1 * l_sample + 2e-2 * noised_sample\n",
    "#     noised_sample = l_sample + 1e-7 * noised_sample\n",
    "    final = model.decode(l_sample+1e-12*noised_latent.sum(dim=1))\n",
    "#     print(final.shape)\n",
    "    pred_org = torch.argmax(classifier(F.upsample(example_data[i,:,:,:].unsqueeze(0).cuda(), (28,28), mode='bilinear', align_corners=True)))\n",
    "    pred = torch.argmax(classifier(F.upsample(final, (28,28), mode='bilinear', align_corners=True)), dim=1)\n",
    "#     print(pred)\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(example_data[i][0].detach().cpu().numpy(), cmap='gray', interpolation='none')\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(final[0][0].detach().cpu().numpy(), cmap='gray', interpolation='none')\n",
    "    plt.title(\"Prediction: {}, {}\".format(pred_org.item(), pred.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(64):\n",
    "    test(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.transpose(torch.clamp(coff[:,None].cuda(), min=-0.8, max=0.3)*self.avg_latent.T, 1, 2).sum(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
