{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a JointVAE model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get MNIST data\n",
    "Build a simple JointVAE model on MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "VAE_TRAIN = False\n",
    "FIND_DIST = False\n",
    "FOLDER = \"dist5-celeba\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloaders import get_celeba_dataloader\n",
    "\n",
    "train_loader, test_loader = get_celeba_dataloader(path_to_data='/home/data/bvaa/CelebA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchvision import datasets, transforms\n",
    "# all_transforms = transforms.Compose([\n",
    "#         transforms.Resize(32),\n",
    "#         transforms.ToTensor()\n",
    "#     ])\n",
    "# train_data = datasets.CIFAR10('/home/data/bvaa/', train=True, download=True,\n",
    "#                                 transform=all_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = enumerate(test_loader)\n",
    "batch_idx, (example_data,target) = next(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f8b454065c0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(example_data[3].permute(1,2,0).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define latent distribution of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Classifiers\n",
    "##########################\n",
    "### MODEL\n",
    "##########################\n",
    "\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classes, grayscale):\n",
    "        self.inplanes = 64\n",
    "        if grayscale:\n",
    "            in_dim = 1\n",
    "        else:\n",
    "            in_dim = 3\n",
    "        super(ResNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_dim, 64, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        self.avgpool = nn.AvgPool2d(7, stride=1, padding=2)\n",
    "        self.fc = nn.Linear(1024 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, (2. / n)**.5)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.float()\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "#         x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "#         print(\"x shape:\", x.shape)\n",
    "        logits = self.fc(x)\n",
    "        probas = F.softmax(logits, dim=1)\n",
    "        return logits, probas\n",
    "\n",
    "\n",
    "\n",
    "def resnet152(num_classes, grayscale):\n",
    "    \"\"\"Constructs a ResNet-152 model.\"\"\"\n",
    "    model = ResNet(block=Bottleneck, \n",
    "                   layers=[3, 4, 36, 3],\n",
    "                   num_classes=NUM_CLASSES,\n",
    "                   grayscale=grayscale)\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Add here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SETTINGS\n",
    "##########################\n",
    "\n",
    "# Hyperparameters\n",
    "RANDOM_SEED = 1\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_EPOCHS = 10\n",
    "\n",
    "# Architecture\n",
    "NUM_FEATURES = 64*64\n",
    "NUM_CLASSES = 2\n",
    "BATCH_SIZE = 64\n",
    "DEVICE = 'cuda:0' # default GPU device\n",
    "GRAYSCALE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "##########################\n",
    "### COST AND OPTIMIZER\n",
    "##########################\n",
    "\n",
    "model = resnet152(NUM_CLASSES, GRAYSCALE)\n",
    "model.to(DEVICE)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc7e7f5f95fe4f6394b97b0996437427",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/010 | Batch 0000/1250 | Cost: 0.7519\n",
      "Epoch: 001/010 | Batch 0050/1250 | Cost: 0.4468\n",
      "Epoch: 001/010 | Batch 0100/1250 | Cost: 0.3332\n",
      "Epoch: 001/010 | Batch 0150/1250 | Cost: 0.2923\n",
      "Epoch: 001/010 | Batch 0200/1250 | Cost: 0.3828\n",
      "Epoch: 001/010 | Batch 0250/1250 | Cost: 0.1364\n",
      "Epoch: 001/010 | Batch 0300/1250 | Cost: 0.2628\n",
      "Epoch: 001/010 | Batch 0350/1250 | Cost: 0.2358\n",
      "Epoch: 001/010 | Batch 0400/1250 | Cost: 0.1749\n",
      "Epoch: 001/010 | Batch 0450/1250 | Cost: 0.1961\n",
      "Epoch: 001/010 | Batch 0500/1250 | Cost: 0.0975\n",
      "Epoch: 001/010 | Batch 0550/1250 | Cost: 0.1633\n",
      "Epoch: 001/010 | Batch 0600/1250 | Cost: 0.1624\n",
      "Epoch: 001/010 | Batch 0650/1250 | Cost: 0.1558\n",
      "Epoch: 001/010 | Batch 0700/1250 | Cost: 0.1773\n",
      "Epoch: 001/010 | Batch 0750/1250 | Cost: 0.1906\n",
      "Epoch: 001/010 | Batch 0800/1250 | Cost: 0.1037\n",
      "Epoch: 001/010 | Batch 0850/1250 | Cost: 0.0611\n",
      "Epoch: 001/010 | Batch 0900/1250 | Cost: 0.1824\n",
      "Epoch: 001/010 | Batch 0950/1250 | Cost: 0.1016\n",
      "Epoch: 001/010 | Batch 1000/1250 | Cost: 0.1661\n",
      "Epoch: 001/010 | Batch 1050/1250 | Cost: 0.0744\n",
      "Epoch: 001/010 | Batch 1100/1250 | Cost: 0.1035\n",
      "Epoch: 001/010 | Batch 1150/1250 | Cost: 0.1623\n",
      "Epoch: 001/010 | Batch 1200/1250 | Cost: 0.1199\n",
      "Epoch: 001/010 | Train: 95.318% | Valid: 95.232%\n",
      "Time elapsed: 56.61 min\n",
      "Epoch: 002/010 | Batch 0000/1250 | Cost: 0.0887\n",
      "Epoch: 002/010 | Batch 0050/1250 | Cost: 0.0804\n",
      "Epoch: 002/010 | Batch 0100/1250 | Cost: 0.1428\n",
      "Epoch: 002/010 | Batch 0150/1250 | Cost: 0.1246\n",
      "Epoch: 002/010 | Batch 0200/1250 | Cost: 0.0737\n",
      "Epoch: 002/010 | Batch 0250/1250 | Cost: 0.1208\n",
      "Epoch: 002/010 | Batch 0300/1250 | Cost: 0.0678\n",
      "Epoch: 002/010 | Batch 0350/1250 | Cost: 0.1294\n",
      "Epoch: 002/010 | Batch 0400/1250 | Cost: 0.2057\n",
      "Epoch: 002/010 | Batch 0450/1250 | Cost: 0.1083\n",
      "Epoch: 002/010 | Batch 0500/1250 | Cost: 0.0981\n",
      "Epoch: 002/010 | Batch 0550/1250 | Cost: 0.1996\n",
      "Epoch: 002/010 | Batch 0600/1250 | Cost: 0.1223\n",
      "Epoch: 002/010 | Batch 0650/1250 | Cost: 0.0926\n",
      "Epoch: 002/010 | Batch 0700/1250 | Cost: 0.1063\n",
      "Epoch: 002/010 | Batch 0750/1250 | Cost: 0.1671\n",
      "Epoch: 002/010 | Batch 0800/1250 | Cost: 0.0633\n",
      "Epoch: 002/010 | Batch 0850/1250 | Cost: 0.1457\n",
      "Epoch: 002/010 | Batch 0900/1250 | Cost: 0.0847\n",
      "Epoch: 002/010 | Batch 0950/1250 | Cost: 0.1129\n",
      "Epoch: 002/010 | Batch 1000/1250 | Cost: 0.1436\n",
      "Epoch: 002/010 | Batch 1050/1250 | Cost: 0.1136\n",
      "Epoch: 002/010 | Batch 1100/1250 | Cost: 0.0925\n",
      "Epoch: 002/010 | Batch 1150/1250 | Cost: 0.0906\n",
      "Epoch: 002/010 | Batch 1200/1250 | Cost: 0.0925\n",
      "Epoch: 002/010 | Train: 96.226% | Valid: 96.142%\n",
      "Time elapsed: 75.42 min\n",
      "Epoch: 003/010 | Batch 0000/1250 | Cost: 0.0842\n",
      "Epoch: 003/010 | Batch 0050/1250 | Cost: 0.0718\n",
      "Epoch: 003/010 | Batch 0100/1250 | Cost: 0.0807\n",
      "Epoch: 003/010 | Batch 0150/1250 | Cost: 0.0386\n",
      "Epoch: 003/010 | Batch 0200/1250 | Cost: 0.0335\n",
      "Epoch: 003/010 | Batch 0250/1250 | Cost: 0.0617\n",
      "Epoch: 003/010 | Batch 0300/1250 | Cost: 0.0767\n",
      "Epoch: 003/010 | Batch 0350/1250 | Cost: 0.0756\n",
      "Epoch: 003/010 | Batch 0400/1250 | Cost: 0.0858\n",
      "Epoch: 003/010 | Batch 0450/1250 | Cost: 0.0669\n",
      "Epoch: 003/010 | Batch 0500/1250 | Cost: 0.0443\n",
      "Epoch: 003/010 | Batch 0550/1250 | Cost: 0.1078\n",
      "Epoch: 003/010 | Batch 0600/1250 | Cost: 0.0469\n",
      "Epoch: 003/010 | Batch 0650/1250 | Cost: 0.1036\n",
      "Epoch: 003/010 | Batch 0700/1250 | Cost: 0.0769\n",
      "Epoch: 003/010 | Batch 0750/1250 | Cost: 0.0867\n",
      "Epoch: 003/010 | Batch 0800/1250 | Cost: 0.1340\n",
      "Epoch: 003/010 | Batch 0850/1250 | Cost: 0.0887\n",
      "Epoch: 003/010 | Batch 0900/1250 | Cost: 0.0489\n",
      "Epoch: 003/010 | Batch 0950/1250 | Cost: 0.1275\n",
      "Epoch: 003/010 | Batch 1000/1250 | Cost: 0.0728\n",
      "Epoch: 003/010 | Batch 1050/1250 | Cost: 0.0600\n",
      "Epoch: 003/010 | Batch 1100/1250 | Cost: 0.0767\n",
      "Epoch: 003/010 | Batch 1150/1250 | Cost: 1.9474\n",
      "Epoch: 003/010 | Batch 1200/1250 | Cost: 0.6036\n",
      "Epoch: 003/010 | Train: 77.058% | Valid: 76.925%\n",
      "Time elapsed: 95.48 min\n",
      "Epoch: 004/010 | Batch 0000/1250 | Cost: 0.5295\n",
      "Epoch: 004/010 | Batch 0050/1250 | Cost: 0.4422\n",
      "Epoch: 004/010 | Batch 0100/1250 | Cost: 0.2498\n",
      "Epoch: 004/010 | Batch 0150/1250 | Cost: 0.2247\n",
      "Epoch: 004/010 | Batch 0200/1250 | Cost: 0.2278\n",
      "Epoch: 004/010 | Batch 0250/1250 | Cost: 0.2025\n",
      "Epoch: 004/010 | Batch 0300/1250 | Cost: 0.2289\n",
      "Epoch: 004/010 | Batch 0350/1250 | Cost: 0.1905\n",
      "Epoch: 004/010 | Batch 0400/1250 | Cost: 0.1553\n",
      "Epoch: 004/010 | Batch 0450/1250 | Cost: 0.1121\n",
      "Epoch: 004/010 | Batch 0500/1250 | Cost: 0.1512\n",
      "Epoch: 004/010 | Batch 0550/1250 | Cost: 0.1533\n",
      "Epoch: 004/010 | Batch 0600/1250 | Cost: 0.1512\n",
      "Epoch: 004/010 | Batch 0650/1250 | Cost: 0.1411\n",
      "Epoch: 004/010 | Batch 0700/1250 | Cost: 0.0922\n",
      "Epoch: 004/010 | Batch 0750/1250 | Cost: 0.1468\n",
      "Epoch: 004/010 | Batch 0800/1250 | Cost: 0.2544\n",
      "Epoch: 004/010 | Batch 0850/1250 | Cost: 0.0569\n",
      "Epoch: 004/010 | Batch 0900/1250 | Cost: 0.1554\n",
      "Epoch: 004/010 | Batch 0950/1250 | Cost: 0.1466\n",
      "Epoch: 004/010 | Batch 1000/1250 | Cost: 0.1346\n",
      "Epoch: 004/010 | Batch 1050/1250 | Cost: 0.1111\n",
      "Epoch: 004/010 | Batch 1100/1250 | Cost: 0.1046\n",
      "Epoch: 004/010 | Batch 1150/1250 | Cost: 0.1244\n",
      "Epoch: 004/010 | Batch 1200/1250 | Cost: 0.1133\n",
      "Epoch: 004/010 | Train: 95.504% | Valid: 95.482%\n",
      "Time elapsed: 114.92 min\n",
      "Epoch: 005/010 | Batch 0000/1250 | Cost: 0.1340\n",
      "Epoch: 005/010 | Batch 0050/1250 | Cost: 0.1049\n",
      "Epoch: 005/010 | Batch 0100/1250 | Cost: 0.0929\n",
      "Epoch: 005/010 | Batch 0150/1250 | Cost: 0.0717\n",
      "Epoch: 005/010 | Batch 0200/1250 | Cost: 0.1061\n",
      "Epoch: 005/010 | Batch 0250/1250 | Cost: 0.1591\n",
      "Epoch: 005/010 | Batch 0300/1250 | Cost: 0.1376\n",
      "Epoch: 005/010 | Batch 0350/1250 | Cost: 0.0757\n",
      "Epoch: 005/010 | Batch 0400/1250 | Cost: 0.0823\n",
      "Epoch: 005/010 | Batch 0450/1250 | Cost: 0.1016\n",
      "Epoch: 005/010 | Batch 0500/1250 | Cost: 0.0639\n",
      "Epoch: 005/010 | Batch 0550/1250 | Cost: 0.0877\n",
      "Epoch: 005/010 | Batch 0600/1250 | Cost: 0.1033\n",
      "Epoch: 005/010 | Batch 0650/1250 | Cost: 0.1105\n",
      "Epoch: 005/010 | Batch 0700/1250 | Cost: 0.1084\n",
      "Epoch: 005/010 | Batch 0750/1250 | Cost: 0.0994\n",
      "Epoch: 005/010 | Batch 0800/1250 | Cost: 0.0824\n",
      "Epoch: 005/010 | Batch 0850/1250 | Cost: 0.1198\n",
      "Epoch: 005/010 | Batch 0900/1250 | Cost: 0.0508\n",
      "Epoch: 005/010 | Batch 0950/1250 | Cost: 0.1020\n",
      "Epoch: 005/010 | Batch 1000/1250 | Cost: 0.1302\n",
      "Epoch: 005/010 | Batch 1050/1250 | Cost: 0.0642\n",
      "Epoch: 005/010 | Batch 1100/1250 | Cost: 0.0882\n",
      "Epoch: 005/010 | Batch 1150/1250 | Cost: 0.0974\n",
      "Epoch: 005/010 | Batch 1200/1250 | Cost: 0.0906\n",
      "Epoch: 005/010 | Train: 96.801% | Valid: 96.713%\n",
      "Time elapsed: 134.47 min\n",
      "Epoch: 006/010 | Batch 0000/1250 | Cost: 0.0951\n",
      "Epoch: 006/010 | Batch 0050/1250 | Cost: 0.0841\n",
      "Epoch: 006/010 | Batch 0100/1250 | Cost: 0.1895\n",
      "Epoch: 006/010 | Batch 0150/1250 | Cost: 0.0659\n",
      "Epoch: 006/010 | Batch 0200/1250 | Cost: 0.0709\n",
      "Epoch: 006/010 | Batch 0250/1250 | Cost: 0.0842\n",
      "Epoch: 006/010 | Batch 0300/1250 | Cost: 0.1060\n",
      "Epoch: 006/010 | Batch 0350/1250 | Cost: 0.0603\n",
      "Epoch: 006/010 | Batch 0400/1250 | Cost: 0.0620\n",
      "Epoch: 006/010 | Batch 0450/1250 | Cost: 0.0907\n",
      "Epoch: 006/010 | Batch 0500/1250 | Cost: 0.1020\n",
      "Epoch: 006/010 | Batch 0550/1250 | Cost: 0.1115\n",
      "Epoch: 006/010 | Batch 0600/1250 | Cost: 0.1054\n",
      "Epoch: 006/010 | Batch 0650/1250 | Cost: 0.1451\n",
      "Epoch: 006/010 | Batch 0700/1250 | Cost: 0.1029\n",
      "Epoch: 006/010 | Batch 0750/1250 | Cost: 0.0849\n",
      "Epoch: 006/010 | Batch 0800/1250 | Cost: 0.0952\n",
      "Epoch: 006/010 | Batch 0850/1250 | Cost: 0.0500\n",
      "Epoch: 006/010 | Batch 0900/1250 | Cost: 0.0804\n",
      "Epoch: 006/010 | Batch 0950/1250 | Cost: 0.0390\n",
      "Epoch: 006/010 | Batch 1000/1250 | Cost: 0.1084\n",
      "Epoch: 006/010 | Batch 1050/1250 | Cost: 0.1076\n",
      "Epoch: 006/010 | Batch 1100/1250 | Cost: 0.0376\n",
      "Epoch: 006/010 | Batch 1150/1250 | Cost: 0.1395\n",
      "Epoch: 006/010 | Batch 1200/1250 | Cost: 0.0964\n",
      "Epoch: 006/010 | Train: 97.121% | Valid: 97.050%\n",
      "Time elapsed: 154.35 min\n",
      "Epoch: 007/010 | Batch 0000/1250 | Cost: 0.0660\n",
      "Epoch: 007/010 | Batch 0050/1250 | Cost: 0.0902\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-9edd1e1a9ab3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/bvaa/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/bvaa/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/bvaa/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/bvaa/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/BVAA/experiments/JointVAE/dataloaders.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0msample_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_paths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0mimg_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mannotations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimg_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/bvaa/lib/python3.6/site-packages/skimage/transform/_warps.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(image, output_shape, order, mode, cval, clip, preserve_range, anti_aliasing, anti_aliasing_sigma)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0mtform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAffineTransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m             \u001b[0mtform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_corners\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst_corners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;31m# Make sure the transform is exactly metric, to ensure fast warping.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/bvaa/lib/python3.6/site-packages/skimage/transform/_geometric.py\u001b[0m in \u001b[0;36mestimate\u001b[0;34m(self, src, dst)\u001b[0m\n\u001b[1;32m    652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 654\u001b[0;31m             \u001b[0msrc_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_center_and_normalize_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    655\u001b[0m             \u001b[0mdst_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_center_and_normalize_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mZeroDivisionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/bvaa/lib/python3.6/site-packages/skimage/transform/_geometric.py\u001b[0m in \u001b[0;36m_center_and_normalize_points\u001b[0;34m(points)\u001b[0m\n\u001b[1;32m     59\u001b[0m                        [0, 0, 1]])\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m     \u001b[0mpointsh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrow_stack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpoints\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoints\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0mnew_pointsh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmatrix\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mpointsh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mvstack\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/bvaa/lib/python3.6/site-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36mvstack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0;31m# raise warning if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0m_arrays_for_stack_dispatcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m     \u001b[0marrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0matleast_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0marrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# import time\n",
    "\n",
    "# from tqdm.notebook import tqdm\n",
    "\n",
    "# def compute_accuracy(model, data_loader, device):\n",
    "#     correct_pred, num_examples = 0, 0\n",
    "#     for i, (features, targets) in enumerate(data_loader):\n",
    "            \n",
    "#         features = features.to(device)\n",
    "#         targets = targets.to(device)\n",
    "\n",
    "#         logits, probas = model(features)\n",
    "#         _, predicted_labels = torch.max(probas, 1)\n",
    "#         num_examples += targets.size(0)\n",
    "#         correct_pred += (predicted_labels == targets).sum()\n",
    "#     return correct_pred.float()/num_examples * 100\n",
    "    \n",
    "\n",
    "# start_time = time.time()\n",
    "# for epoch in tqdm(range(NUM_EPOCHS)):\n",
    "    \n",
    "#     model.train()\n",
    "#     for batch_idx, (features, targets) in enumerate(train_loader):\n",
    "        \n",
    "#         features = features.to(DEVICE)\n",
    "#         targets = targets.to(DEVICE)\n",
    "            \n",
    "#         ### FORWARD AND BACK PROP\n",
    "#         logits, probas = model(features)\n",
    "#         cost = F.cross_entropy(logits, targets)\n",
    "#         optimizer.zero_grad()\n",
    "        \n",
    "#         cost.backward()\n",
    "        \n",
    "#         ### UPDATE MODEL PARAMETERS\n",
    "#         optimizer.step()\n",
    "        \n",
    "#         ### LOGGING\n",
    "#         if not batch_idx % 50:\n",
    "#             print ('Epoch: %03d/%03d | Batch %04d/%04d | Cost: %.4f' \n",
    "#                    %(epoch+1, NUM_EPOCHS, batch_idx, \n",
    "#                      len(train_loader), cost))\n",
    "\n",
    "        \n",
    "\n",
    "#     model.eval()\n",
    "#     with torch.set_grad_enabled(False): # save memory during inference\n",
    "#         print('Epoch: %03d/%03d | Train: %.3f%% | Valid: %.3f%%' % (\n",
    "#               epoch+1, NUM_EPOCHS, \n",
    "#               compute_accuracy(model, train_loader, device=DEVICE),\n",
    "#               compute_accuracy(model, test_loader, device=DEVICE)))\n",
    "        \n",
    "#     print('Time elapsed: %.2f min' % ((time.time() - start_time)/60))\n",
    "    \n",
    "# print('Total Training Time: %.2f min' % ((time.time() - start_time)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), './models/celeba/classifier.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (6): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (7): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (8): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (9): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (10): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (11): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (12): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (13): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (14): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (15): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (16): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (17): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (18): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (19): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (20): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (21): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (22): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (23): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (24): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (25): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (26): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (27): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (28): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (29): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (30): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (31): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (32): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (33): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (34): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (35): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=2)\n",
       "  (fc): Linear(in_features=4096, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = resnet152(NUM_CLASSES, GRAYSCALE)\n",
    "classifier.to(DEVICE)\n",
    "\n",
    "classifier.load_state_dict(torch.load('models/celeba/classifier.pt'))\n",
    "classifier.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Latent distribution will be joint distribution of 10 gaussian normal distributions\n",
    "# and one 10 dimensional Gumbel Softmax distribution\n",
    "latent_spec = {'cont': 32,\n",
    "               'disc': [10]}\n",
    "latent_dim = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from celeba.models import VAE\n",
    "\n",
    "model = VAE(latent_spec=latent_spec, img_size=(3, 64, 64), use_cuda=True).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from celeba.training import Trainer\n",
    "\n",
    "# Define the capacities\n",
    "# Continuous channels\n",
    "cont_capacity = [0.0, 50.0, 100000, 100.0]  # Starting at a capacity of 0.0, increase this to 5.0\n",
    "                                         # over 25000 iterations with a gamma of 30.0\n",
    "# Discrete channels\n",
    "disc_capacity = [0.0, 10.0, 100000, 100.0]  # Starting at a capacity of 0.0, increase this to 5.0\n",
    "                                         # over 25000 iterations with a gamma of 30.0\n",
    "\n",
    "# Build optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=5e-4)\n",
    "    \n",
    "# Build a trainer\n",
    "trainer = Trainer(model, optimizer,\n",
    "                  cont_capacity=cont_capacity,\n",
    "                  disc_capacity=disc_capacity, use_cuda=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Build a visualizer which will be passed to trainer to visualize progress during training\n",
    "# from visualize import Visualizer\n",
    "\n",
    "# viz = Visualizer(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model for 10 epochs\n",
    "# Note this should really be a 100 epochs and trained on a GPU, but this is just to demo\n",
    "\n",
    "# trainer.train(train_loader, epochs=100, save_training_gif=('./training.gif', viz))\n",
    "if VAE_TRAIN:\n",
    "    trainer.train(train_loader, epochs=300)\n",
    "    torch.save(model.state_dict(), 'models/celeba/model.pt')\n",
    "else:\n",
    "    model.load_state_dict(torch.load('models/celeba/model.pt'))\n",
    "    model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'classifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-b8676d793a03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'classifier' is not defined"
     ]
    }
   ],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "for param in classifier.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloaders import CelebADataset\n",
    "from torchvision import transforms\n",
    "train_data = CelebADataset('/home/data/bvaa/CelebA', transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "252d63a075bf4bb79c77efa4baff8022",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=160000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "list_index = {}\n",
    "for i in tqdm(range(len(train_data))):\n",
    "    index = train_data[i][1]\n",
    "    if index not in list_index.keys():\n",
    "        list_index[index] = [i]\n",
    "    else:\n",
    "        list_index[index].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b05373a46e64cc780d387b2e7ec065d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "l_sample_list = {}\n",
    "def get_average_latent_space(list_index):\n",
    "    for i in tqdm(list_index.keys()):\n",
    "        for j in list_index[i]:\n",
    "            output, l_dist = model(train_data[j][0].unsqueeze(0).cuda())\n",
    "            l_sample_x = model.reparameterize(l_dist)\n",
    "            if i not in l_sample_list.keys():\n",
    "                l_sample_list[i] = [l_sample_x]\n",
    "            else:\n",
    "                l_sample_list[i].append(l_sample_x)\n",
    "        l_sample_list[i] = {'mean':torch.mean(torch.stack(l_sample_list[i]), dim=0),\n",
    "                           'std':torch.std(torch.stack(l_sample_list[i]), dim=0)}\n",
    "        \n",
    "get_average_latent_space(list_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def added_noise(image, digit, alphax=0.2, betay=1, plot=False):\n",
    "    output, l_dist = model(image.unsqueeze(0).float().cuda())\n",
    "    l_sample_x = model.reparameterize(l_dist)\n",
    "    alpha = torch.clamp(torch.randn(l_sample_list[digit]['std'].shape).cuda(), min=-1, max=1)\n",
    "    test_sample = l_sample_list[digit]['mean'] + alpha*l_sample_list[digit]['std']\n",
    "    test_sample = betay * l_sample_x + alphax * test_sample\n",
    "    test = model.decode(test_sample)\n",
    "#     preds = torch.argmax(classifier(F.upsample(test, (28,28), mode='bilinear', align_corners=True)))\n",
    "#     print(preds.item())\n",
    "    if plot:\n",
    "        plt.imshow(test[0].permute(1, 2, 0).cpu().detach().numpy(), interpolation='none')\n",
    "    return test_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(example_data[30].permute(1,2,0).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "added_noise(example_data[30], 0, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def check_distribution(digit, plot=False):\n",
    "    alpha = torch.clamp(torch.randn(l_sample_list[digit]['std'].shape).cuda(), min=-1, max=1)\n",
    "    test_sample = l_sample_list[digit]['mean'] + alpha*l_sample_list[digit]['std']\n",
    "    test = model.decode(test_sample)\n",
    "#     preds = torch.argmax(classifier(F.upsample(test, (28,28), mode='bilinear', align_corners=True)))\n",
    "#     print(preds.item())\n",
    "    if plot:\n",
    "        plt.imshow(test[0].permute(1, 2, 0).cpu().detach().numpy(), interpolation='none')\n",
    "    return test_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_distribution(1, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def digits_add(digit1, digit2, alpha=1, beta=1, plot=False):\n",
    "    l_1 = check_distribution(digit1)\n",
    "    l_2 = check_distribution(digit2)\n",
    "    if plot:\n",
    "        test = model.decode(beta*l_1+alpha*l_2)\n",
    "        plt.imshow(test[0].permute(1,2,0).cpu().detach().numpy(), interpolation='none')\n",
    "#         preds = classifier(F.upsample(test, (28,28), mode='bilinear', align_corners=True))\n",
    "#         print(preds.dtype)\n",
    "#         print(torch.argmax(preds).item())\n",
    "    return torch.norm(l_1-l_2), l_1, l_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg_dist(digit1, digit2, exp=10000):\n",
    "    cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "    distance = []\n",
    "    similarity = []\n",
    "    for i in range(exp):\n",
    "        dist, l1, l2 = digits_add(digit1,digit2)\n",
    "        similar = cos(l1,l2)\n",
    "        distance.append(dist.item())\n",
    "        similarity.append(similar.item())\n",
    "    a = round(sum(distance)/len(distance),5)\n",
    "    b = round(sum(similarity)/len(similarity),5)\n",
    "    return a,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def digit_to_study(digit):\n",
    "    distance = {}\n",
    "    similarity = {}\n",
    "    for i in tqdm(range(10)):\n",
    "        distance[i], similarity[i] = get_avg_dist(digit,i)\n",
    "    return distance, similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_avg_dist(1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_avg_dist(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_avg_dist(2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# digits_add(1,-1,0,plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# digits_add(1,3,0.3,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# digits_add(1,2,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# digit_to_study(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# digit_to_study(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check_distribution(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if FIND_DIST is True:\n",
    "#     l_means = []\n",
    "#     l_stds = []\n",
    "#     for i in l_sample_list.keys():\n",
    "#         l_means.append(l_sample_list[i]['mean'])\n",
    "#         l_stds.append(l_sample_list[i]['std'])\n",
    "\n",
    "#     l_mean_tensor = torch.stack(l_means).squeeze(1)\n",
    "#     # print(l_mean_tensor.shape)\n",
    "\n",
    "#     l_std_tensor = torch.stack(l_stds).squeeze(1)\n",
    "#     # print(l_std_tensor.shape)\n",
    "\n",
    "#     torch.save(l_mean_tensor, 'tensor/latent_mean.pt')\n",
    "#     torch.save(l_std_tensor, 'tensor/latent_std.pt')\n",
    "\n",
    "# else:\n",
    "#     l_mean_tensor = torch.load('tensor/latent_mean.pt')\n",
    "#     l_std_tensor = torch.load('tensor/latent_std.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examples = enumerate(test_loader)\n",
    "# batch_idx, (example_data,target) = next(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def check(i, digit1, digit2):\n",
    "    \n",
    "#     alpha = torch.clamp(torch.randn(l_sample_list[digit1]['std'].shape).cuda(), min=-1, max=1)\n",
    "#     test_sample = l_sample_list[digit1]['mean'] + F.normalize(alpha)*l_sample_list[digit1]['std']\n",
    "    \n",
    "#     alpha = torch.clamp(torch.randn(l_sample_list[digit2]['std'].shape).cuda(), min=-1, max=1)\n",
    "#     test_sample += l_sample_list[digit2]['mean'] + F.normalize(alpha)*l_sample_list[digit2]['std']\n",
    "    \n",
    "#     example_img = example_data[i,:,:,:].unsqueeze(0).cuda()\n",
    "#     output, l_dist = model(example_img)\n",
    "#     l_sample = model.reparameterize(l_dist)\n",
    "#     test_sample = l_sample + 0.4*test_sample\n",
    "#     test = model.decode(test_sample)\n",
    "#     preds = torch.argmax(classifier(F.upsample(test, (28,28), mode='bilinear', align_corners=True)))\n",
    "#     print(preds)\n",
    "#     plt.imshow(model.decode(test_sample)[0,0].cpu().detach().numpy(), cmap='gray', interpolation='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check(2,1,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_64(data):\n",
    "#     l_sample = None\n",
    "#     for i in range(data.shape[0]):\n",
    "#         output, l_dist_x = model(data[i,:,:,:].unsqueeze(0).cuda())\n",
    "#         l_sample_x = model.reparameterize(l_dist_x)\n",
    "#         if l_sample is None:\n",
    "#             l_sample = l_sample_x\n",
    "#         else:\n",
    "#             l_sample += l_sample_x\n",
    "#     l_sample = l_sample / data.shape[0]\n",
    "#     new_output = model.decode(l_sample)\n",
    "#     plt.imshow(new_output[0][0].detach().cpu().numpy(), cmap='gray', interpolation='none')\n",
    "#     pred = classifier(F.upsample(new_output, (28,28), mode='bilinear', align_corners=True))\n",
    "#     print(pred)\n",
    "#     print(torch.argmax(pred))\n",
    "#     return l_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_batch_avg(data):\n",
    "#     l_sample = None\n",
    "#     for i in range(data.shape[0]):\n",
    "#         output, l_dist_x = model(data[i,:,:,:].unsqueeze(0).cuda())\n",
    "#         l_sample_x = model.reparameterize(l_dist_x)\n",
    "#         if l_sample is None:\n",
    "#             l_sample = l_sample_x\n",
    "#         else:\n",
    "#             l_sample += l_sample_x\n",
    "#     l_sample = l_sample / data.shape[0]\n",
    "# #     new_output = model.decode(l_sample)\n",
    "# #     plt.imshow(new_output[0][0].detach().cpu().numpy(), cmap='gray', interpolation='none')\n",
    "# #     pred = classifier(F.upsample(new_output, (28,28), mode='bilinear', align_corners=True))\n",
    "# #     print(pred)\n",
    "# #     print(torch.argmax(pred))\n",
    "#     return l_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_avg_mnist(img1, data):\n",
    "# #     new_l_sample = None\n",
    "# #     count = len(list_to_process)\n",
    "#     output, l_dist_x = model(img1.cuda())\n",
    "#     l_sample_x = model.reparameterize(l_dist_x)\n",
    "#     l_sample_y = get_batch_avg(data)\n",
    "# #     output, l_dist_y = model(img2.cuda())\n",
    "# #     l_sample_y = model.reparameterize(l_dist_y)\n",
    "    \n",
    "#     l_sample = 1*l_sample_x + 0.4*l_sample_y\n",
    "    \n",
    "#     new_output = model.decode(l_sample)\n",
    "# #     for i in list_to_process:\n",
    "# #         example_img = example_data[i,:,:,:].unsqueeze(0).cuda()\n",
    "# #         output, l_dist = model(example_img)\n",
    "# #         l_sample = model.reparameterize(l_dist)\n",
    "# #         if new_l_sample is None:\n",
    "# #             new_l_sample = l_sample\n",
    "# #         else:\n",
    "# #             new_l_sample += l_sample\n",
    "# #     new_l_sample = new_l_sample / count\n",
    "# #     new_output = model.decode(new_l_sample)\n",
    "#     plt.imshow(new_output[0][0].detach().cpu().numpy(), cmap='gray', interpolation='none')\n",
    "#     pred = classifier(F.upsample(new_output, (28,28), mode='bilinear', align_corners=True))\n",
    "#     print(pred)\n",
    "#     print(torch.argmax(pred))\n",
    "#     print(pred[0,2].item(), pred[0,5].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_mnist(list_to_process):\n",
    "#     new_l_sample = None\n",
    "#     count = len(list_to_process)\n",
    "#     for i in list_to_process:\n",
    "#         example_img = example_data[i,:,:,:].unsqueeze(0).cuda()\n",
    "#         output, l_dist = model(example_img)\n",
    "#         l_sample = model.reparameterize(l_dist)\n",
    "#         if new_l_sample is None:\n",
    "#             new_l_sample = l_sample\n",
    "#         else:\n",
    "#             new_l_sample += l_sample\n",
    "#     new_l_sample = new_l_sample / count\n",
    "#     new_output = model.decode(new_l_sample)\n",
    "#     plt.imshow(new_output[0][0].detach().cpu().numpy(), cmap='gray', interpolation='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def check(i, j, alpha, beta):\n",
    "#     im1 = example_data[i,:,:,:].unsqueeze(0).cuda()\n",
    "#     im2 = example_data[j,:,:,:].unsqueeze(0).cuda()\n",
    "#     out1, l_dist1 = model(im1)\n",
    "#     out2, l_dist2 = model(im2)\n",
    "#     l_sample1 = model.reparameterize(l_dist1)\n",
    "#     l_sample2 = model.reparameterize(l_dist2)\n",
    "#     l_sample = alpha*l_sample1 + beta*l_sample2\n",
    "#     new_out = model.decode(l_sample)\n",
    "# #     new_out1 = model.decode(l_sample1)\n",
    "# #     new_out2 = model.decode(l_sample2)\n",
    "#     plt.figure(figsize=(10,15))\n",
    "#     plt.subplot(1,3,1)\n",
    "#     plt.imshow(example_data[i][0].detach().cpu().numpy(), cmap='gray', interpolation='none')\n",
    "#     plt.subplot(1,3,2)\n",
    "#     plt.imshow(example_data[j][0].detach().cpu().numpy(), cmap='gray', interpolation='none')\n",
    "#     plt.subplot(1,3,3)\n",
    "#     plt.imshow(new_out[0][0].detach().cpu().numpy(), cmap='gray', interpolation='none')\n",
    "#     print(torch.argmax(classifier(F.upsample(new_out, (28,28), mode='bilinear', align_corners=True))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpha=1\n",
    "# beta = 1.2\n",
    "# check(19,11, alpha, beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Attack(nn.Module):\n",
    "#     def __init__(self, attack_digit=attack_digit, target_digit=target_digit, vae=model, classifier=classifier, avg_latent=l_sample_list):\n",
    "#         super(self, Attack).__init__()\n",
    "#         self.classifier = classifier\n",
    "#         self.classifier.eval()\n",
    "#         self.vae = vae\n",
    "#         self.vae.eval()\n",
    "#         self.avg_latent = avg_latent\n",
    "#         self.attack_digit = attack_digit\n",
    "#         self.target_digit = target_digit\n",
    "#         self.hidden_layers = hidden_layers\n",
    "#         self.hidden_layers.insert(0, latent_dim)\n",
    "#         self.hidden_layers.append(latent_dim)\n",
    "#         self.layers = []\n",
    "        \n",
    "#         for i in range(len(self.hidden_layers)-1):\n",
    "#             self.layers.append(nn.Linear(self.hidden_layers[i], self.hidden_layers[i+1]))\n",
    "        \n",
    "#         self.layers = nn.ModuleList(self.layers)\n",
    "        \n",
    "#     def forward(self, x, y):\n",
    "#         _, l_dist_x = self.vae(x)\n",
    "#         _, l_dist_y = self.vae(y)\n",
    "#         l_sample_x = self.vae.reparameterize(l_dist_x)\n",
    "#         l_sample_y = self.vae.reparameterize(l_dist_y)\n",
    "#         noised_sample = l_sample\n",
    "#         for layer in self.layers:\n",
    "#             noised_sample = layer(noised_sample)\n",
    "#         noised_images = self.vae.decoder(noised_sample)\n",
    "#         preds = self.classifier(F.upsample(noised_image, (28,28), mode='bilinear', align_corners=True))\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import exp\n",
    "\n",
    "def gaussian(window_size, sigma):\n",
    "    gauss = torch.Tensor([exp(-(x - window_size//2)**2/float(2*sigma**2)) for x in range(window_size)])\n",
    "    return gauss/gauss.sum()\n",
    "\n",
    "def create_window(window_size, channel):\n",
    "    _1D_window = gaussian(window_size, 1.5).unsqueeze(1)\n",
    "    _2D_window = _1D_window.mm(_1D_window.t()).float().unsqueeze(0).unsqueeze(0)\n",
    "    window = torch.Tensor(_2D_window.expand(channel, 1, window_size, window_size).contiguous())\n",
    "    return window\n",
    "\n",
    "def _ssim(img1, img2, window, window_size, channel, size_average = True):\n",
    "    mu1 = F.conv2d(img1, window, padding = window_size//2, groups = channel)\n",
    "    mu2 = F.conv2d(img2, window, padding = window_size//2, groups = channel)\n",
    "\n",
    "    mu1_sq = mu1.pow(2)\n",
    "    mu2_sq = mu2.pow(2)\n",
    "    mu1_mu2 = mu1*mu2\n",
    "\n",
    "    sigma1_sq = F.conv2d(img1*img1, window, padding = window_size//2, groups = channel) - mu1_sq\n",
    "    sigma2_sq = F.conv2d(img2*img2, window, padding = window_size//2, groups = channel) - mu2_sq\n",
    "    sigma12 = F.conv2d(img1*img2, window, padding = window_size//2, groups = channel) - mu1_mu2\n",
    "\n",
    "    C1 = 0.01**2\n",
    "    C2 = 0.03**2\n",
    "\n",
    "    ssim_map = ((2*mu1_mu2 + C1)*(2*sigma12 + C2))/((mu1_sq + mu2_sq + C1)*(sigma1_sq + sigma2_sq + C2))\n",
    "\n",
    "    if size_average:\n",
    "        return ssim_map.mean()\n",
    "    else:\n",
    "        return ssim_map.mean(1).mean(1).mean(1)\n",
    "\n",
    "class SSIM(nn.Module):\n",
    "    def __init__(self, window_size = 11, size_average = True):\n",
    "        super(SSIM, self).__init__()\n",
    "        self.window_size = window_size\n",
    "        self.size_average = size_average\n",
    "        self.channel = 1\n",
    "        self.window = create_window(window_size, self.channel)\n",
    "\n",
    "    def forward(self, img1, img2):\n",
    "        (_, channel, _, _) = img1.size()\n",
    "\n",
    "        if channel == self.channel and self.window.data.type() == img1.data.type():\n",
    "            window = self.window\n",
    "        else:\n",
    "            window = create_window(self.window_size, channel)\n",
    "            \n",
    "            if img1.is_cuda:\n",
    "                window = window.cuda(img1.get_device())\n",
    "            window = window.type_as(img1)\n",
    "            \n",
    "            self.window = window\n",
    "            self.channel = channel\n",
    "\n",
    "\n",
    "        return _ssim(img1, img2, window, self.window_size, channel, self.size_average)\n",
    "\n",
    "def ssim(img1, img2, window_size = 11, size_average = True):\n",
    "    (_, channel, _, _) = img1.size()\n",
    "    window = create_window(window_size, channel)\n",
    "    \n",
    "    if img1.is_cuda:\n",
    "        window = window.cuda(img1.get_device())\n",
    "    window = window.type_as(img1)\n",
    "    \n",
    "    return _ssim(img1, img2, window, window_size, channel, size_average)\n",
    "\n",
    "ssim_loss = SSIM(window_size = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = True\n",
    "device = torch.device('cuda' if use_cuda else 'cpu')\n",
    "\n",
    "# Constrained Translator\n",
    "class Noise(nn.Module):\n",
    "    def __init__(self, hidden_layers=[50, 100, latent_dim], latent_dim=latent_dim):\n",
    "        super(Noise, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.hidden_layers.insert(0, latent_dim)\n",
    "        self.layers = []\n",
    "        \n",
    "        for i in range(len(self.hidden_layers)-1):\n",
    "            self.layers.append(nn.Linear(self.hidden_layers[i], self.hidden_layers[i+1]))\n",
    "        \n",
    "        self.layers = nn.ModuleList(self.layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constrained Cofficients\n",
    "class Cofficients(nn.Module):\n",
    "    def __init__(self, hidden_layers=[40, 20, 10, 1], latent_dim=latent_dim):\n",
    "        super(Cofficients, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.hidden_layers.insert(0, latent_dim)\n",
    "        self.layers = []\n",
    "        \n",
    "        for i in range(len(self.hidden_layers)-1):\n",
    "            self.layers.append(nn.Linear(self.hidden_layers[i], self.hidden_layers[i+1]))\n",
    "        \n",
    "        self.layers = nn.ModuleList(self.layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# use_cuda = True\n",
    "# device = torch.device('cuda' if use_cuda else 'cpu')\n",
    "\n",
    "\n",
    "# def create_logits(preds, device=device):\n",
    "#     preds = preds.cpu()\n",
    "#     logits = preds.cpu()\n",
    "    \n",
    "#     sorted_ = torch.argsort(preds, dim=1, descending=True)\n",
    "#     first = sorted_[:,0]\n",
    "#     second = sorted_[:,1]\n",
    "#     print(first)\n",
    "#     print(second)\n",
    "    \n",
    "#     p_first = preds.gather(1, first.view(-1,1))\n",
    "#     p_second = preds.gather(1, second.view(-1,1))\n",
    "#     means = torch.mean(torch.stack([p_first, p_second]), dim=0).squeeze(1)\n",
    "#     print(means)\n",
    "#     diff = 0.1*(first - second)\n",
    "#     print(diff)\n",
    "#     print((means-diff).shape)\n",
    "#     j = torch.arange(logits.size(0)).long()\n",
    "#     logits[j, first] = torch.FloatTensor(means - diff)\n",
    "#     logits[j, second] = torch.FloatTensor(means + diff)\n",
    "# #     print(logits[0])\n",
    "#     return logits.to(device), first, second\n",
    "\n",
    "# a = torch.randn((10,4)).cuda()\n",
    "# b = create_logits(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "use_cuda = True\n",
    "device = torch.device('cuda' if use_cuda else 'cpu')\n",
    "\n",
    "\n",
    "def create_logits(preds, device=device):\n",
    "    preds = preds.cpu()\n",
    "    logits = preds\n",
    "    \n",
    "    sorted_ = torch.argsort(preds, dim=1, descending=True)\n",
    "    first = sorted_[:,0]\n",
    "    second = sorted_[:,1]\n",
    "    \n",
    "    p_first = preds.gather(1, first.view(-1,1))\n",
    "    p_second = preds.gather(1, second.view(-1,1))\n",
    "#     print(p_first.shape)\n",
    "    \n",
    "    means = torch.mean(torch.stack([p_first, p_second]), dim=0).squeeze(1)\n",
    "#     print(means.shape)\n",
    "    diff = 0.5*(p_first - p_second).squeeze(1)\n",
    "#     print(diff.shape)\n",
    "    j = torch.arange(logits.size(0)).long()\n",
    "    \n",
    "    logits[j, first] = torch.FloatTensor(means - diff)\n",
    "    logits[j, second] = torch.FloatTensor(means + diff)\n",
    "    \n",
    "    return logits.to(device), first, second\n",
    "\n",
    "def structural(org_image, noised_image):\n",
    "    batch_size, channels, width, height = org_image.shape\n",
    "    loss1 = 0\n",
    "    for b_ in range(batch_size):\n",
    "        ch_loss = 0\n",
    "        for ch_ in range(channels):\n",
    "            ch_loss += 1-ssim(org_image[b_][ch_].detach().cpu().numpy(), noised_image[b_][ch_].detach().cpu().numpy())\n",
    "        loss1 += ch_loss/channels\n",
    "    return loss1\n",
    "            \n",
    "class T_Loss(nn.Module):\n",
    "    def __init__(self, decoder=model.decode, classifier=classifier,\n",
    "                 latent_dim=latent_dim, l_samples=l_sample_list,\n",
    "                 classes=len(l_sample_list.keys())):\n",
    "        super(T_Loss, self).__init__()\n",
    "        self.decoder = decoder\n",
    "        self.classifier = classifier\n",
    "#         self.means = means\n",
    "#         self.stds = stds\n",
    "        self.l_samples = l_samples\n",
    "        self.classes = classes\n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "        \n",
    "    def forward(self, coffs, noises, org_x, targets, alpha=0.6, beta=1):\n",
    "        \n",
    "        org_image = self.decoder(org_x)\n",
    "        \n",
    "        preds = self.classifier(org_image)[1]\n",
    "#         print(preds)\n",
    "        \n",
    "        alt_target, first, second = create_logits(preds)\n",
    "        \n",
    "        means = []\n",
    "        stds = []\n",
    "        \n",
    "        for key in second:\n",
    "            means.append(self.l_samples[key.item()]['mean'])\n",
    "            stds.append(self.l_samples[key.item()]['std'])\n",
    "        \n",
    "        means = torch.stack(means)\n",
    "        stds = torch.stack(stds)\n",
    "        noised_latent = means.squeeze(1) + torch.clamp(noises, min=-2, max=2) * stds.squeeze(1)\n",
    "        \n",
    "        noised_latent = torch.clamp(coffs, min=-3, max=3) * noised_latent\n",
    "#         noise_latent = F.normalize(coffs) * noise_latent\n",
    "        \n",
    "        noised_sample = beta * org_x + alpha * noised_latent\n",
    "        \n",
    "        noised_image = self.decoder(noised_sample)\n",
    "#         print(noised_image.shape)\n",
    "        preds = self.classifier(noised_image)[1]\n",
    "        \n",
    "        loss1 = ssim_loss(org_image, noised_image)\n",
    "#         print(preds.shape)\n",
    "#         print(alt_target.shape)\n",
    "        loss2 = nn.BCELoss(reduction='sum')(preds, alt_target)\n",
    "        \n",
    "        loss3 = torch.norm(org_image-noised_image, p=2)  \n",
    "\n",
    "        loss = 400*(1-loss1) + 0.6*loss2 + 20*loss3\n",
    "#         loss = 0.8*loss2 + 20*loss3\n",
    "#         loss = loss2 + 20*loss3\n",
    "#         loss.requires_grad = True\n",
    "        \n",
    "        out_labels = preds.argmax(dim=1, keepdim=True)\n",
    "#         print(out_labels)\n",
    "#         print(torch.empty(out_labels.shape).fill_(target_label))\n",
    "#         print(preds)\n",
    "#         correct = out_labels.eq(torch.Tensor([target_label]*out_labels.shape[0]).to(device)).sum()\n",
    "#         print(out_labels.shape)\n",
    "#         print((out_labels.squeeze(1)==targets.cuda()).sum())\n",
    "        correct = (out_labels.squeeze(1)==targets.cuda()).sum()\n",
    "#         print(out_labels.shape)\n",
    "#         print(correct)\n",
    "#         print(torch.Tensor([target_label]*out_labels.shape[0]))\n",
    "#         print(out_labels)\n",
    "        return loss, correct.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alt_target = 5\n",
    "noise = Noise().to(device)\n",
    "cofficient = Cofficients().to(device)\n",
    "\n",
    "for param in noise.parameters():\n",
    "    param.requires_grad=True\n",
    "    \n",
    "for param in cofficient.parameters():\n",
    "    param.requires_grad=True\n",
    "\n",
    "tloss = T_Loss().to(device)\n",
    "tloss.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count_digit = 0\n",
    "# for i in range(len(train_data)):\n",
    "#     if train_data[i][1]==5:\n",
    "#         count_digit += 1\n",
    "# print(count_digit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "attack_log_interval = 1\n",
    "\n",
    "noise.train()\n",
    "cofficient.train()\n",
    "\n",
    "optimizer1 = optim.Adam(noise.parameters(), lr=1e-4)\n",
    "# optimizer1 = torch.optim.SGD(noise.parameters(), lr=1e-4, momentum=0.9)\n",
    "\n",
    "# optimizer2 = torch.optim.SGD(cofficient.parameters(), lr=1e-4, momentum=0.9)\n",
    "optimizer2 = optim.Adam(cofficient.parameters(), lr=1e-4)\n",
    "\n",
    "\n",
    "# scheduler1 = torch.optim.lr_scheduler.CyclicLR(optimizer1, base_lr=1e-7, max_lr=0.1)\n",
    "# scheduler2 = torch.optim.lr_scheduler.CyclicLR(optimizer2, base_lr=1e-7, max_lr=0.1)\n",
    "\n",
    "for epoch in tqdm(range(150)):\n",
    "    epoch_loss = 0\n",
    "    epoch_correct = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data = data.float()\n",
    "        data = torch.Tensor(data).float().to(device)\n",
    "#         print(data.type)\n",
    "        _, l_dist = model(data)\n",
    "        l_sample = model.reparameterize(l_dist)\n",
    "        \n",
    "        n = noise(l_sample)\n",
    "        c = cofficient(l_sample)\n",
    "\n",
    "        optimizer1.zero_grad()\n",
    "        optimizer2.zero_grad()\n",
    "        \n",
    "        loss, correct = tloss(c, n, l_sample, target, alpha=1, beta=0)\n",
    "\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer1.step()\n",
    "        optimizer2.step()\n",
    "\n",
    "#         scheduler1.step()\n",
    "#         scheduler2.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "        epoch_correct += correct\n",
    "        \n",
    "    if (epoch+1) % attack_log_interval == 0:\n",
    "        print('Train Epoch: {}\\tLoss: {:.6f}\\tCorrect: {}'.format(\n",
    "            epoch+1, epoch_loss/batch_idx, epoch_correct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(noise, 'models/{}/noise.pt'.format(FOLDER))\n",
    "torch.save(cofficient, 'models/{}/coff.pt'.format(FOLDER))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise.eval()\n",
    "cofficient.eval()\n",
    "total_correct = 0\n",
    "total_test = 0\n",
    "for batch_idx, (data, target) in enumerate(test_loader):\n",
    "    total_test += data.shape[0]\n",
    "    data = data.float()\n",
    "    data = torch.Tensor(data).float().to(device)\n",
    "\n",
    "    _, l_dist = model(data)\n",
    "    l_sample = model.reparameterize(l_dist)\n",
    "    \n",
    "    noise_ = noise(l_sample)\n",
    "    coff_ = cofficient(l_sample)\n",
    "    \n",
    "    loss, correct = tloss(coff_, noise_, l_sample, target, 0., 0)\n",
    "    total_correct += correct\n",
    "#     print(correct)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         print(correct)\n",
    "#         epoch_loss += loss.item()\n",
    "    \n",
    "\n",
    "#     if (epoch+1) % attack_log_interval == 0:\n",
    "#         print('Train Epoch: \\tCorrect: {}'.format(\n",
    "#             epoch, epoch_correct))\n",
    "print(total_correct)\n",
    "print(\"Accuracy: \", 100*(total_correct/total_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check(i, alpha=0.6, beta=1):\n",
    "    _, l_dist = model(example_data[i].unsqueeze_(0).to(device))\n",
    "    l_sample = model.reparameterize(l_dist)\n",
    "\n",
    "    _,org_preds = classifier(model.decode(l_sample))\n",
    "#     print(\"original: \", torch.argmax(org_preds, dim=1))\n",
    "\n",
    "    noises = noise(l_sample)\n",
    "    coffs = cofficient(l_sample)\n",
    "\n",
    "    d = torch.argsort(org_preds, dim=1, descending=True)\n",
    "#     print(d)\n",
    "\n",
    "    noised_latent = l_sample_list[d[0,1].item()]['mean'].squeeze(1) + torch.clamp(noises, min=-5, max=5) * l_sample_list[d[0,1].item()]['std'].squeeze(1)\n",
    "    \n",
    "    noised_latent = torch.clamp(coffs, min=-3, max=3) * noised_latent\n",
    "#     noised_latent = F.normalize(coffs) * noised_latent\n",
    "\n",
    "    noised_sample = beta * l_sample + alpha * noised_latent\n",
    "\n",
    "    noised_image = model.decode(noised_sample)\n",
    "\n",
    "    _,fake_preds = classifier(noised_image)\n",
    "#     print(\"noised: \", torch.argmax(fake_preds, dim=1))\n",
    "#     print(example_data[i].permute(1,2,0).shape)\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(example_data[i].permute(1,2,0).detach().cpu().numpy())\n",
    "    plt.title(\"org:{}\".format(torch.argmax(org_preds, dim=1)))\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(noised_image[0].permute(1,2,0).detach().cpu().numpy())\n",
    "    plt.title(\"fake:{}\".format(torch.argmax(fake_preds, dim=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = enumerate(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_idx, (example_data,target) = next(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(64):\n",
    "    check(i,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(i, means=l_mean_tensor, stds=l_std_tensor, latent_dim=latent_dim, classes=len(train_data.classes)):\n",
    "    _, l_dist = model(example_data[i].unsqueeze_(0).to(device))\n",
    "    l_sample = model.reparameterize(l_dist)\n",
    "    noises = noise(l_sample)\n",
    "    coffs = cofficient(l_sample)\n",
    "#     print(coffs.shape)\n",
    "#     print(noises.shape)\n",
    "    noised_latent = means + noises.reshape(noises.shape[0], classes, latent_dim)*stds\n",
    "    noised_latent = coffs[:,:,None]*noised_latent\n",
    "#     print(noised_latent.shape)\n",
    "#     print(l_sample.shape)\n",
    "#     print(torch.transpose(coff[:,None].cuda()*avg_latent.T, 1, 2).sum(1).shape)\n",
    "#     noised_latent = l_sample + 2e-1*torch.transpose(coff[:,None].cuda()*avg_latent.T, 1, 2).sum(1)\n",
    "#     print(noised_latent.shape)\n",
    "#     print(noised_sample)\n",
    "#     print(l_sample)\n",
    "#     noised_sample = 1 * ((l_sample - l_sample.min())/(l_sample.max() - l_sample.min())) + 1e-2 * ((noised_sample - noised_sample.min())/(noised_sample.max() - noised_sample.min()))\n",
    "#     noised_sample = 1 * l_sample + 2e-2 * noised_sample\n",
    "#     noised_sample = l_sample + 1e-7 * noised_sample\n",
    "    final = model.decode(l_sample+1e-12*noised_latent.sum(dim=1))\n",
    "#     print(final.shape)\n",
    "    pred_org = torch.argmax(classifier(F.upsample(example_data[i,:,:,:].unsqueeze(0).cuda(), (28,28), mode='bilinear', align_corners=True)))\n",
    "    pred = torch.argmax(classifier(F.upsample(final, (28,28), mode='bilinear', align_corners=True)), dim=1)\n",
    "#     print(pred)\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(example_data[i][0].detach().cpu().numpy(), cmap='gray', interpolation='none')\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(final[0][0].detach().cpu().numpy(), cmap='gray', interpolation='none')\n",
    "    plt.title(\"Prediction: {}, {}\".format(pred_org.item(), pred.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(64):\n",
    "    test(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.transpose(torch.clamp(coff[:,None].cuda(), min=-0.8, max=0.3)*self.avg_latent.T, 1, 2).sum(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
